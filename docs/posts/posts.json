[
  {
    "path": "posts/20210123_PCA wine/",
    "title": "PCA Wine",
    "description": "PCA (using tidymodels) with wine dataset",
    "author": [
      {
        "name": "lruolin",
        "url": {}
      }
    ],
    "date": "2021-01-23",
    "categories": [],
    "contents": "\nSummary\nPCA is a data reduction technique, to uncover latent variables that are uncorrelated. It is an unsupervised way of classification. Not all of the variables in high-dimensional data are required. Some are highly correlated with others and these variables may be omitted, while retaining a similar level of information in the dataset in terms of explaining the variance.\nIt is used as an exploratory data analysis tool, and may be used for feature engineering and/or clustering.\nWorkflow\nImport data\nExploratory data analysis\nskim\nggcorr\nggpairs\nCheck assumptions on whether PCA can be carried out\nKMO\nBartlett\nCarry out PCA using tidymodels workflow\nAlways use only continuous variables, ensure that there are no missing data. Determine the number of components using eigenvalues, scree plots and parallel analysis.\nrecipe : preprocess the data (missing values, center and scale, ensuring that variables are continuous)\nprep : evaluate the data\nbake : get the PCA Scores results\nvisualize\ncommunicate results: show the scree plot, PCA loadings, variance explained by each component, loadings and score plot.\nThe scores plot show the positions of the individual wine samples in the coordinate system of the PCs.\nThe loadings plot shows the contribution of the X variables to the PCs.\nLoading packages\n\n\nlibrary(pacman)\np_load(corrr, palmerpenguins, GGally, tidymodels, tidytext, tidyverse, psych,\n       skimr, gridExtra, kohonen, janitor, learntidymodels, kohonen)\n\n\n\nImport\nThis dataset is from the kohonen package. It contains 177 rows and 13 columns.\nThese data are the results of chemical analyses of wines grown in the same region in Italy (Piedmont) but derived from three different cultivars: Nebbiolo, Barberas and Grignolino grapes. The wine from the Nebbiolo grape is called Barolo. The data contain the quantities of several constituents found in each of the three types of wines, as well as some spectroscopic variables.\nThe dataset requires some cleaning, and the type of wine was added to the datset.\n\n\ndata(wines)\n\nwines <- as.data.frame(wines) %>% \n  janitor::clean_names() %>%  # require data.frame\n  as_tibble() %>% \n  cbind(vintages)  # vintages = Y outcome = category\n \nglimpse(wines)\n\n\nRows: 177\nColumns: 14\n$ alcohol          <dbl> 13.20, 13.16, 14.37, 13.24, 14.20, 14.39, …\n$ malic_acid       <dbl> 1.78, 2.36, 1.95, 2.59, 1.76, 1.87, 2.15, …\n$ ash              <dbl> 2.14, 2.67, 2.50, 2.87, 2.45, 2.45, 2.61, …\n$ ash_alkalinity   <dbl> 11.2, 18.6, 16.8, 21.0, 15.2, 14.6, 17.6, …\n$ magnesium        <dbl> 100, 101, 113, 118, 112, 96, 121, 97, 98, …\n$ tot_phenols      <dbl> 2.65, 2.80, 3.85, 2.80, 3.27, 2.50, 2.60, …\n$ flavonoids       <dbl> 2.76, 3.24, 3.49, 2.69, 3.39, 2.52, 2.51, …\n$ non_flav_phenols <dbl> 0.26, 0.30, 0.24, 0.39, 0.34, 0.30, 0.31, …\n$ proanth          <dbl> 1.28, 2.81, 2.18, 1.82, 1.97, 1.98, 1.25, …\n$ col_int          <dbl> 4.38, 5.68, 7.80, 4.32, 6.75, 5.25, 5.05, …\n$ col_hue          <dbl> 1.05, 1.03, 0.86, 1.04, 1.05, 1.02, 1.06, …\n$ od_ratio         <dbl> 3.40, 3.17, 3.45, 2.93, 2.85, 3.58, 3.58, …\n$ proline          <dbl> 1050, 1185, 1480, 735, 1450, 1290, 1295, 1…\n$ vintages         <fct> Barolo, Barolo, Barolo, Barolo, Barolo, Ba…\n\nEDA\nSome exploratory data analysis was carried out:\nWhat are the types of variables? Categorical or numerical?\nWhat is the distribution like? Skewed?\nAre there any missing values?\nAre there any outliers?\nCheck the types of wine\nAre the variables quite correlated with each other?\nskimr\n\n\nskim(wines) # 177 x 13, all numeric + Y outcome\n\n\nTable 1: Data summary\nName\nwines\nNumber of rows\n177\nNumber of columns\n14\n_______________________\n\nColumn type frequency:\n\nfactor\n1\nnumeric\n13\n________________________\n\nGroup variables\nNone\nVariable type: factor\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\nvintages\n0\n1\nFALSE\n3\nGri: 71, Bar: 58, Bar: 48\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nalcohol\n0\n1\n12.99\n0.81\n11.03\n12.36\n13.05\n13.67\n14.83\n▂▇▇▇▃\nmalic_acid\n0\n1\n2.34\n1.12\n0.74\n1.60\n1.87\n3.10\n5.80\n▇▅▂▂▁\nash\n0\n1\n2.37\n0.28\n1.36\n2.21\n2.36\n2.56\n3.23\n▁▂▇▅▁\nash_alkalinity\n0\n1\n19.52\n3.34\n10.60\n17.20\n19.50\n21.50\n30.00\n▁▆▇▃▁\nmagnesium\n0\n1\n99.59\n14.17\n70.00\n88.00\n98.00\n107.00\n162.00\n▅▇▃▁▁\ntot_phenols\n0\n1\n2.29\n0.63\n0.98\n1.74\n2.35\n2.80\n3.88\n▅▇▇▇▁\nflavonoids\n0\n1\n2.02\n1.00\n0.34\n1.20\n2.13\n2.86\n5.08\n▆▆▇▂▁\nnon_flav_phenols\n0\n1\n0.36\n0.12\n0.13\n0.27\n0.34\n0.44\n0.66\n▃▇▅▃▂\nproanth\n0\n1\n1.59\n0.57\n0.41\n1.25\n1.55\n1.95\n3.58\n▃▇▆▂▁\ncol_int\n0\n1\n5.05\n2.32\n1.28\n3.21\n4.68\n6.20\n13.00\n▇▇▃▂▁\ncol_hue\n0\n1\n0.96\n0.23\n0.48\n0.78\n0.96\n1.12\n1.71\n▅▇▇▃▁\nod_ratio\n0\n1\n2.60\n0.71\n1.27\n1.93\n2.78\n3.17\n4.00\n▆▃▆▇▂\nproline\n0\n1\n745.10\n314.88\n278.00\n500.00\n672.00\n985.00\n1680.00\n▇▇▅▃▁\n\nGGally\n\n\nwines %>% \n  select(-vintages) %>% \n  ggcorr(label = T, label_alpha = T, label_round = 2)\n\n\n\nwines %>% \n  ggpairs(aes(col = vintages))\n\n\n\n\nChecking assumptions\nIs the dataset suitable for PCA analysis?\n\n\n# Continuous Y\n# No missing data\n# Check assumptions for PCA #####\nwines_no_y <- wines %>% \n  select(-vintages)\n\nglimpse(wines_no_y)\n\n\nRows: 177\nColumns: 13\n$ alcohol          <dbl> 13.20, 13.16, 14.37, 13.24, 14.20, 14.39, …\n$ malic_acid       <dbl> 1.78, 2.36, 1.95, 2.59, 1.76, 1.87, 2.15, …\n$ ash              <dbl> 2.14, 2.67, 2.50, 2.87, 2.45, 2.45, 2.61, …\n$ ash_alkalinity   <dbl> 11.2, 18.6, 16.8, 21.0, 15.2, 14.6, 17.6, …\n$ magnesium        <dbl> 100, 101, 113, 118, 112, 96, 121, 97, 98, …\n$ tot_phenols      <dbl> 2.65, 2.80, 3.85, 2.80, 3.27, 2.50, 2.60, …\n$ flavonoids       <dbl> 2.76, 3.24, 3.49, 2.69, 3.39, 2.52, 2.51, …\n$ non_flav_phenols <dbl> 0.26, 0.30, 0.24, 0.39, 0.34, 0.30, 0.31, …\n$ proanth          <dbl> 1.28, 2.81, 2.18, 1.82, 1.97, 1.98, 1.25, …\n$ col_int          <dbl> 4.38, 5.68, 7.80, 4.32, 6.75, 5.25, 5.05, …\n$ col_hue          <dbl> 1.05, 1.03, 0.86, 1.04, 1.05, 1.02, 1.06, …\n$ od_ratio         <dbl> 3.40, 3.17, 3.45, 2.93, 2.85, 3.58, 3.58, …\n$ proline          <dbl> 1050, 1185, 1480, 735, 1450, 1290, 1295, 1…\n\n# KMO: Indicates the proportion of variance in the variables that may be caused by underlying factors. High values (close to 1) indicate that factor analysis may be useful.\nwines_no_y %>% \n  cor() %>% \n  KMO() # .70 above : YES\n\n\nKaiser-Meyer-Olkin factor adequacy\nCall: KMO(r = .)\nOverall MSA =  0.78\nMSA for each item = \n         alcohol       malic_acid              ash   ash_alkalinity \n            0.73             0.80             0.44             0.68 \n       magnesium      tot_phenols       flavonoids non_flav_phenols \n            0.67             0.87             0.81             0.82 \n         proanth          col_int          col_hue         od_ratio \n            0.85             0.62             0.79             0.86 \n         proline \n            0.81 \n\n# Bartlett's test of sphericity: tests the hypothesis that the correlation matrix is an identity matrix (ie variables are unrelated and not suitable for structure detection.) For factor analysis, the p. value should be <0.05.\n\nwines_no_y %>% \n  cor() %>% \n  cortest.bartlett(., n = 177) # p<0.05\n\n\n$chisq\n[1] 1306.787\n\n$p.value\n[1] 3.302319e-222\n\n$df\n[1] 78\n\nTidymodels (PCA)\nRecipe\nWith the use of update_role(), the types of wine information is retained in the dataset.\nstep_normalize() combines step_center() and step_scale()\nNote that step_pca is the second step –> will need to retrieve the PCA results from the second list later.\n\n\nwines_recipe <- recipe(~ ., data = wines) %>% \n  update_role(vintages, new_role = \"id\") %>%  \n  # step_naomit(all_predictors()) %>% \n  step_normalize(all_predictors()) %>% \n  step_pca(all_predictors(), id = \"pca\")\n\nwines_recipe # 13 predictors\n\n\nData Recipe\n\nInputs:\n\n      role #variables\n        id          1\n predictor         13\n\nOperations:\n\nCentering and scaling for all_predictors()\nNo PCA components were extracted.\n\nPreparation\n\n\nwines_prep <- prep(wines_recipe)\n\nwines_prep # trained\n\n\nData Recipe\n\nInputs:\n\n      role #variables\n        id          1\n predictor         13\n\nTraining data contained 177 data points and no missing data.\n\nOperations:\n\nCentering and scaling for alcohol, malic_acid, ... [trained]\nPCA extraction with alcohol, malic_acid, ... [trained]\n\ntidy_pca_loadings <- wines_prep %>% \n  tidy(id = \"pca\")\n\ntidy_pca_loadings # values here are the loading\n\n\n# A tibble: 169 x 4\n   terms               value component id   \n   <chr>               <dbl> <chr>     <chr>\n 1 alcohol          -0.138   PC1       pca  \n 2 malic_acid        0.246   PC1       pca  \n 3 ash               0.00432 PC1       pca  \n 4 ash_alkalinity    0.237   PC1       pca  \n 5 magnesium        -0.135   PC1       pca  \n 6 tot_phenols      -0.396   PC1       pca  \n 7 flavonoids       -0.424   PC1       pca  \n 8 non_flav_phenols  0.299   PC1       pca  \n 9 proanth          -0.313   PC1       pca  \n10 col_int           0.0933  PC1       pca  \n# … with 159 more rows\n\nBake\n\n\nwines_bake <- bake(wines_prep, wines)\nwines_bake  # has the PCA SCORES that we are familiar with\n\n\n# A tibble: 177 x 6\n   vintages   PC1    PC2    PC3      PC4     PC5\n   <fct>    <dbl>  <dbl>  <dbl>    <dbl>   <dbl>\n 1 Barolo   -2.22 -0.301 -2.03   0.281   -0.259 \n 2 Barolo   -2.52  1.06   0.974 -0.734   -0.198 \n 3 Barolo   -3.74  2.80  -0.180 -0.575   -0.257 \n 4 Barolo   -1.02  0.886  2.02   0.432    0.274 \n 5 Barolo   -3.04  2.16  -0.637  0.486   -0.630 \n 6 Barolo   -2.45  1.20  -0.985  0.00466 -1.03  \n 7 Barolo   -2.06  1.64   0.143  1.20     0.0105\n 8 Barolo   -2.51  0.958 -1.78  -0.104   -0.871 \n 9 Barolo   -2.76  0.822 -0.986 -0.374   -0.437 \n10 Barolo   -3.48  1.35  -0.428 -0.0399  -0.316 \n# … with 167 more rows\n\nCheck number of PC\n\n\n# a. Eigenvalues: Keep components greater than 1\n# data is stored in penguins_prep, step 3\n\nwines_prep$steps[[2]]$res$sdev # 3\n\n\n [1] 2.1628220 1.5815708 1.2055413 0.9614802 0.9282978 0.8030241\n [7] 0.7429548 0.5922321 0.5377546 0.4967984 0.4748054 0.4103374\n[13] 0.3224124\n\n# b. Scree plot/Variance plot\n\nwines_prep %>% \n  tidy(id = \"pca\", type = \"variance\") %>% \n  filter(terms ==  \"percent variance\") %>% \n  ggplot(aes(x = component, y = value)) +\n  geom_point(size = 2) +\n  geom_line(size = 1) +\n  scale_x_continuous(breaks = 1:4) +\n  labs(title = \"% Variance explained\",\n       y = \"% total variance\",\n       x = \"PC\",\n       caption = \"Source: ChemometricswithR book\") +\n  theme_minimal() +\n  theme(axis.title = element_text(face = \"bold\", size = 12),\n        axis.text = element_text(size = 10),\n        plot.title = element_text(size = 14, face = \"bold\"))  # 2 or 3\n\n\n\n# bii: Cumulative variance plot\n\nwines_prep %>% \n  tidy(id = \"pca\", type = \"variance\") %>% \n  filter(terms == \"cumulative percent variance\") %>%\n  ggplot(aes(component, value)) +\n  geom_col(fill= \"forestgreen\") +\n  labs(x = \"Principal Components\", \n       y = \"Cumulative variance explained (%)\",\n       title = \"Cumulative Variance explained\") +\n  geom_text(aes(label = round(value, 2)), vjust = -0.2, size = 4) +\n  theme_minimal() +\n  theme(axis.title = element_text(face = \"bold\", size = 12),\n        axis.text = element_text(size = 10),\n        plot.title = element_text(size = 14, face = \"bold\")) \n\n\n\n# c. Parallel analysis\n\nfa.parallel(cor(wines_no_y),\n            n.obs = 333,\n            cor = \"cor\",\n            plot = T)  # 3\n\n\n\nParallel analysis suggests that the number of factors =  4  and the number of components =  3 \n\nVisualize\nLoadings plot\n\n\nplot_loadings <- tidy_pca_loadings %>% \n  filter(component %in% c(\"PC1\", \"PC2\", \"PC3\", \"PC4\")) %>% \n  mutate(terms = tidytext::reorder_within(terms, \n                                          abs(value), \n                                          component)) %>% \n  ggplot(aes(abs(value), terms, fill = value>0)) +\n  geom_col() +\n  facet_wrap( ~component, scales = \"free_y\") +\n  scale_y_reordered() + # appends ___ and then the facet at the end of each string\n  scale_fill_manual(values = c(\"deepskyblue4\", \"darkorange\")) +\n  labs( x = \"absolute value of contribution\",\n        y = NULL,\n        fill = \"Positive?\",\n        title = \"PCA Loadings Plot\",\n        subtitle = \"Number of PC should be 3, compare the pos and the neg\",\n        caption = \"Source: ChemometricswithR\") +\n  theme_minimal()\n\n\nplot_loadings\n\n\n\n# PC1: flavonoids, tot_phenols, od_ratio, proanthocyanidins, col_hue, 36%\n# PC2: col_int, alcohol, proline, ash, magnesium; 19.2%\n# PC3: ash, ash_alkalinity, non_flav phenols; 11.2%\n# PC4: malic acid?\n\n\n\nAn alternative way to plot:\n\n\n# alternate plot loadings\n\nlearntidymodels::plot_top_loadings(wines_prep,\n                  component_number <= 4, n = 5) +\n  scale_fill_manual(values = c(\"deepskyblue4\", \"darkorange\")) +\n  theme_minimal()\n\n\n\n\nLoadings only\n\n\n# define arrow style\narrow_style <- arrow(angle = 30,\n                     length = unit(0.2, \"inches\"),\n                     type = \"closed\")\n\n# get pca loadings into wider format\npca_loadings_wider <- tidy_pca_loadings%>% \n  pivot_wider(names_from = component, id_cols = terms)\n\n\npca_loadings_only <- pca_loadings_wider %>% \n  ggplot(aes(x = PC1, y = PC2)) +\n  geom_segment(aes(xend = PC1, yend = PC2),\n               x = 0, \n               y = 0,\n               arrow = arrow_style) +\n  ggrepel::geom_text_repel(aes(x = PC1, y = PC2, label = terms),\n            hjust = 0, \n            vjust = 1,\n            size = 5,\n            color = \"red\") +\n  labs(title = \"Loadings on PCs 1 and 2 for normalized data\") +\n  theme_classic()\n\n\n\nScores plot\n\n\n# Scores plot #####\n# PCA SCORES are in bake\npc1pc2_scores_plot <- wines_bake %>% \n  ggplot(aes(PC1, PC2)) +\n  geom_point(aes(color = vintages, shape = vintages), \n             alpha = 0.8, size = 2) +\n  scale_color_manual(values = c(\"deepskyblue4\", \"darkorange\", \"purple\")) +\n  labs(title = \"Scores on PCs 1 and 2 for normalized data\",\n       x = \"PC1 (36%)\",\n       y = \"PC2 (19.2%)\") +\n  theme_classic() +\n  theme(legend.position = \"none\") \n\n\n\nFinalised plots\n\n\ngrid.arrange(pc1pc2_scores_plot, pca_loadings_only, ncol = 2)\n\n\n\n\nCheck against Data\n\n\nwines %>% \n  group_by(vintages) %>% \n  summarise(across(c(flavonoids, col_int, ash, malic_acid),\n                   mean,\n                   na.rm = T))\n\n\n# A tibble: 3 x 5\n  vintages   flavonoids col_int   ash malic_acid\n* <fct>           <dbl>   <dbl> <dbl>      <dbl>\n1 Barbera         0.781    7.40  2.44       3.33\n2 Barolo          2.98     5.53  2.46       2.02\n3 Grignolino      2.08     3.09  2.24       1.93\n\nInterpretation of results\nPCA allows for exploratory characterizing of x variables that are associated with each other.\nPC1: flavanoids, total phenols, OD_ratio. PC2: color intensity, alcohol, proline PC3: ash, ash_alkalinity PC4: malic acid (by right 3 components are sufficient)\nBarbera, indicated in blue, has the largest score on PC 1 and PC2. Barolo, indicated in orange, has the smallest score on PC 1. Grignolo, indicated in purple, has the lowest score on PC 2.\nBarbera has low flavonoids, high col_int and high malic acid Barolo has high flavonoids, medium col_int and intermediate malic acid Grignolino has intermediate flavonoids, high col_int and low malic acid.\nReferences\nhttps://rdrr.io/github/tidymodels/learntidymodels/f/inst/tutorials/pca_recipes/pca_recipes.Rmd\nhttps://allisonhorst.github.io/palmerpenguins/articles/articles/pca.html\nhttps://www.ibm.com/support/knowledgecenter/en/SSLVMB_subs/statistics_casestudies_project_ddita/spss/tutorials/fac_telco_kmo_01.html\n\n\n\n",
    "preview": "posts/20210123_PCA wine/PCA-wine_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2021-01-23T15:55:43+08:00",
    "input_file": {}
  },
  {
    "path": "posts/20210120_statistical concepts/",
    "title": "Statistical Concepts",
    "description": "Definition of terms",
    "author": [
      {
        "name": "lruolin",
        "url": {}
      }
    ],
    "date": "2021-01-20",
    "categories": [],
    "contents": "\nThis is a glossary of terms, in alphabetical order.\nCorrelation, r : whether there is any relationship between two variables. If so, whether the relationship is weak or strong, and what the direction of relationship is.\nPrincipal Component Analysis (PCA): a multivariate technique used to reduce the number of dimensions to explain the total variation in the data with a few linear combinations of original variables, which are uncorrelated.\nVariance, Sˆ2: the average of squared deviations of the values from mean. Square root of variance = standard deviation.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-21T00:34:33+08:00",
    "input_file": {}
  },
  {
    "path": "posts/20210115_kovats/",
    "title": "Kovats Index",
    "description": "R script for calculating Kovats Index",
    "author": [
      {
        "name": "lruolin",
        "url": {}
      }
    ],
    "date": "2021-01-15",
    "categories": [],
    "contents": "\n\nContents\nBackground\nR workflow\nExampleLoad packages\nImport\nTransform\n\nReferences:\n\nBackground\nAbout 70% of my time at work is spent on interpreting GCMS and GC data. It is more of a qualitative type of identifying what each peak is, and this requires a seach based on mass spectra found in the GCMS library, as well as using the retention index. When working on GC data, I am even more reliant on the retention index for cross checking of peaks on GCMS, since there is no spectra information available.\nRetention time is influenced by GC conditions and column types. Using retention time alone is not useful when you are trying to compare with retention times stated in the literature, since the elution conditions are different.\nThe Kovats index (KI) may be used to convert retention times into standardised retention indices (RI), based on retention times of alkane standards. The equation for Non-Isothermal Kovats RI is shown below.\n\\[\nI_x = 100n + 100(t_x-t_n) / (t_(n+1) − t_n)\n\\]\nPrior to learning R, I used to do the calculation on an excel spreadsheet. This was cumbersome, first I had to key in the retention times of each alkane standard, and then update my formula for the range of retention times between each alkane standard, and then copy and paste all the compiled retention times into 2 columns. That involved a lot of clicking with the mouse.\nR workflow\nRun alkane standards on instrument (for example, GCMS) and compile the retention times in either .csv or .xlsx.\nCreate a function to calculate KI.\nCalculate the KI for retention times between each pair of alkane standard\nMerge the compiled retention times and corresponding KI together\nExport the data to excel and use the vlookup function to find out the KI when retention time is keyed in; alternatively, use inner_join function to tabulate calculated KI before identifying the peaks. I am using the former as there may be some small peaks that were not integrated, or coeluted with other peaks, so there is still a degree of manual input that is required.\nExample\nSample retention time data was retrieved from: https://massfinder.com/wiki/Retention_index_guide\nLoad packages\n\n\nlibrary(tidyverse)\n\n\n\nImport\n\n\n# Key in values\ncarbon_number <- c(\"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\")\nMS_RT <- c(1.85, 2.71, 3.69, 4.59, 5.37, 6.19, 7.17, 8.40, 9.99)\n\n# Create a tibble\nms_rt <- cbind(carbon_number, MS_RT) %>% as_tibble()\nms_rt$carbon_number <- as.numeric(ms_rt$carbon_number)\nms_rt$MS_RT <- as.numeric(ms_rt$MS_RT)\n\n# The data may also be imported from excel\n\n\n\nTransform\n\n\n# create function to calculate KI ####\nto_Calc_KI = function(n,Tn,m,Tm,Ti){\n  RI = 100*n + (100*(m-n)*((Ti-Tn)/(Tm-Tn)))\n  round(RI, 0)\n  \n}\n\n\n\n\n\n# create function to filter by carbon number ####\n# dat refers to data\n# col refers to column\n# val refers to values\n\nfilter_by_carbon_number <- function(dat, col, val){\n  filter(dat, col %in%  val)\n}\n\n\n\nThe following step could be improved on by creating another function to repeat the codes rather than manually changing the values.\n\n\nfil_c8c9 <- filter_by_carbon_number(ms_rt, ms_rt$carbon_number, c(8,9)) \n\nfil_c9c10 <- filter_by_carbon_number(ms_rt, ms_rt$carbon_number, c(9,10)) \n\nfil_c10c11 <- filter_by_carbon_number(ms_rt, ms_rt$carbon_number, c(10,11)) \nfil_c11c12 <- filter_by_carbon_number(ms_rt, ms_rt$carbon_number, c(11,12)) \nfil_c12c13 <- filter_by_carbon_number(ms_rt, ms_rt$carbon_number, c(12,13)) \nfil_c13c14 <- filter_by_carbon_number(ms_rt, ms_rt$carbon_number, c(13,14)) \nfil_c14c15 <- filter_by_carbon_number(ms_rt, ms_rt$carbon_number, c(14,15)) \nfil_c15c16 <- filter_by_carbon_number(ms_rt, ms_rt$carbon_number, c(15,16)) \n\n\n\n\n\n# create function to generate tibble for KI calculation\ncreate_KI_tibble <- function(msrt_col, n , m){\n  seq(from = min(msrt_col), to = max(msrt_col), by = 0.01) %>% \n    as_tibble() %>% \n    rename(\"Ti\" = value) %>% \n    mutate(n = n,\n           m = m,\n           Tn = min(msrt_col), \n           Tm = max(msrt_col)) %>% \n    dplyr::select(n, Tn, m, Tm, Ti) %>% \n    mutate(KI = pmap_dbl(., to_Calc_KI))\n}\n\n\n\n\n\nc8c9 <- create_KI_tibble(fil_c8c9$MS_RT, 8, 9)\nc9c10 <- create_KI_tibble(fil_c9c10$MS_RT, 9, 10)\nc10c11 <- create_KI_tibble(fil_c10c11$MS_RT, 10, 11)\nc11c12 <- create_KI_tibble(fil_c11c12$MS_RT, 11, 12)\nc12c13 <- create_KI_tibble(fil_c12c13$MS_RT, 12, 13)\nc13c14 <- create_KI_tibble(fil_c13c14$MS_RT, 13, 14)\nc14c15 <- create_KI_tibble(fil_c14c15$MS_RT, 14, 15)\nc15c16 <- create_KI_tibble(fil_c15c16$MS_RT, 15, 16)\n\ncalculated_MS_KI <- rbind(c8c9, c9c10, c10c11, c11c12, c12c13, \n                          c13c14, c14c15, c15c16) %>% \n  select(Ti, KI)\n\n# Export created file if needed\n# write_xlsx(calculated_MS_KI, \"Kovats_Indices.xlsx\")\n\n\n\nLooking at the first 6 lines of tabulated KI:\n\n\nhead(calculated_MS_KI)\n\n\n# A tibble: 6 x 2\n     Ti    KI\n  <dbl> <dbl>\n1  1.85   800\n2  1.86   801\n3  1.87   802\n4  1.88   803\n5  1.89   805\n6  1.9    806\n\nReferences:\nhttps://webbook.nist.gov/chemistry/gc-ri/\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-15T11:19:30+08:00",
    "input_file": {}
  },
  {
    "path": "posts/20210118_calibration curves/",
    "title": "Calibration Curves Data",
    "description": "R script for calculating Limit of Detection and Limit of Quantification",
    "author": [
      {
        "name": "lruolin",
        "url": {}
      }
    ],
    "date": "2021-01-15",
    "categories": [],
    "contents": "\n\nContents\nLoading required packages\nBackground\nImport Example Dataset\nVisualize\nModel\nErrors in slope and intercept of regression line\nPredict the value of x from y:\n\nNote: the data and theory on calibration curve were with reference from: Statistics and Chemometrics for Analytical Chemistry, James N. Miller and Jane Charlotte Miller, 6th edition, Chapter 5\nLoading required packages\n\n\nlibrary(pacman)\np_load(tidyverse, broom, chemCal)\n\n\n\nBackground\nChemists often work with calibration data using standards of known concentrations and putting them through instrumental analysis. When plotting a calibration curve, it is of interest to calculate the limit of detection (LOD) and limit of quantification (LOQ) of the method.\nImport Example Dataset\nThe fluorescence intensities of standard aqueous fluorescein solutions were analysed with a spectrophotometer, and the fluorescence results are shown below:\n\n# A tibble: 7 x 2\n  conc_pgml  fluo\n      <dbl> <dbl>\n1         0   2.1\n2         2   5  \n3         4   9  \n4         6  12.6\n5         8  17.3\n6        10  21  \n7        12  24.7\n\nVisualize\n\n\n\nModel\nLet’s fit a linear model to get the slope (b) and intercept(a).\n\\[\ny = a + bx\n\\]\n\n\nCall:\nlm(formula = fluo ~ conc_pgml, data = data)\n\nResiduals:\n       1        2        3        4        5        6        7 \n 0.58214 -0.37857 -0.23929 -0.50000  0.33929  0.17857  0.01786 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   1.5179     0.2949   5.146  0.00363 ** \nconc_pgml     1.9304     0.0409  47.197 8.07e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4328 on 5 degrees of freedom\nMultiple R-squared:  0.9978,    Adjusted R-squared:  0.9973 \nF-statistic:  2228 on 1 and 5 DF,  p-value: 8.066e-08\n\nFrom above, we can see that slope = 1.9304, and intercept = 1.5179.\nErrors in slope and intercept of regression line\nThe limit of detection is defined as:\n\\[\nLOD = \\gamma_B + 3_{SB}\n\\] where LOD is the analyte concentration wich gives a signal equal to the blank signal plus three standard deviations of the blank.\nA function was created to calculate LOD and LOQ:\n\n\ncalcLOD_y <- function(model) {\n  SSE <- sum(model$residuals**2)\n  n <- length(model$residuals) -2\n  Syx <- sqrt(SSE/n)\n  intercept <- as.numeric(model$coefficients[1])\n  calculated_y <- intercept + 3*Syx\n  names(calculated_y) <- \"calculated_y\"\n  print(calculated_y)\n  \n  chemCal::inverse.predict(model,\n                  newdata = calculated_y,\n                  alpha = 0.05) \n}\n\n\n\n\n\ncalcLOQ_y <- function(model) {\n  SSE <- sum(model$residuals**2)\n  n <- length(model$residuals) -2\n  Syx <- sqrt(SSE/n)\n  intercept <- as.numeric(model$coefficients[1])\n  calculated_y <- intercept + 10*Syx\n  names(calculated_y) <- \"calculated_y\"\n  print(calculated_y)\n  \n  chemCal::inverse.predict(model,\n                  newdata = calculated_y,\n                  alpha = 0.05) \n}\n\n\n\nInserting the linear model from the fluorescence data:\n\n\nLOD_x <- calcLOD_y(fl_mod)\n\n\ncalculated_y \n      2.8164 \n\nLOD_x$Prediction \n\n\n[1] 0.6726958\n\n\n\nLOQ_x <- calcLOQ_y(fl_mod)\n\n\ncalculated_y \n    5.846334 \n\nLOQ_x$Prediction \n\n\n[1] 2.242319\n\nPredict the value of x from y:\nTo predict the concentration of fluorescein that has fluorescence units of 2.9, we use the function inverse.predict():\n\n\nchemCal::inverse.predict(fl_mod, \n                newdata = 2.9,\n                alpha = 0.05)\n\n\n$Prediction\n[1] 0.7160037\n\n$`Standard Error`\n[1] 0.2645698\n\n$Confidence\n[1] 0.6800982\n\n$`Confidence Limits`\n[1] 0.03590545 1.39610195\n\n\n\n\n",
    "preview": "posts/20210118_calibration curves/calibration-curves_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2021-01-18T23:23:27+08:00",
    "input_file": {}
  },
  {
    "path": "posts/20210114_motivations/",
    "title": "Motivations",
    "description": "why R?",
    "author": [
      {
        "name": "lruolin",
        "url": {}
      }
    ],
    "date": "2021-01-14",
    "categories": [],
    "contents": "\nWhy R?\nI attended a short modular course on R, and was introduced to more effective and efficient ways of structuring data for customised plots that look way better than on Excel and SPSS. At the end of the course, I really wanted to retain what I have learnt, and build on what I have learnt, so that I can be better at R.\nR, to me, is a new form of literacy (like how Microsoft Office was taught in school last time). It is also an effective approach to learn problem solving, as well as a job skill.\nAristotle — ‘The more you know, the more you know you don’t know.’\nand that makes me want to learn even more.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-14T20:47:28+08:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "My first post: Learning goals for 2021",
    "description": "pRactice corner for coding in R",
    "author": [
      {
        "name": "lruolin",
        "url": {}
      }
    ],
    "date": "2021-01-14",
    "categories": [],
    "contents": "\nHi, this is my practice corner for coding in R. I would want to:\nlearn tidyverse\npractice on data visualization, exploration.\nlearn tidymodels/machine learning\nwork on chemistry related datasets using R\nlearn Design of Experiment\nlearn Chemometrics\nlearn how to analyse sensory data\nbe able to communicate insights from data analysis using the Rmarkdown/distill packages\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-18T21:54:53+08:00",
    "input_file": {}
  }
]
