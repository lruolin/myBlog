[
  {
    "path": "posts/20210301_tidy models regression 1/",
    "title": "Tidy Models - Regression",
    "description": "Predicting numerical outcomes using linear regression and random forest",
    "author": [
      {
        "name": "lruolin",
        "url": {}
      }
    ],
    "date": "2021-03-01",
    "categories": [],
    "contents": "\nOverview\nThis is an exercise for me to revise the tidymodels way of carrying out regression using linear regression (OLS) and random forest models. Only after going through the readings, my course materials, and actually trying to work through a dataset myself do I really appreciate what my Prof was trying to teach during his machine learning course..\nI will be working on a dataset familiar to me - the white wine dataset.\nMachine learning can be divided into supervised and unsupervised machine learning - the differentiating point is whether you know the outcome. In this case, I want to apply what I have learnt on predicting a known numerical outcome - this would be regression. If I want to predict a known categorical outcome - for eg whether the wine is red or white, then that would be classification. If I am unsure what are the types of wine, and just want to group them, then that would be clustering.\nFor regression, I could work on predicting the quality of wine from the white wine dataset, the quality of wine from the red wine dataset, or the quality of wine from both the red and white wine dataset.\nAs a start, let me try to predict the quality score of white wine from the various attributes.\nGeneral Workflow for Predicting Numerical Outcome using Linear Regression and Random Forest\nMost of the points mentioned below were taken from: https://jhudatascience.org/tidyversecourse/model.html#summary-of-tidymodels.\nThis was a great read for me to frame my learning and see the whole picture\nThe general steps are outlined below:\n1. Import the data\nI will import the white wine dataset from https://archive.ics.uci.edu/ml/datasets/wine+quality. The attributes are:\nFeatures/X variables\nfixed acidity\nvolatile acidity\ncitric acid\nresidual sugar\nchlorides\nfree sulfur dioxide\ntotal sulfur dioxide\ndensity\npH\nsulphates\nalcohol\nOutcome/Y variable: 12 - quality (score between 0 and 10)\n2. Define the question you want to ask the data\nCan I predict the quality score (Y variable), based on the physicochemical attributes of white wine (X variables)?\n3. Clean and transform the data\nIn this case, the data is already in a tidy format. As for transformations required, I will leave it to the pre-processing step later.\n4. Exploratory data analysis (EDA)\nWhat do you look out for when doing EDA?\nShape of data: How many Y and how many X variables are there? How many observations are there? The number of observations (n) and number of parameters (p) may affect your choice of models.\nType of variables: are they numerical or categorical? Or are they numerical, but actually can be transformed into categorical (eg month of the year), or are they categorical, but should be transformed into dummy variables (eg for regression)?\nAre there any missing values? This may affect the modelling as some models cannot handle missing values.\nWithin each variable, what is the min, max, mean, median, range? Are the datapoints normally distributed, or skewed? This affects whether modelling, for eg OLS regression can be carried out, or should further transformations be carried out first?\nHow are the X variables related to each other? Are they correlated? What is the strength of correlation? Is there a multi-collinearity issue? These are points to be addressed for linear regression.\n5. Preprocessing the data\nAfter identifying all the “touch-up” points required for successful modelling, the data may be pre-processed using the recipes package. This is really a powerful package that can transform the data the way you want, using single-line commands (as compared to multiple clicks of the mouse). However, it requires the user to know what steps are to be taken.\nA list of preprocessig steps is given below:\nhttps://recipes.tidymodels.org/reference/index.html#section-basic-functions\nLike cooking, this is part art part science. If I want to do missing values imputation, which kind of imputation do I use? I am still learning as I go along for this step..\nIn a way, this preprocessing step helps you to zoom in razor sharp to the important X variables that can be used to predict Y. These X variables may exist as hidden variables that need carving out and polishing/transformation. There may be X variables that are of not much importance, so it is important to extract relevant information and keep the number of variables as small as possible without compromising on accuracy. In other words, that is called feature engineering.\n6. Carry out modelling on the training dataset\nSplit dataset into training, testing and cross-validation. The training dataset is for you to train models with. The cross-validation dataset should be a subset of training dataset, for tuning different parameters of the model to make it an even better model. Cross-validation is useful when the number of observations isn’t big enough to split into three different datasets for training, validation and testing. Instead, the data is randomly partitioned into subsamples to be used as training dataset for one partition, and the same subsample would be used as test dataset for another partition. In repeated cross-validation, the cross-validation is repeated many times, giving random partitions of the original sample. The test dataset is for testing the trained model to see if the model is able to deliver predictive results.\nUsually, you will train more than one model, and then compare the results. The choice of model could span over simple, easy to understand linear models, or difficult to interpret but accurate models (eg neural networks which is like a blackbox). The results of the trained dataset will usually not fare too badly, since the model was built using the training dataset. Different models may require different preprocessing and different types of parameter tuning.\n7. Assessing the test dataset.\nA litmus test of whether the model works is to look at how well the model performs its predictive task when a set of completely new data is provided to the model. Models may be assessed in terms of r-sq, root mean square error or mean absolute error to judge the performance.\nThe indicators above give us an understanding of how accurate the model is in terms of predicting new data. A model that is over-fitted fits the training dataset well, but is unable to predict the test dataset well. A model that can fit the test dataset well, may not be accurate enough to give good predictions. This is known as the bias-variance tradeoff.\n8. Communicate the modelling results\nResults should be shown as visualizations/data tables to communicate the findings.\nLoad required packages\nLoad required packages:\n\n\nlibrary(pacman)\np_load(tidyverse, janitor, GGally, skimr, ggthemes, ggsci,\n       broom, gvlma, ggfortify, jtools, car, huxtable, sandwich,\n       tidymodels, parsnip, vip)\n\n\n\nImport\n\n\nwhite_rawdata <- read.table(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\", \n                            strip.white = T, sep = \";\", header = T) %>% \n  as_tibble() \n\n# save as another variable \ndata_white <- white_rawdata\n\n\n\nExploratory data analysis\n\n\nglimpse(data_white) # 12 variables, all numerical\n\n\nRows: 4,898\nColumns: 12\n$ fixed.acidity        <dbl> 7.0, 6.3, 8.1, 7.2, 7.2, 8.1, 6.2, 7.0,…\n$ volatile.acidity     <dbl> 0.27, 0.30, 0.28, 0.23, 0.23, 0.28, 0.3…\n$ citric.acid          <dbl> 0.36, 0.34, 0.40, 0.32, 0.32, 0.40, 0.1…\n$ residual.sugar       <dbl> 20.70, 1.60, 6.90, 8.50, 8.50, 6.90, 7.…\n$ chlorides            <dbl> 0.045, 0.049, 0.050, 0.058, 0.058, 0.05…\n$ free.sulfur.dioxide  <dbl> 45, 14, 30, 47, 47, 30, 30, 45, 14, 28,…\n$ total.sulfur.dioxide <dbl> 170, 132, 97, 186, 186, 97, 136, 170, 1…\n$ density              <dbl> 1.0010, 0.9940, 0.9951, 0.9956, 0.9956,…\n$ pH                   <dbl> 3.00, 3.30, 3.26, 3.19, 3.19, 3.26, 3.1…\n$ sulphates            <dbl> 0.45, 0.49, 0.44, 0.40, 0.40, 0.44, 0.4…\n$ alcohol              <dbl> 8.8, 9.5, 10.1, 9.9, 9.9, 10.1, 9.6, 8.…\n$ quality              <int> 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, …\n\nsummary(data_white) # scale and range of values are quite different\n\n\n fixed.acidity    volatile.acidity  citric.acid     residual.sugar  \n Min.   : 3.800   Min.   :0.0800   Min.   :0.0000   Min.   : 0.600  \n 1st Qu.: 6.300   1st Qu.:0.2100   1st Qu.:0.2700   1st Qu.: 1.700  \n Median : 6.800   Median :0.2600   Median :0.3200   Median : 5.200  \n Mean   : 6.855   Mean   :0.2782   Mean   :0.3342   Mean   : 6.391  \n 3rd Qu.: 7.300   3rd Qu.:0.3200   3rd Qu.:0.3900   3rd Qu.: 9.900  \n Max.   :14.200   Max.   :1.1000   Max.   :1.6600   Max.   :65.800  \n   chlorides       free.sulfur.dioxide total.sulfur.dioxide\n Min.   :0.00900   Min.   :  2.00      Min.   :  9.0       \n 1st Qu.:0.03600   1st Qu.: 23.00      1st Qu.:108.0       \n Median :0.04300   Median : 34.00      Median :134.0       \n Mean   :0.04577   Mean   : 35.31      Mean   :138.4       \n 3rd Qu.:0.05000   3rd Qu.: 46.00      3rd Qu.:167.0       \n Max.   :0.34600   Max.   :289.00      Max.   :440.0       \n    density             pH          sulphates         alcohol     \n Min.   :0.9871   Min.   :2.720   Min.   :0.2200   Min.   : 8.00  \n 1st Qu.:0.9917   1st Qu.:3.090   1st Qu.:0.4100   1st Qu.: 9.50  \n Median :0.9937   Median :3.180   Median :0.4700   Median :10.40  \n Mean   :0.9940   Mean   :3.188   Mean   :0.4898   Mean   :10.51  \n 3rd Qu.:0.9961   3rd Qu.:3.280   3rd Qu.:0.5500   3rd Qu.:11.40  \n Max.   :1.0390   Max.   :3.820   Max.   :1.0800   Max.   :14.20  \n    quality     \n Min.   :3.000  \n 1st Qu.:5.000  \n Median :6.000  \n Mean   :5.878  \n 3rd Qu.:6.000  \n Max.   :9.000  \n\nskim(data_white) # no missing values, probably need to normalize data\n\n\nTable 1: Data summary\nName\ndata_white\nNumber of rows\n4898\nNumber of columns\n12\n_______________________\n\nColumn type frequency:\n\nnumeric\n12\n________________________\n\nGroup variables\nNone\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nfixed.acidity\n0\n1\n6.85\n0.84\n3.80\n6.30\n6.80\n7.30\n14.20\n▁▇▁▁▁\nvolatile.acidity\n0\n1\n0.28\n0.10\n0.08\n0.21\n0.26\n0.32\n1.10\n▇▅▁▁▁\ncitric.acid\n0\n1\n0.33\n0.12\n0.00\n0.27\n0.32\n0.39\n1.66\n▇▆▁▁▁\nresidual.sugar\n0\n1\n6.39\n5.07\n0.60\n1.70\n5.20\n9.90\n65.80\n▇▁▁▁▁\nchlorides\n0\n1\n0.05\n0.02\n0.01\n0.04\n0.04\n0.05\n0.35\n▇▁▁▁▁\nfree.sulfur.dioxide\n0\n1\n35.31\n17.01\n2.00\n23.00\n34.00\n46.00\n289.00\n▇▁▁▁▁\ntotal.sulfur.dioxide\n0\n1\n138.36\n42.50\n9.00\n108.00\n134.00\n167.00\n440.00\n▂▇▂▁▁\ndensity\n0\n1\n0.99\n0.00\n0.99\n0.99\n0.99\n1.00\n1.04\n▇▂▁▁▁\npH\n0\n1\n3.19\n0.15\n2.72\n3.09\n3.18\n3.28\n3.82\n▁▇▇▂▁\nsulphates\n0\n1\n0.49\n0.11\n0.22\n0.41\n0.47\n0.55\n1.08\n▃▇▂▁▁\nalcohol\n0\n1\n10.51\n1.23\n8.00\n9.50\n10.40\n11.40\n14.20\n▃▇▆▃▁\nquality\n0\n1\n5.88\n0.89\n3.00\n5.00\n6.00\n6.00\n9.00\n▁▅▇▃▁\n\ndata_white %>% \n  ggpairs() # distribution of X is quite skewed, except maybe for pH.\n\n\n\n            # outcome is not unimodal --> ? \n\ndata_white %>% \n  ggcorr(label = T, label_alpha = T, label_round = 2) # some collinearity issues?\n\n\n\n\nSeems like OLS linear model isn’t really the best option for this case, since Y is multi-modal. It may be more suitable for classification to predict Y instead.\nNevertheless, let me compare the performance of OLS linear model with random forest, just for me to familiarise myself with the workflow for regression.\nTidymodels\nSplitting the dataset into training and testing datasets\n\n\nset.seed(202102212)\nwhitewine_split <- initial_split(data_white, prop = 0.8)\n\nwhitewine_train <- training(whitewine_split)\nwhitewine_test <- testing(whitewine_split)\n\n# split training dataset for cross-validation\nset.seed(20210228)\nwhite_cv <- vfold_cv(whitewine_train) # split training dataset for tuning mtry later\n\n\n\nSplitting the dataset into a training and testing dataset helps to minimise over-fitting of the model. Over-fitting the model would mean that the model fits the existing data very well, but is unable to predict for new data accurately.\nPreprocessing\nThe aim of preprocessing would be to solve the multi-collinearity issue, transform the data so that the distribution is not skewed, as well as to normalize the data.\n\n\nwhitewine_reciped <- whitewine_train %>% \n  recipe(quality ~., .) %>% \n  step_log(all_predictors(), -pH, offset = 1) %>% # do not use all numeric since will affect Y (outcome)\n  step_corr(all_predictors(), threshold = 0.5) %>%  # remove variables with r-sq > 0.5\n  step_normalize(all_predictors()) # means centering and scaling\n\nwhitewine_reciped \n\n\nData Recipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor         11\n\nOperations:\n\nLog transformation on all_predictors(), -pH\nCorrelation filter on all_predictors()\nCentering and scaling for all_predictors()\n\nTrain the data recipe\n\n\nwhitewine_preprocessed <- prep(whitewine_reciped, verbose = T)\n\n\noper 1 step log [training] \noper 2 step corr [training] \noper 3 step normalize [training] \nThe retained training set is ~ 0.29 Mb  in memory.\n\nww_transformed <- whitewine_preprocessed %>% bake(new_data = NULL) # see preprocessed data\nww_transformed %>%  as_tibble() %>% round(., digits = 3) %>%  head()\n\n\n┌────────────────────────────────────────────────────────────────── │ fixed.ac volatile citric.a residual chloride free.sul\n│ idity .acidity cid .sugar s fur.diox\n│ ide\n├────────────────────────────────────────────────────────────────── │ 0.226 -0.042 0.264 1.83  -0.023 0.682\n│ -0.643 0.27  0.093 -1.1   0.171 -1.47 \n│ 0.46  -0.471 -0.08  0.691 0.604 0.763\n│ 0.46  -0.471 -0.08  0.691 0.604 0.763\n│ 1.45  0.063 0.598 0.436 0.219 -0.075\n│ 0.226 -0.042 0.264 1.83  -0.023 0.682\n└──────────────────────────────────────────────────────────────────\nColumn names: fixed.acidity, volatile.acidity, citric.acid, residual.sugar, chlorides, free.sulfur.dioxide, pH, sulphates, alcohol, quality\n6/10 columns shown.\n\n# check for missing values \nww_transformed %>% \n  map(is.na) %>%  \n  map_df(sum) %>% \n  tidy() %>% \n  select(column, mean) %>%  # no missing values\n  as_tibble()\n\n\n               ┌──────────────────────────────┐\n               │ column                  mean │\n               ├──────────────────────────────┤\n               │ fixed.acidity              0 │\n               │ volatile.acidity           0 │\n               │ citric.acid                0 │\n               │ residual.sugar             0 │\n               │ chlorides                  0 │\n               │ free.sulfur.dioxide        0 │\n               │ pH                         0 │\n               │ sulphates                  0 │\n               │ alcohol                    0 │\n               │ quality                    0 │\n               └──────────────────────────────┘\nColumn names: column, mean\n\nSpecify the models\nLinear regression (OLS)\n\n\nww_lr_model <- linear_reg() %>% \n  set_engine(\"lm\") %>% # there are other options available, eg glmnet\n  set_mode(\"regression\") # could also be classification for certain models, so just specify as best practice to be clear\n\nww_lr_workflow <- workflow() %>% \n  add_recipe(whitewine_reciped) %>% \n  add_model(ww_lr_model)\n\n#  fit model to training data, and get predicted values\nfinal_ww_lm_model_fit <- fit(ww_lr_workflow, whitewine_train)\n\n# understanding the lm model\n\nlm_fit_output <- final_ww_lm_model_fit %>% \n  pull_workflow_fit() %>% \n  tidy() %>% \n  as_tibble()\n\nlm_fit_output\n\n\n┌────────────────────────────────────────────────────────────┐\n│ term          estimate   std.error   statistic     p.value │\n├────────────────────────────────────────────────────────────┤\n│ (Intercept    5.88          0.012     488        0         │\n│ )                                                          │\n│ fixed.acid   -0.0459        0.0139     -3.3      0.000983  │\n│ ity                                                        │\n│ volatile.a   -0.199         0.0126    -15.8      2.61e-54  │\n│ cidity                                                     │\n│ citric.aci   -0.000888      0.0129     -0.0686   0.945     │\n│ d                                                          │\n│ residual.s    0.121         0.0142      8.53     1.98e-17  │\n│ ugar                                                       │\n│ chlorides    -0.0194        0.0133     -1.45     0.147     │\n│ free.sulfu    0.125         0.0131      9.61     1.31e-21  │\n│ r.dioxide                                                  │\n│ pH            0.0165        0.0139      1.19     0.234     │\n│ sulphates     0.0465        0.0123      3.78     0.000161  │\n│ alcohol       0.458         0.0147     31.1      4.63e-190 │\n└────────────────────────────────────────────────────────────┘\nColumn names: term, estimate, std.error, statistic, p.value\n\nlm_fit <- final_ww_lm_model_fit %>% \n  pull_workflow_fit()\n\nlm_fit\n\n\nparsnip model object\n\nFit time:  8ms \n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n        (Intercept)        fixed.acidity     volatile.acidity  \n          5.8775198           -0.0459302           -0.1989870  \n        citric.acid       residual.sugar            chlorides  \n         -0.0008882            0.1212696           -0.0193643  \nfree.sulfur.dioxide                   pH            sulphates  \n          0.1254698            0.0165026            0.0465193  \n            alcohol  \n          0.4576764  \n\n# Looking at the fitted values:\nlm_fitted_values <- lm_fit$fit$fitted.values\n\n# another way, from workflow\nlm_wf_fitted_values <- \n  broom::augment(lm_fit$fit, data = whitewine_train) %>% \n  select(quality, .fitted: .std.resid)\n\nglimpse(lm_wf_fitted_values)\n\n\nRows: 3,919\nColumns: 6\n$ quality    <int> 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 7, 5, 6, 8, 5, 8…\n$ .fitted    <dbl> 5.469029, 5.165576, 5.863142, 5.863142, 5.686045,…\n$ .hat       <dbl> 0.0016112016, 0.0019222325, 0.0009142831, 0.00091…\n$ .sigma     <dbl> 0.7532844, 0.7532139, 0.7533292, 0.7533292, 0.753…\n$ .cooksd    <dbl> 8.032116e-05, 2.368036e-04, 3.023818e-06, 3.02381…\n$ .std.resid <dbl> 0.705488442, 1.108851543, 0.181776968, 0.18177696…\n\n# looking at variable importance\nvip_lm <- final_ww_lm_model_fit %>% \n  pull_workflow_fit() %>% # extracts the model information\n  vip(num_features = 10, \n      aesthetics = list(fill = \"deepskyblue4\")) + # most important factor is alcohol +\n  labs(title = \"Variable Importance: Linear Regression\") +\n  theme_few() +\n  theme(axis.text = element_text(face = \"bold\", size = 14))\n\nvip_lm\n\n\n\n\nRandom forest model\n\n\nrf_model <- rand_forest() %>% \n  set_args(mtry = tune()) %>% \n  set_mode(mode = \"regression\") %>% \n  set_engine(engine = \"ranger\", importance = \"impurity\")\n\nrf_model\n\n\nRandom Forest Model Specification (regression)\n\nMain Arguments:\n  mtry = tune()\n\nEngine-Specific Arguments:\n  importance = impurity\n\nComputational engine: ranger \n\nrf_workflow <- workflow() %>% \n  add_recipe(whitewine_reciped) %>% \n  add_model(rf_model)\n\nrf_grid <- expand.grid(mtry = 3:7) # choose sqrt(no. of variables) usually\n\ntuned_rf_results <- rf_workflow %>% \n  tune_grid(resamples = white_cv, # using cv dataset from training dataset\n            grid = rf_grid,\n            metrics = metric_set(rmse, rsq, mae))\n\nmodel_results <- tuned_rf_results %>% \n  collect_metrics()\n\nfinalized_rf_param <- tuned_rf_results %>% \n  select_best(metric = \"rmse\") %>% \n  as_tibble()\n\nfinalized_rf_param #M TRY = 3\n\n\n              ┌───────────────────────────────┐\n              │   mtry   .config              │\n              ├───────────────────────────────┤\n              │      3   Preprocessor1_Model1 │\n              └───────────────────────────────┘\nColumn names: mtry, .config\n\nrf_model_b <- rand_forest() %>% \n  set_args(mtry = 3) %>% \n  set_engine(engine = \"ranger\", importance = \"impurity\") %>% \n  set_mode(mode = \"regression\")\n\nrf_workflow_b <- workflow() %>% \n  add_recipe(whitewine_reciped) %>% \n  add_model(rf_model_b)\n\nfinal_ww_rf_model_fit <- fit(rf_workflow_b, whitewine_train)\n\n# understanding the rf model\n\n# for random forest, need to set importance = impurity in set_engine() to extract this\nvip_rf <- final_ww_rf_model_fit %>% \n  pull_workflow_fit() %>% # extracts the model information\n  vip(num_features = 10, \n      aesthetics = list(fill = \"darkorange\"))+ # most important factor is alcohol\n  labs(title = \"Variable Importance: Random Forest\") +\n  theme_few() +\n  theme(axis.text = element_text(face = \"bold\", size = 14))\n\nvip_rf\n\n\n\n\nComparing Linear Regression (OLS) vs Random Forest (RF)\n\n\ngridExtra::grid.arrange(vip_lm, vip_rf, nrow = 2)\n\n\n\n\nAlcohol content was the most important variable for both OLS and random forest models.\nAssessing on test data\n\n\nresults_train <- final_ww_lm_model_fit %>% \n  predict(new_data = whitewine_train) %>%  # use actual train data, not preprocessed data\n  mutate(truth = whitewine_train$quality,\n         model = \"lm\") %>% \n  bind_rows(final_ww_rf_model_fit %>% \n              predict(new_data = whitewine_train) %>% \n              mutate(truth = whitewine_train$quality,\n                     model = \"rf\")) \n  \nresults_train %>% \n  group_by(model) %>% \n  metrics(truth = truth, estimate = .pred) %>% \n  as_tibble()\n\n\n         ┌──────────────────────────────────────────┐\n         │ model   .metric   .estimator   .estimate │\n         ├──────────────────────────────────────────┤\n         │ lm      rmse      standard         0.752 │\n         │ rf      rmse      standard         0.277 │\n         │ lm      rsq       standard         0.282 │\n         │ rf      rsq       standard         0.934 │\n         │ lm      mae       standard         0.584 │\n         │ rf      mae       standard         0.198 │\n         └──────────────────────────────────────────┘\nColumn names: model, .metric, .estimator, .estimate\n\nresults_test <- final_ww_lm_model_fit %>% \n  predict(new_data = whitewine_test) %>% \n  mutate(truth = whitewine_test$quality,\n         model = \"lm\") %>% \n  bind_rows(final_ww_rf_model_fit %>% \n              predict(new_data = whitewine_test) %>% \n              mutate(truth = whitewine_test$quality,\n                     model = \"rf\")) \n\nresults_test %>% \n  group_by(model) %>% \n  metrics(truth = truth, estimate = .pred) %>% \n  as_tibble()\n\n\n         ┌──────────────────────────────────────────┐\n         │ model   .metric   .estimator   .estimate │\n         ├──────────────────────────────────────────┤\n         │ lm      rmse      standard         0.737 │\n         │ rf      rmse      standard         0.589 │\n         │ lm      rsq       standard         0.295 │\n         │ rf      rsq       standard         0.56  │\n         │ lm      mae       standard         0.581 │\n         │ rf      mae       standard         0.435 │\n         └──────────────────────────────────────────┘\nColumn names: model, .metric, .estimator, .estimate\n\nWhen comparing rmse, rf has lower rmse in training dataset but the rmse value increased in the test dataset –> overfitting and cannot predict as well.This was the same for other indicators rsq and mean absolute error.\nBear in mind that in the first place, the outcome variable Y was multi-modal. This may be the reason why OLS wasn’t a suitable learner.\nVisualizing the assessment\n\n\nresults_train %>% \n  ggplot(aes(x =  truth, y = .pred)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") +\n  geom_abline(col = \"darkorange\") +\n  labs(x = \"actual values (truth)\",\n       y = \"predicted values\",\n       title = \"Training dataset\") +\n  scale_x_continuous(breaks = c(1:10)) +\n  facet_wrap( model ~ ., ncol = 2) +\n  theme_few()\n\n\n\nresults_test %>% \n  ggplot(aes(x =  truth, y = .pred)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") +\n  geom_abline(col = \"darkorange\") +\n  labs(x = \"actual values (truth)\",\n       y = \"predicted values\",\n       title = \"Testing dataset\") +\n  scale_x_continuous(breaks = c(1:10)) +\n  facet_wrap( model ~ ., ncol = 2) +\n  theme_few()\n\n\n\n\nLearning points\nIt took me a while to piece different pieces of the jigsaw together to see the whole picture for machine learning. Initially, I will be carrying out EDA blindly, simply using skim() because it is a convenient function, but not fully understanding what I should be looking out for. I would be doing pre-processing steps at random, depending on what I saw from other websites. Finally, I saw the light that the purpose of doing EDA was to understand what I should be doing for preprocessing!\nIt is always good to start with the simple OLS when I am learning regression. There are assumptions that must be met before doing OLS – these could be checked using the gvlma package, and you can carry out the necessary transformations before doing OLS. There are other types of linear regression, for example generalized linear model (GLM), which I should try as well.\nThe order of carrying out preprocessing steps matter!\nThe choice of all_numerical, all_predictors in the recipe step matters! In this case, all_numerical includes the Y variable. Although Y is multimodal, it is not skewed, so I should not log transform it (which is what would happen if I were to use step_log(all_numerical())). If I log-transformed Y, I would run into errors further along the script, as there are some bugs regarding predict function if Y is transformed. The OLS model performed relatively consistently in both training and test dataset. However, the RF model performed better in the training dataset, but performance was poorer in the test dataset. This suggested that the RF model, in this case, had over-fitting issues.\nNext steps:\nTry out regression on a dataset in which Y is suitable for regression analysis\nTry out classification on wine dataset.\nTry out step_dummy, which creates numerical variables out of categorical variables\nTry out different algorithms and their tuning parameters\n“There is only one corner of the universe you can be certain of improving, and that’s your own self.” - ― Aldous Huxley\nThis is just the beginning of my learning journey!\nReferences\nhttps://www.tmwr.org/\nhttps://online.stat.psu.edu/stat508/lesson/1a\nhttps://semba-blog.netlify.app/05/11/2020/regression-with-tidymodels/\nhttps://stackoverflow.com/questions/63239600/how-to-make-predictions-in-tidymodels-r-when-the-data-has-been-preprocessed\nhttps://stackoverflow.com/questions/13956435/setting-values-for-ntree-and-mtry-for-random-forest-regression-model\nhttps://rviews.rstudio.com/2019/06/19/a-gentle-intro-to-tidymodels/\nhttps://jhudatascience.org/tidyversecourse/model.html\nhttps://koalaverse.github.io/vip/articles/vip.html\nhttp://rstudio-pubs-static.s3.amazonaws.com/565136_b4395e2500ec4c129ab776b9e8dd24de.html#results\n\n\n\n",
    "preview": "posts/20210301_tidy models regression 1/Tidy-Models---Regression-v2_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2021-03-03T22:04:39+08:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/20210219_color calculations (juice)/",
    "title": "Color Analysis in Juices",
    "description": "Using R for color calculations and data visualization",
    "author": [
      {
        "name": "lruolin",
        "url": {}
      }
    ],
    "date": "2021-02-19",
    "categories": [],
    "contents": "\nIntroduction\nWhy are food scientists interested in color analysis? Color is a visual quality attribute that determines food acceptance (Wrolstad and Smith (2017)). Instrumental color analysis is carried out in most commercial research and development laboratories to assess color stability, and in turn, shelf life of food products. The Hunter L a b color space is commonly used in the food industry, and was first published in 1942. Improvements were made to this system, to give more uniform color spacing, and in 1976, the CIELAB L* a* b* system was introduced. Chroma and Hue could be calculated from the a* and b* values. What do all these terms mean?\nL* : lightness (0 being black and 100 being white)\na*: red (+) and green (-)\nb*: yellow (+) and blue (-)\nChroma: a measure of how vivid/dull the color is. Chroma increases with increasing pigment concentration, and then decreases as the sample becomes darker.\nHue (in radian): the type of color - where red is defined as 0/360deg, yellow is defined as 90 deg, green is defined as 180 deg and blue is defined as 270 deg.\nThe calculations for chroma and hue are give below:\nChroma = sqrt(aˆ2 + bˆ2)\nHue is expressed in radians (multiply by 180/pi). However, this equation is only for the first quadrant. Other quadrants need to be handled so that a 360deg representation is accomodated (Mclellan, Lind, and Kime (1995)).\nFirst quadrant [+a, +b] : Hue = arc tan (b/a)\nSecond quadrant [‐a, +b] and third quadrant [−a, −b] calculations should be: hue = 180+Arc tan(b/a).\nFourth quadrant [+a, −b] calculations should be: hue = 360+ Arc tan(b/a).\nThe L* C* H* color space is more useful than just looking at L* a* b*, since it takes into account human perception of color, rather than just looking at redness/greenness and yellowness/blueness individually.\nUltimately, when color is measured, other than having an objective set of numbers to describe colors, it is also of interest to assess if there is any color difference between a reference sample and a test sample, and to peg a number to this color difference and immediately tell if the color difference is visually obvious to people.\nThere are different equations for assessing color difference:\ndeltaE-1976: the first internationally endorced color difference equation. However, it does not take into account that the human eye is more sensitive to small color differences in some regions of the color wheel but less sensitive to others.\ndeltaE-1994: Improvements were made to the 1976 equation, but it lacked accuracy in the blue-violet region of the color space.\ndeltaE-2000: Corrected for the 1994 equation to improve accuracy in the blue-violet space. This is the most updated and accurate representation of total color difference so far, and the equation is given in: http://www2.ece.rochester.edu/~gsharma/ciede2000/ciede2000noteCRNA.pdf.\nPreviously, I worked with Excel spreadsheets to carry out color data calculations. It was a nightmare when I tried to calculate hue using Excel, as the equations used for +a/-a/+b/-b could be different and it was problematic when I was trying to fill an equation down for my shelf life study. DE2000 was complicated and I tried to use a spreadsheet that I downloaded off the Internet, but I had to copy my data over to the template spreadsheet and it was a lot of copying and pasting.\nAll I want, is a workflow that can house all my data in 1 place, and automatically apply calculations with minimal manual input.\nI am so glad that I found R, and that there is an inbuilt package spacesXYZ, that can calculate the different variants of total color difference.\nObjective\nTo develop a workflow for automatic color calculations. This include writing my own function for calculating chroma, hue, and using inbuilt functions within spacesXYZ package to calculate de2000.\nTo visualize data and derive insights from shelf life data clearly.\nData\nThe data I am using is from a paper by Porto et al: https://www.mdpi.com/2306-5710/3/3/36. In this paper, the color data for five types of juices were given, and color changes were assessed in terms of L* a* b*, chroma and de1976. I went on further to look at hue, and de2000.\nWorkflow\nLoad data\nTransform data (in wide format) - calculate chroma and hue\nAdd in new columns with initial L* a* b* to facilitate calculation for de2000\nExtract initial L* a* b* values as matrix form\nExtract measured L* a* b* values as matrix form\nCalculate de2000 using spacesXYZ, as the function requires input to be in matrix form\nCalculate change in L* a* b* chroma and hue\nTransform data into long format for data visualization\nPlot de2000, L* a* b* chroma and hue, as well as change in L* a* b* chroma and hue to derive insights.\nLoad packages\n\n\nlibrary(pacman)\np_load(tidyverse, spacesXYZ, ggthemes, gridExtra, ggsci)\n\n\n\nImport Data\nThe five samples tested were:\nBJ: raw beet juice\nPBJ: pasteurized beet juice\nPOJ: pasteurized orange juice\nBOMJ_1: pasteurized beet and orange mix juice (1:1 v/v)\nBOMJ-2: pasteurized beet and orange mix juice (1:2, v/v)\n\n\ndata_l <- tribble(\n  ~Juices, ~L_d0, ~L_d5, ~L_d10, ~L_d15, ~L_d30,\n  #-------/------/-----/--------/------/-------\n  \"BJ\",     22.45, 22.87, 22.31, 22.37, 24.16 , \n  \"PBJ\",    22.37, 22.71, 22.34, 22.23, 23.72,\n  \"POJ\",    33.61, 38.18, 36.73, 37.04, 42.42,\n  \"BOMJ_1\", 23.21, 23.76, 23.15, 23.14, 24.78,\n  \"BOMJ_2\", 23.77, 24.33, 23.81, 24.15, 26.18\n)\n\n\ndata_a <- tribble(\n  ~Juices, ~a_d0, ~a_d5, ~a_d10, ~a_d15, ~a_d30,\n  #-------/------/-----/--------/------/-------\n  \"BJ\",     0.78, 0.68, 0.74, 0.81, 1.07,\n  \"PBJ\",    0.95, 0.82, 0.87, 0.91, 1.19,\n  \"POJ\",    -2.49, -2.87, -2.51, -2.63, -3.64,\n  \"BOMJ_1\", 4.80, 5.18, 4.78, 4.59, 6.13,\n  \"BOMJ_2\", 6.65, 7.07, 6.65, 6.68, 8.76\n)\n\n\ndata_b <- tribble(\n  ~Juices, ~b_d0, ~b_d5, ~b_d10, ~b_d15, ~b_d30,\n  #-------/------/-----/--------/------/-------\n  \"BJ\",    1.56, 1.52, 1.56, 1.57, 0.97, \n  \"PBJ\",   1.67, 1.61, 1.63, 1.64, 1.21,  \n  \"POJ\",  16.34, 17.03, 16.46, 15.95, 18.34,\n  \"BOMJ_1\", 2.39, 2.38, 2.35, 2.19, 2.23,\n  \"BOMJ_2\", 2.75, 2.82, 2.68, 2.26, 2.47\n)\n\n# Transform #####\ndata <- bind_cols(data_l, data_a, data_b, .name_repair = \"unique\") %>% \n  select(-Juices...7, -Juices...13) %>% \n  rename(juices = Juices...1)\n\n\n\nTransform\n\n\ndata_reshape_L <- data %>% \n  pivot_longer(cols = starts_with(\"L\"),\n               names_to = \"days_L\",\n               values_to = \"L_av\") %>% \n  select(juices, days_L, L_av)\n\n\ndata_reshape_a <- data %>% \n  pivot_longer(cols = starts_with(\"a\"),\n               names_to = \"days_a\",\n               values_to = \"a_av\") %>% \n  select(juices, days_a, a_av)\n  \ndata_reshape_b <- data %>%   \n  pivot_longer(cols = starts_with(\"b\"),\n               names_to = \"days_b\",\n               values_to = \"b_av\") %>% \n  select(juices, days_b, b_av)\n\n\ndata_reshaped <- bind_cols(data_reshape_L, data_reshape_a, data_reshape_b) %>% \n  mutate(days = parse_number(days_L)) %>% \n  select(juices...1, days, L_av, a_av, b_av) %>% \n  rename(juices = juices...1)\n\ndata_reshaped\n\n\n# A tibble: 25 x 5\n   juices  days  L_av  a_av  b_av\n   <chr>  <dbl> <dbl> <dbl> <dbl>\n 1 BJ         0  22.4  0.78  1.56\n 2 BJ         5  22.9  0.68  1.52\n 3 BJ        10  22.3  0.74  1.56\n 4 BJ        15  22.4  0.81  1.57\n 5 BJ        30  24.2  1.07  0.97\n 6 PBJ        0  22.4  0.95  1.67\n 7 PBJ        5  22.7  0.82  1.61\n 8 PBJ       10  22.3  0.87  1.63\n 9 PBJ       15  22.2  0.91  1.64\n10 PBJ       30  23.7  1.19  1.21\n# … with 15 more rows\n\nColor calculations\nWriting functions to calculate chroma and hue\n\n\ncal_chroma <- function (a_av, b_av) {\n  \n  a_sq = a_av^2\n  b_sq = b_av^2\n  chroma = sqrt(a_sq + b_sq)\n  \n}\n\ncal_hue <- function (a_av, b_av) {\n  \n  if(a_av > 0 & b_av > 0) {  # a pos, b pos\n    hue = 180*(atan(b_av/a_av)/pi)\n    \n    \n  }   else if (a_av<0 & b_av > 0) {  # a neg, b pos\n    hue = 180 + 180*(atan(b_av/a_av)/pi)\n    \n    \n  } else if (a_av<0 & b_av<0) {   # a neg, b neg\n    hue = 180 + 180*(atan(b_av/a_av)/pi)\n    \n    \n  } else {    # a pos, b neg\n    hue = 360 + 180*(atan(b_av/a_av)/pi)\n    \n  }\n  \n}\n\n\n\nAdding calculated chroma and hue columns to tibble\n\n\ndata_transformed <- data_reshaped %>% \n  mutate(chroma = map2_dbl(.x = a_av,\n                           .y = b_av,\n                           .f = cal_chroma),\n         hue = map2_dbl(.x = a_av,\n                        .y = b_av,\n                        .f = cal_hue))\n\nglimpse(data_transformed) # compares well with table\n\n\nRows: 25\nColumns: 7\n$ juices <chr> \"BJ\", \"BJ\", \"BJ\", \"BJ\", \"BJ\", \"PBJ\", \"PBJ\", \"PBJ\", \"…\n$ days   <dbl> 0, 5, 10, 15, 30, 0, 5, 10, 15, 30, 0, 5, 10, 15, 30…\n$ L_av   <dbl> 22.45, 22.87, 22.31, 22.37, 24.16, 22.37, 22.71, 22.…\n$ a_av   <dbl> 0.78, 0.68, 0.74, 0.81, 1.07, 0.95, 0.82, 0.87, 0.91…\n$ b_av   <dbl> 1.56, 1.52, 1.56, 1.57, 0.97, 1.67, 1.61, 1.63, 1.64…\n$ chroma <dbl> 1.744133, 1.665173, 1.726615, 1.766635, 1.444230, 1.…\n$ hue    <dbl> 63.43495, 65.89777, 64.62226, 62.70972, 42.19363, 60…\n\nCreating initial values tibble dataframe to calculate dE2000 later\n\n\ninitial <-  data_transformed %>% \n                      filter(days == 0) %>% \n                      select(L_av, a_av, b_av, chroma, hue) %>% \n                      rename(ini_L = L_av,\n                             ini_a = a_av,\n                             ini_b = b_av,\n                             ini_chroma = chroma,\n                             ini_hue = hue)\n\ninitial\n\n\n# A tibble: 5 x 5\n  ini_L ini_a ini_b ini_chroma ini_hue\n  <dbl> <dbl> <dbl>      <dbl>   <dbl>\n1  22.4  0.78  1.56       1.74    63.4\n2  22.4  0.95  1.67       1.92    60.4\n3  33.6 -2.49 16.3       16.5     98.7\n4  23.2  4.8   2.39       5.36    26.5\n5  23.8  6.65  2.75       7.20    22.5\n\nAdding the initial L* a* b* values to tibble\n\n\ndata_transformed_b<- data_transformed %>% \n  group_by(juices) %>% \n  nest() %>% \n  bind_cols(initial) %>% \n  unnest(cols = c(data))\n\ndata_transformed_b\n\n\n# A tibble: 25 x 12\n# Groups:   juices [5]\n   juices  days  L_av  a_av  b_av chroma   hue ini_L ini_a ini_b\n   <chr>  <dbl> <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 BJ         0  22.4  0.78  1.56   1.74  63.4  22.4  0.78  1.56\n 2 BJ         5  22.9  0.68  1.52   1.67  65.9  22.4  0.78  1.56\n 3 BJ        10  22.3  0.74  1.56   1.73  64.6  22.4  0.78  1.56\n 4 BJ        15  22.4  0.81  1.57   1.77  62.7  22.4  0.78  1.56\n 5 BJ        30  24.2  1.07  0.97   1.44  42.2  22.4  0.78  1.56\n 6 PBJ        0  22.4  0.95  1.67   1.92  60.4  22.4  0.95  1.67\n 7 PBJ        5  22.7  0.82  1.61   1.81  63.0  22.4  0.95  1.67\n 8 PBJ       10  22.3  0.87  1.63   1.85  61.9  22.4  0.95  1.67\n 9 PBJ       15  22.2  0.91  1.64   1.88  61.0  22.4  0.95  1.67\n10 PBJ       30  23.7  1.19  1.21   1.70  45.5  22.4  0.95  1.67\n# … with 15 more rows, and 2 more variables: ini_chroma <dbl>,\n#   ini_hue <dbl>\n\nCalculating de2000\n\n\n# calculate de2000 using spacesXYZ package, input must be as matrix\n\nlab_meas <- as.matrix(data_transformed_b[, c(\"L_av\", \"a_av\", \"b_av\")])\nlab_ini <- as.matrix(data_transformed_b[, c(\"ini_L\", \"ini_a\", \"ini_b\")])\n\ndata_de <- spacesXYZ::DeltaE(lab_ini, lab_meas, metric = 2000)\n  \n\ndata_transformed_c <- data_transformed_b %>% \n  bind_cols(data_de) %>% \n  rename(de2000 = ...13) %>% \n  ungroup() # remove group by juices\n\n# round off to 2 digits\ndata_transformed_c$de2000 <- round(data_transformed_c$de2000, digits = 2)\n\nglimpse(data_transformed_c)\n\n\nRows: 25\nColumns: 13\n$ juices     <chr> \"BJ\", \"BJ\", \"BJ\", \"BJ\", \"BJ\", \"PBJ\", \"PBJ\", \"PBJ…\n$ days       <dbl> 0, 5, 10, 15, 30, 0, 5, 10, 15, 30, 0, 5, 10, 15…\n$ L_av       <dbl> 22.45, 22.87, 22.31, 22.37, 24.16, 22.37, 22.71,…\n$ a_av       <dbl> 0.78, 0.68, 0.74, 0.81, 1.07, 0.95, 0.82, 0.87, …\n$ b_av       <dbl> 1.56, 1.52, 1.56, 1.57, 0.97, 1.67, 1.61, 1.63, …\n$ chroma     <dbl> 1.744133, 1.665173, 1.726615, 1.766635, 1.444230…\n$ hue        <dbl> 63.43495, 65.89777, 64.62226, 62.70972, 42.19363…\n$ ini_L      <dbl> 22.45, 22.45, 22.45, 22.45, 22.45, 22.37, 22.37,…\n$ ini_a      <dbl> 0.78, 0.78, 0.78, 0.78, 0.78, 0.95, 0.95, 0.95, …\n$ ini_b      <dbl> 1.56, 1.56, 1.56, 1.56, 1.56, 1.67, 1.67, 1.67, …\n$ ini_chroma <dbl> 1.744133, 1.744133, 1.744133, 1.744133, 1.744133…\n$ ini_hue    <dbl> 63.43495, 63.43495, 63.43495, 63.43495, 63.43495…\n$ de2000     <dbl> 0.00, 0.33, 0.11, 0.07, 1.42, 0.00, 0.31, 0.12, …\n\nThe perceptible difference is defined theoretically as de2000 being greater than 2 http://zschuessler.github.io/DeltaE/learn/. Which samples have de2000 >2?\n\n\n# threshold is de2000>2\n\nabove_threshold <- data_transformed_c %>% \n  filter(de2000>2) %>% \n  select(juices, days, de2000)\n\nabove_threshold  # POJ\n\n\n# A tibble: 5 x 3\n  juices  days de2000\n  <chr>  <dbl>  <dbl>\n1 POJ        5   3.84\n2 POJ       10   2.57\n3 POJ       15   2.85\n4 POJ       30   7.7 \n5 BOMJ_2    30   2.76\n\nColor difference was already perceptible for pasteurized orange juice from day 5. For beet and orange mixed juice (1:2 v/v), the color difference was perceptibely at day 30, at the end of shelf life.\nVisualization\n\n\n# Reshape data to make it suitable for facetting \n\ndata_viz_long <- data_transformed_c %>% \n  mutate(delta_L = L_av - ini_L,\n         delta_a = a_av - ini_a,\n         delta_b = b_av - ini_b,\n         delta_chroma = chroma - ini_chroma,\n         delta_hue = hue - ini_hue) %>% \n  select(juices, days, L_av:delta_hue) %>% \n  pivot_longer(cols = c(L_av:delta_hue),\n               names_to = \"parameters\",\n               values_to = \"readings\")\n  \n\ndata_viz_long\n\n\n# A tibble: 400 x 4\n   juices  days parameters readings\n   <chr>  <dbl> <chr>         <dbl>\n 1 BJ         0 L_av          22.4 \n 2 BJ         0 a_av           0.78\n 3 BJ         0 b_av           1.56\n 4 BJ         0 chroma         1.74\n 5 BJ         0 hue           63.4 \n 6 BJ         0 ini_L         22.4 \n 7 BJ         0 ini_a          0.78\n 8 BJ         0 ini_b          1.56\n 9 BJ         0 ini_chroma     1.74\n10 BJ         0 ini_hue       63.4 \n# … with 390 more rows\n\nde2000\n\n\ndata_viz_long %>% \n  filter(parameters == \"de2000\") %>% \n  ggplot(aes(days, readings)) +\n  geom_point(aes(col = juices), size = 2) +\n  geom_line(aes(col = juices), size = 1) +\n  scale_color_lancet() +\n  geom_hline(yintercept = 2, col = \"grey77\", lty = 2) +\n  labs(title = \"Comparison of Total Color Difference (dE2000) when stored at 4degC for 30 days\",\n       x = \"Days\",\n       y = \"Calc. dE2000\",\n       subtitle = \"Pure Orange Juice (POJ) had the greatest change in color. Addition of beet juice decreases change in color difference.\",\n       caption = \"Source: Porto et al, 2017\") +\n  facet_wrap(~juices, ncol = 3) +\n  theme_few() +\n  theme(title = element_text(face = \"bold\", size = 16),\n        legend.position = \"none\",\n        strip.text = element_text(face = \"bold\", size = 14))\n\n\n\n\nWhilst we know that pasteurized orange juice had perceptible color difference, what exactly was the difference due to? To answer this question, we will have to look at individual parameters (L* a* b* chroma and hue).\nUnderstanding each color parameter\n\n\nviz_absolute <- data_viz_long %>% \n  filter(parameters %in% c(\"L_av\", \"a_av\", \"b_av\", \"chroma\", \"hue\")) %>%\n  mutate(parameters_fct = factor(parameters,\n                                 levels = c(\"L_av\", \"a_av\", \"b_av\", \"chroma\", \"hue\"))) %>% \n  ggplot(aes(days, readings, group = juices)) +\n  geom_point(aes(col = juices), size = 2) +\n  geom_line(aes(col = juices), size = 1) +\n  scale_color_lancet() +\n  labs(title = \"Change in color over shelf life period\",\n       caption = \"Source: Porto et al, 2017\",\n       col = \"Juices\") +\n  facet_wrap( ~ parameters_fct, ncol = 5, scales = \"free\") +\n  theme_few()+\n  theme(title = element_text(face = \"bold\", size = 20),\n        strip.text = element_text(face = \"bold\", size = 16),\n        axis.text = element_text(size = 14),\n        legend.text = element_text(size = 14),\n        legend.position = \"top\")\n\nviz_change <- data_viz_long %>% \n  filter(parameters %in% c(\"delta_L\", \"delta_a\", \"delta_b\", \"delta_chroma\", \"delta_hue\")) %>% \n  mutate(parameters_fct = factor(parameters, \n                                 levels = c(\"delta_L\", \"delta_a\", \"delta_b\", \"delta_chroma\", \"delta_hue\"))) %>% \n  ggplot(aes(days, readings, group = juices)) +\n  geom_point(aes(col = juices), size = 2) +\n  geom_line(aes(col = juices), size = 1) +\n  scale_color_lancet() +\n  labs(title = \"Change in color over shelf life period\",\n       caption = \"Source: Porto et al, 2017\",\n       col = \"Juices\") +\n  facet_wrap( ~ parameters_fct, ncol = 5) +\n  theme_few()+\n  theme(title = element_text(face = \"bold\", size = 20),\n        strip.text = element_text(face = \"bold\", size = 16),\n        axis.text = element_text(size = 14),\n        legend.text = element_text(size = 14),\n        legend.position = \"top\")\n\ngrid.arrange(viz_absolute, viz_change, nrow = 2)\n\n\n\n\nInterpretation\nBeet juice is red in color and orange juice is orange-yellow in color. If we look at the L* a* b* values, from the onset, POJ had higher values for L* (ie more dark), lower a* (ie less red) and higher b* (ie more yellow). This is more easily understood by looking at the hue values, which describes the type of color (0 = red, 90 = yellow). In terms of color vividness, POJ was relatively more vivid than the other samples, and BJ and PBJ has the “dullest” color.\nHowever, for total color difference, we would be more interested in the change in each parameter. POJ had a relatively large increase in L* (ie more darkening of color). For hue, there was a slight increase for POJ, but it was less in magnitude as compared to BJ and PBJ.\n\n\ndata_viz_long %>% \n  filter(juices %in% c(\"BJ\", \"PBJ\", \"POJ\"),\n         days == 30,\n         parameters == \"delta_hue\") \n\n\n# A tibble: 3 x 4\n  juices  days parameters readings\n  <chr>  <dbl> <chr>         <dbl>\n1 BJ        30 delta_hue    -21.2 \n2 PBJ       30 delta_hue    -14.9 \n3 POJ       30 delta_hue      2.56\n\nBJ and PBJ had a decrease in hue of 21 units and 15 units. This meant that the color became less orange-red and more red. However, the change in de2000 was probably attributed to the change in L* for POJ. Even though there was a difference in hue, the total color difference was below threshold of 2 for BJ and PBJ. Color instability was mostly attributed to pasteurized orange juice, and beet juice was relatively more stable.\nBetalains were responsible for the red color in beet, and carotenoids are responsible for the orange color in oranges (Tanaka, Sasaki, and Ohmiya (2008)). Fun fact: betalains color are not pH-dependent like anthocyanins, and they do not co-exist in plants.\nReflections\nI am happy that I managed to write a function for hue calculation, and use existing functions to calculate de2000. The calculations were really cumbersome when done in excel.\nWhen looking at color difference, it is important to look at both absolute readings and change in parameter readings to get the whole picture. The former allows you to understand what the starting point was, and the latter zooms in to the change between the start and at the end of shelf life. Although the data could be expressed in numerical form in tables, properly drawn graphs give more intuitive understanding of the data. I really like the faceting function in R, as it allows me to see all the types of juices and different color parameters clearly. In addition, the grid.arrange function allows me to display more than one graph.\nIn this shelf life study, only one temperature condition was studied. What if more than one temperature/product were looked at? In such cases, repetitive color calculations may be made more efficient by using purrr.\nLinks\nhttps://www.mdpi.com/2306-5710/3/3/36 https://www.xrite.com/blog/lab-color-space https://sensing.konicaminolta.us/us/blog/identifying-color-differences-using-l-a-b-or-l-c-h-coordinates/ https://www.konicaminolta.com/instruments/knowledge/color/pdf/color_communication.pdf https://www.hdm-stuttgart.de/international_circle/circular/issues/13_01/ICJ_06_2013_02_069.pdf http://zschuessler.github.io/DeltaE/learn/\n\n\n\nMclellan, M. R., L. R. Lind, and R. W. Kime. 1995. “HUE ANGLE DETERMINATIONS AND STATISTICAL ANALYSIS FOR MULTIQUADRANT HUNTER l,a,b DATA.” Journal of Food Quality 18 (3): 235–40. https://doi.org/https://doi.org/10.1111/j.1745-4557.1995.tb00377.x.\n\n\nTanaka, Yoshikazu, Nobuhiro Sasaki, and Akemi Ohmiya. 2008. “Biosynthesis of Plant Pigments: Anthocyanins, Betalains and Carotenoids.” The Plant Journal 54 (4): 733–49. https://doi.org/https://doi.org/10.1111/j.1365-313X.2008.03447.x.\n\n\nWrolstad, Ronald E., and Daniel E. Smith. 2017. “Color Analysis.” In Food Analysis, edited by S. Suzanne Nielsen, 545–55. Food Science Text Series. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-45776-5_31.\n\n\n\n\n",
    "preview": "posts/20210219_color calculations (juice)/Color-analysis-for-Juices_files/figure-html5/unnamed-chunk-11-1.png",
    "last_modified": "2021-02-21T15:51:34+08:00",
    "input_file": {},
    "preview_width": 3072,
    "preview_height": 2304
  },
  {
    "path": "posts/20210216_durian volatiles/",
    "title": "Comparison of volatiles in Durians",
    "description": "Data visualization for volatiles in different durian varieties",
    "author": [
      {
        "name": "lruolin",
        "url": {}
      }
    ],
    "date": "2021-02-16",
    "categories": [],
    "contents": "\nIntroduction\nDurian is a tropical fruit that is either much loved or much hated in Singapore. There are different varieties of durians, and the top durians such as Mao Shan Wang can command prices of around $20-30 per kg. The price depends on the supply, the quality, and of course the demand.\nTeh et al. (2017) mentioned that the durian aroma comes mainly from the sulfur compounds, which gives it the characteristic pungent smell; as well as esters, which contributes to the fruity character.\nThe data below is from the work done by Chin et al. (2007). A total of 39 volatiles were identified in three varieties of durian: D2, D24 and D101. In the paper, PCA was carried out to distinguish between the three varieties.\nObjective\nData visualization for top 10 volatile compounds (by concentration) in three different durian varieties: D2, D24 and D101\nLoad packages\n\n\nlibrary(tidyverse)\nlibrary(janitor)\n\n\n\nImport\nThe file was saved on my working directory and I imported it into R\n\n\ndurian <- read_csv(\"Durian.csv\") %>% \n  clean_names() \n\n\n\nData visualization\n\n\nd101 <- durian %>% \n  select(-peak_no, -odor_description, - category) %>% \n  pivot_longer(cols = starts_with(\"d\"),\n               names_to = \"variety\",\n               values_to = \"concentration\") %>% \n  filter(variety == \"d101\") %>% \n  top_n(10, concentration) %>% \n  ggplot(aes(fct_reorder(compound, concentration), concentration)) +\n  geom_col(fill = \"goldenrod\") +\n  labs(x = NULL,\n       title = \"D101\",\n       x = \"Relative Concentration (ug/g)\",\n       caption = \"Chin et al, 2007\") +\n  coord_flip() +\n  theme_classic() +\n  theme(title = element_text(face = \"bold\", size = 16),\n        axis.text = element_text(size = 14))\n  \nd2 <- durian %>% \n  select(-peak_no, -odor_description, - category) %>% \n  pivot_longer(cols = starts_with(\"d\"),\n               names_to = \"variety\",\n               values_to = \"concentration\") %>% \n  filter(variety == \"d2\") %>% \n  top_n(10, concentration) %>% \n  ggplot(aes(fct_reorder(compound, concentration), concentration)) +\n  geom_col(fill = \"forestgreen\") +\n  labs(x = NULL,\n       title = \"D2\",\n       x = \"Relative Concentration (ug/g)\",\n       caption = \"Chin et al, 2007\") +\n  coord_flip() +\n  theme_classic() +\n  theme(title = element_text(face = \"bold\", size = 16),\n        axis.text = element_text(size = 14))\n\nd24 <- durian %>% \n  select(-peak_no, -odor_description, - category) %>% \n  pivot_longer(cols = starts_with(\"d\"),\n               names_to = \"variety\",\n               values_to = \"concentration\") %>% \n  filter(variety == \"d24\") %>% \n  top_n(10, concentration) %>% \n  ggplot(aes(fct_reorder(compound, concentration), concentration)) +\n  geom_col(fill = \"darkorange2\") +\n  labs(x = NULL,\n       title = \"D24\",\n       x = \"Relative Concentration (ug/g)\",\n       caption = \"Chin et al, 2007\") +\n  coord_flip() +\n  theme_classic() +\n  theme(title = element_text(face = \"bold\", size = 16),\n        axis.text = element_text(size = 14))\n\n\ngridExtra::grid.arrange(d101, d2, d24, ncol = 3,\n                        top = \"Comparison of top volatiles found in different durian varieties\")\n\n\n\ndurian %>% \n  select(-peak_no, -odor_description) %>% \n  pivot_longer(cols = starts_with(\"d\"),\n               names_to = \"variety\",\n               values_to = \"concentration\") %>% \n  group_by(category, variety) %>% \n  summarize(sum_conc = sum(concentration)) %>% \n  arrange(desc(sum_conc))\n\n\n# A tibble: 9 x 3\n# Groups:   category [3]\n  category         variety sum_conc\n  <chr>            <chr>      <dbl>\n1 Ester            d2         54.7 \n2 Ester            d101       54.6 \n3 Sulfur-compounds d24        47.4 \n4 Sulfur-compounds d2         46.5 \n5 Sulfur-compounds d101       36.5 \n6 Ester            d24        30.5 \n7 Alcohol          d2          1.09\n8 Alcohol          d101        0.72\n9 Alcohol          d24         0.56\n\nInterpretation\nFrom the plot above, half of the top ten volatile compounds in D24 were sulfur-containing compounds, and the most abundant volatile was diethyl disulfide (18.76 ug/g). The odor description for diethyl disulfide is “Sulfury, roasty, cabbage-like odor”.\nFor D101, the top two most abundant volatile compounds were esters: ethyl 2-methylbutanoate (21.89 ug/g) (poweful green, fruity, apple-like odor) and propyl 2-methylbutanoate (12.67 ug/g), followed by sulfur compounds diethyl disulfide (12.42ug/g) and diethyl trisulfide (5.97ug/g).\nFor D2, ethyl 2-methylbutanoate (29.68 ug/g) was relatively higher than in D101.\nIf we look at the total concentration of esters and sulfur compounds, D24 has the highest concentration of sulfur compounds (in line with the plot above). Comparing D2 and D101, the concentration of esters is about the same, but D2 has higher concentration of sulfur-containing compounds than D101. According to Takeoka et al. (1995), branched chain esters have lower odor thresholds than their straight chain counterparts. It appeared that D101, with slightly lower concentration of sulfur-compounds, would be perceived as more fruity. However, the authors found that D2 was perceived to have a stronger sweet and fruity odor; and that D101 was perceived to have a well-balanced aroma. I’m not quite sure why, I guess I would need to taste in person to find out!\nPCA\nI attempted to do PCA with the data provided, but it was a bit silly as n = 3, as I did not have the raw data with me. In addition, the assumptions for KMO and Bartlett’s tests were not met.\nDue to the very small number of observations, I ran into this error: Error in comps[, 1:object$num_comp, drop = FALSE] : subscript out of bounds\nAfter specifying that num_comp = 3, I did not receive this error message again.\nThe script below shows my attempt to reproduce the PCA variable loadings plot. I managed to get the same plot as the authors, so probably if I have raw data with me, that would be great. Note that I did not show the scree plot, eigenvalues and variance explained plot, as n=3 is really very small and PCA should not even be conducted. Nevertheless, it was an exercise in attempting to understand the conclusions drawn by the authors.\n\n\n# PACKAGES ####\nlibrary(pacman)\np_load(tidyverse, janitor, skimr, psych, tidymodels, learntidymodels)\n\n# IMPORT ####\n\ndurian <- read_csv(\"Durian.csv\") %>% \n  clean_names() %>% \n  mutate(peak_no_2 = paste( \"peak\", peak_no, sep = \"_\")) %>% \n  select(-peak_no) %>% \n  rename(peak_no = peak_no_2) %>% \n  select(peak_no, everything())\n\nglimpse(durian)\n\n\nRows: 39\nColumns: 7\n$ peak_no          <chr> \"peak_3\", \"peak_4\", \"peak_7\", \"peak_8\", \"p…\n$ compound         <chr> \"Ethyl acetate\", \"Methyl propanoate\", \"Eth…\n$ category         <chr> \"Ester\", \"Ester\", \"Ester\", \"Ester\", \"Ester…\n$ d101             <dbl> 0.28, 0.97, 3.11, 0.46, 0.19, 0.30, 4.07, …\n$ d2               <dbl> 0.61, 0.88, 1.85, 0.51, 0.09, 0.45, 2.33, …\n$ d24              <dbl> 0.93, 0.71, 2.53, 0.52, 0.56, 0.00, 2.29, …\n$ odor_description <chr> \"Pleasant, ethereal, fruity, brandy-like o…\n\n# so that can pivot longer later\n# durian$d101 <- as.character(durian$d101)\n# durian$d2 <- as.character(durian$d2)\ndurian$d24 <- as.numeric(durian$d24)\n\n# TRANSFORM #####\n\ndurian_reshape <- durian %>% \n  \n  # remove unnecessary columns\n  select(-category, -odor_description, -compound) %>% \n  # pivot longer for variety\n  pivot_longer(cols = starts_with(\"d\"),\n               names_to = \"variety\",\n               values_to = \"concentration\") %>% \n  \n  pivot_wider(names_from = peak_no,\n              values_from = concentration) %>% \n  \n  clean_names() %>% \n\n  # pivot wider for compound names as (X)/Features\n  dplyr::group_by(variety) %>% \n  dplyr::summarize_all(sum, na.rm = T)\n\n  \nglimpse(durian_reshape)  # 40 variables: 1Y and 39 X\n\n\nRows: 3\nColumns: 40\n$ variety <chr> \"d101\", \"d2\", \"d24\"\n$ peak_3  <dbl> 0.28, 0.61, 0.93\n$ peak_4  <dbl> 0.97, 0.88, 0.71\n$ peak_7  <dbl> 3.11, 1.85, 2.53\n$ peak_8  <dbl> 0.46, 0.51, 0.52\n$ peak_9  <dbl> 0.19, 0.09, 0.56\n$ peak_10 <dbl> 0.30, 0.45, 0.00\n$ peak_11 <dbl> 4.07, 2.33, 2.29\n$ peak_12 <dbl> 0.85, 2.22, 0.04\n$ peak_13 <dbl> 4.63, 1.74, 3.81\n$ peak_14 <dbl> 21.89, 29.68, 4.97\n$ peak_15 <dbl> 0.32, 0.22, 0.22\n$ peak_17 <dbl> 0.95, 0.63, 0.95\n$ peak_18 <dbl> 12.67, 4.77, 11.30\n$ peak_19 <dbl> 0.19, 0.00, 0.38\n$ peak_20 <dbl> 0.00, 0.14, 0.00\n$ peak_22 <dbl> 0.32, 1.70, 0.00\n$ peak_23 <dbl> 0.73, 0.00, 0.60\n$ peak_26 <dbl> 1.17, 5.52, 0.00\n$ peak_28 <dbl> 0.58, 0.45, 0.31\n$ peak_29 <dbl> 0.15, 0.25, 0.15\n$ peak_32 <dbl> 0.22, 0.10, 0.00\n$ peak_33 <dbl> 0.55, 0.55, 0.26\n$ peak_6  <dbl> 0.72, 1.09, 0.56\n$ peak_1  <dbl> 5.48, 4.26, 3.55\n$ peak_2  <dbl> 5.00, 2.72, 5.77\n$ peak_5  <dbl> 0.27, 0.00, 0.13\n$ peak_16 <dbl> 0.34, 0.00, 0.31\n$ peak_21 <dbl> 0.09, 0.06, 0.32\n$ peak_24 <dbl> 12.42, 15.85, 18.76\n$ peak_25 <dbl> 0.00, 0.00, 0.33\n$ peak_27 <dbl> 3.63, 3.35, 9.04\n$ peak_30 <dbl> 0.66, 0.14, 0.66\n$ peak_31 <dbl> 0.20, 0.11, 1.03\n$ peak_34 <dbl> 5.97, 14.68, 2.52\n$ peak_35 <dbl> 0.86, 1.73, 0.68\n$ peak_36 <dbl> 0.47, 1.46, 1.74\n$ peak_37 <dbl> 0.59, 1.47, 1.71\n$ peak_38 <dbl> 0.12, 0.16, 0.11\n$ peak_39 <dbl> 0.42, 0.49, 0.71\n\ndurian_reshape$variety <- factor(durian_reshape$variety)\n\n# EDA\nskim(durian_reshape)\n\n\nTable 1: Data summary\nName\ndurian_reshape\nNumber of rows\n3\nNumber of columns\n40\n_______________________\n\nColumn type frequency:\n\nfactor\n1\nnumeric\n39\n________________________\n\nGroup variables\nNone\nVariable type: factor\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\nvariety\n0\n1\nFALSE\n3\nd10: 1, d2: 1, d24: 1\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\npeak_3\n0\n1\n0.61\n0.33\n0.28\n0.44\n0.61\n0.77\n0.93\n▇▁▇▁▇\npeak_4\n0\n1\n0.85\n0.13\n0.71\n0.79\n0.88\n0.92\n0.97\n▇▁▁▇▇\npeak_7\n0\n1\n2.50\n0.63\n1.85\n2.19\n2.53\n2.82\n3.11\n▇▁▇▁▇\npeak_8\n0\n1\n0.50\n0.03\n0.46\n0.48\n0.51\n0.52\n0.52\n▃▁▁▁▇\npeak_9\n0\n1\n0.28\n0.25\n0.09\n0.14\n0.19\n0.38\n0.56\n▇▇▁▁▇\npeak_10\n0\n1\n0.25\n0.23\n0.00\n0.15\n0.30\n0.38\n0.45\n▇▁▁▇▇\npeak_11\n0\n1\n2.90\n1.02\n2.29\n2.31\n2.33\n3.20\n4.07\n▇▁▁▁▃\npeak_12\n0\n1\n1.04\n1.10\n0.04\n0.44\n0.85\n1.54\n2.22\n▇▇▁▁▇\npeak_13\n0\n1\n3.39\n1.49\n1.74\n2.78\n3.81\n4.22\n4.63\n▇▁▁▇▇\npeak_14\n0\n1\n18.85\n12.63\n4.97\n13.43\n21.89\n25.78\n29.68\n▇▁▁▇▇\npeak_15\n0\n1\n0.25\n0.06\n0.22\n0.22\n0.22\n0.27\n0.32\n▇▁▁▁▃\npeak_17\n0\n1\n0.84\n0.18\n0.63\n0.79\n0.95\n0.95\n0.95\n▃▁▁▁▇\npeak_18\n0\n1\n9.58\n4.22\n4.77\n8.04\n11.30\n11.98\n12.67\n▃▁▁▁▇\npeak_19\n0\n1\n0.19\n0.19\n0.00\n0.10\n0.19\n0.29\n0.38\n▇▁▇▁▇\npeak_20\n0\n1\n0.05\n0.08\n0.00\n0.00\n0.00\n0.07\n0.14\n▇▁▁▁▃\npeak_22\n0\n1\n0.67\n0.90\n0.00\n0.16\n0.32\n1.01\n1.70\n▇▁▁▁▃\npeak_23\n0\n1\n0.44\n0.39\n0.00\n0.30\n0.60\n0.66\n0.73\n▃▁▁▁▇\npeak_26\n0\n1\n2.23\n2.91\n0.00\n0.58\n1.17\n3.34\n5.52\n▇▇▁▁▇\npeak_28\n0\n1\n0.45\n0.14\n0.31\n0.38\n0.45\n0.52\n0.58\n▇▁▇▁▇\npeak_29\n0\n1\n0.18\n0.06\n0.15\n0.15\n0.15\n0.20\n0.25\n▇▁▁▁▃\npeak_32\n0\n1\n0.11\n0.11\n0.00\n0.05\n0.10\n0.16\n0.22\n▇▁▇▁▇\npeak_33\n0\n1\n0.45\n0.17\n0.26\n0.41\n0.55\n0.55\n0.55\n▃▁▁▁▇\npeak_6\n0\n1\n0.79\n0.27\n0.56\n0.64\n0.72\n0.90\n1.09\n▇▇▁▁▇\npeak_1\n0\n1\n4.43\n0.98\n3.55\n3.90\n4.26\n4.87\n5.48\n▇▇▁▁▇\npeak_2\n0\n1\n4.50\n1.59\n2.72\n3.86\n5.00\n5.38\n5.77\n▇▁▁▇▇\npeak_5\n0\n1\n0.13\n0.14\n0.00\n0.06\n0.13\n0.20\n0.27\n▇▁▇▁▇\npeak_16\n0\n1\n0.22\n0.19\n0.00\n0.16\n0.31\n0.32\n0.34\n▃▁▁▁▇\npeak_21\n0\n1\n0.16\n0.14\n0.06\n0.07\n0.09\n0.21\n0.32\n▇▁▁▁▃\npeak_24\n0\n1\n15.68\n3.17\n12.42\n14.13\n15.85\n17.30\n18.76\n▇▁▇▁▇\npeak_25\n0\n1\n0.11\n0.19\n0.00\n0.00\n0.00\n0.16\n0.33\n▇▁▁▁▃\npeak_27\n0\n1\n5.34\n3.21\n3.35\n3.49\n3.63\n6.33\n9.04\n▇▁▁▁▃\npeak_30\n0\n1\n0.49\n0.30\n0.14\n0.40\n0.66\n0.66\n0.66\n▃▁▁▁▇\npeak_31\n0\n1\n0.45\n0.51\n0.11\n0.16\n0.20\n0.62\n1.03\n▇▁▁▁▃\npeak_34\n0\n1\n7.72\n6.27\n2.52\n4.24\n5.97\n10.32\n14.68\n▇▇▁▁▇\npeak_35\n0\n1\n1.09\n0.56\n0.68\n0.77\n0.86\n1.29\n1.73\n▇▁▁▁▃\npeak_36\n0\n1\n1.22\n0.67\n0.47\n0.96\n1.46\n1.60\n1.74\n▇▁▁▇▇\npeak_37\n0\n1\n1.26\n0.59\n0.59\n1.03\n1.47\n1.59\n1.71\n▇▁▁▇▇\npeak_38\n0\n1\n0.13\n0.03\n0.11\n0.11\n0.12\n0.14\n0.16\n▇▁▁▁▃\npeak_39\n0\n1\n0.54\n0.15\n0.42\n0.45\n0.49\n0.60\n0.71\n▇▇▁▁▇\n\n# no missing values\n# should do auto-scale and means centering later\n\n# Check assumptions for EDA\n\ndurian_no_y <- durian_reshape %>% \n  dplyr::select(-variety)\n\n# KMO test\ndurian_no_y %>% \n  cor() %>% \n  KMO() # overall MSA = 0.5\n\n\nError in solve.default(r) : \n  system is computationally singular: reciprocal condition number = 2.35978e-20\nKaiser-Meyer-Olkin factor adequacy\nCall: KMO(r = .)\nOverall MSA =  0.5\nMSA for each item = \n peak_3  peak_4  peak_7  peak_8  peak_9 peak_10 peak_11 peak_12 \n    0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5 \npeak_13 peak_14 peak_15 peak_17 peak_18 peak_19 peak_20 peak_22 \n    0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5 \npeak_23 peak_26 peak_28 peak_29 peak_32 peak_33  peak_6  peak_1 \n    0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5 \n peak_2  peak_5 peak_16 peak_21 peak_24 peak_25 peak_27 peak_30 \n    0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5 \npeak_31 peak_34 peak_35 peak_36 peak_37 peak_38 peak_39 \n    0.5     0.5     0.5     0.5     0.5     0.5     0.5 \n\n# Bartlett \n\ndurian_no_y %>% \n  cor() %>% \n  cortest.bartlett(., n = 3) # p = 1, by right not suitable for PCA\n\n\n$chisq\n[1] -Inf\n\n$p.value\n[1] 1\n\n$df\n[1] 741\n\n# 3 observations - not really ok for PCA\n\n# PCA ####\nglimpse(durian_reshape)\n\n\nRows: 3\nColumns: 40\n$ variety <fct> d101, d2, d24\n$ peak_3  <dbl> 0.28, 0.61, 0.93\n$ peak_4  <dbl> 0.97, 0.88, 0.71\n$ peak_7  <dbl> 3.11, 1.85, 2.53\n$ peak_8  <dbl> 0.46, 0.51, 0.52\n$ peak_9  <dbl> 0.19, 0.09, 0.56\n$ peak_10 <dbl> 0.30, 0.45, 0.00\n$ peak_11 <dbl> 4.07, 2.33, 2.29\n$ peak_12 <dbl> 0.85, 2.22, 0.04\n$ peak_13 <dbl> 4.63, 1.74, 3.81\n$ peak_14 <dbl> 21.89, 29.68, 4.97\n$ peak_15 <dbl> 0.32, 0.22, 0.22\n$ peak_17 <dbl> 0.95, 0.63, 0.95\n$ peak_18 <dbl> 12.67, 4.77, 11.30\n$ peak_19 <dbl> 0.19, 0.00, 0.38\n$ peak_20 <dbl> 0.00, 0.14, 0.00\n$ peak_22 <dbl> 0.32, 1.70, 0.00\n$ peak_23 <dbl> 0.73, 0.00, 0.60\n$ peak_26 <dbl> 1.17, 5.52, 0.00\n$ peak_28 <dbl> 0.58, 0.45, 0.31\n$ peak_29 <dbl> 0.15, 0.25, 0.15\n$ peak_32 <dbl> 0.22, 0.10, 0.00\n$ peak_33 <dbl> 0.55, 0.55, 0.26\n$ peak_6  <dbl> 0.72, 1.09, 0.56\n$ peak_1  <dbl> 5.48, 4.26, 3.55\n$ peak_2  <dbl> 5.00, 2.72, 5.77\n$ peak_5  <dbl> 0.27, 0.00, 0.13\n$ peak_16 <dbl> 0.34, 0.00, 0.31\n$ peak_21 <dbl> 0.09, 0.06, 0.32\n$ peak_24 <dbl> 12.42, 15.85, 18.76\n$ peak_25 <dbl> 0.00, 0.00, 0.33\n$ peak_27 <dbl> 3.63, 3.35, 9.04\n$ peak_30 <dbl> 0.66, 0.14, 0.66\n$ peak_31 <dbl> 0.20, 0.11, 1.03\n$ peak_34 <dbl> 5.97, 14.68, 2.52\n$ peak_35 <dbl> 0.86, 1.73, 0.68\n$ peak_36 <dbl> 0.47, 1.46, 1.74\n$ peak_37 <dbl> 0.59, 1.47, 1.71\n$ peak_38 <dbl> 0.12, 0.16, 0.11\n$ peak_39 <dbl> 0.42, 0.49, 0.71\n\n# recipe\ndurian_recipe <- recipe(~ ., data = durian_reshape) %>% \n  update_role(variety, new_role = \"id\") %>%  \n  # step_naomit(all_predictors()) %>% \n  step_normalize(all_predictors()) %>% \n  step_pca(all_predictors(), id = \"pca\", num_comp = 3)\n\n\n# need to specify num_comp = 3 if not will have error\n# Error in comps[, 1:object$num_comp, drop = FALSE] : \n# subscript out of bounds\n\n\n# prep: estimate the required parameters from a training set\n# that can be later applied to other data sets\n# returns an updated recipe with its estimates\n\ndurian_prep <- prep(durian_recipe)\n\ntidy_pca_loadings <- durian_prep %>% \n  tidy(id = \"pca\")\n\n\n# bake\n\ndurian_bake <- bake(durian_prep, durian_reshape)\n\n\n# plot loadings for top 8\n\nloadings_top_8 <- tidy_pca_loadings %>% \n  group_by(component) %>% \n  top_n(8, abs(value)) %>% \n  ungroup() %>% \n  mutate(terms = tidytext::reorder_within(terms, abs(value), component)) %>% \n  ggplot(aes(abs(value), terms, fill = value>0)) +\n  geom_col() +\n  facet_wrap(~component, scales = \"free_y\") +\n  tidytext::scale_y_reordered() +\n  ggthemes::scale_fill_few() +\n  theme_minimal()\n\n\njuice(durian_prep) %>% \n  ggplot(aes(PC1, PC2, label = variety)) +\n  geom_point(aes(col = variety), show.legend = F) +\n  geom_text() +\n  labs(x = \"PC1\",\n       y = \"PC2\") +\n  theme_classic()\n\n\n\n# loadings only\n\n# define arrow style\narrow_style <- arrow(angle = 30,\n                     length = unit(0.02, \"inches\"),\n                     type = \"closed\")\n\n# get pca loadings into wider format\npca_loadings_wider <- tidy_pca_loadings%>% \n  pivot_wider(names_from = component, id_cols = terms)\n\n\npca_loadings_only <- pca_loadings_wider %>% \n  ggplot(aes(x = PC1, y = PC2)) +\n  geom_segment(aes(xend = PC1, yend = PC2),\n               x = 0, \n               y = 0,\n               arrow = arrow_style) +\n  ggrepel::geom_text_repel(aes(x = PC1, y = PC2, label = terms),\n                           hjust = 0, \n                           vjust = 1,\n                           size = 4,\n                           color = \"deepskyblue4\") +\n  labs(title = \"Loadings on PCs 1 and 2 for normalized data\") +\n  theme_classic()\n\n\n\n# check raw data\n\n# PC 1\npc1_raw <- durian %>% \n  filter(peak_no %in% c(\"peak_19\",\n                        \"peak_12\",\n                        \"peak_6\",\n                        \"peak_34\",\n                        \"peak_2\",\n                        \"peak_10\",\n                        \"peak_14\",\n                        \"peak_26\"))\n\n\n\n# PC 2\npc2_raw <- durian %>% \n  filter(peak_no %in% c(\"peak_11\",\n                        \"peak_15\",\n                        \"peak_8\",\n                        \"peak_37\",\n                        \"peak_36\",\n                        \"peak_1\",\n                        \"peak_32\",\n                        \"peak_24\"))\n\n\npc1_raw %>% arrange(peak_no)\n\n\n# A tibble: 8 x 7\n  peak_no compound    category   d101    d2   d24 odor_description    \n  <chr>   <chr>       <chr>     <dbl> <dbl> <dbl> <chr>               \n1 peak_10 Methyl but… Ester      0.3   0.45  0    Apple-like odor     \n2 peak_12 Ethyl buta… Ester      0.85  2.22  0.04 Fruity odor with pi…\n3 peak_14 Ethyl 2-me… Ester     21.9  29.7   4.97 Powerful green, fru…\n4 peak_19 Propyl 3-m… Ester      0.19  0     0.38 Fruity odor         \n5 peak_2  Propanethi… Sulfur-c…  5     2.72  5.77 Cabbage, sweet onio…\n6 peak_26 Ethyl hexa… Ester      1.17  5.52  0    Powerful fruity odo…\n7 peak_34 Diethyl tr… Sulfur-c…  5.97 14.7   2.52 Sweet alliaceous od…\n8 peak_6  Ethanol     Alcohol    0.72  1.09  0.56 <NA>                \n\npc2_raw %>%  arrange(peak_no)\n\n\n# A tibble: 8 x 7\n  peak_no compound      category   d101    d2   d24 odor_description  \n  <chr>   <chr>         <chr>     <dbl> <dbl> <dbl> <chr>             \n1 peak_1  Ethanethiol   Sulfur-c…  5.48  4.26  3.55 Onion, rubber odor\n2 peak_11 Methyl 2-but… Ester      4.07  2.33  2.29 Sweet fruity, app…\n3 peak_15 Ethyl 3-meth… Ester      0.32  0.22  0.22 Fruity odor remin…\n4 peak_24 Diethyl disu… Sulfur-c… 12.4  15.8  18.8  Sulfury, roasty, …\n5 peak_32 Methyl octan… Ester      0.22  0.1   0    Powerful winey, f…\n6 peak_36 3,5-dimethyl… Sulfur-c…  0.47  1.46  1.74 Sulfury, heavy, c…\n7 peak_37 3,5-dimethyl… Sulfur-c…  0.59  1.47  1.71 Sulfury, onion od…\n8 peak_8  Ethyl 2-meth… Ester      0.46  0.51  0.52 Fruity aromatic o…\n\npca_loadings_only\n\n\n\nloadings_top_8\n\n\n\n\nLearning pointers\nI feel that data visualization is a very important data exploratory tool to better understand your data. After data visualization, PCA can be performed to further explore your data and uncover latent structures. Together with the insights from earlier visualizations, the findings of PCA could be better interpreted.\nThe number of observations should not be so small until it is a bit meaningless to carry out PCA. This, was due to me carrying out analysis on aggregated data. I would need to remember to carry out more replicates if I am doing this experiment in the lab.\nWhat I like about the paper was that there was proper documentation on how extraction efficiency was optimised through sample size, vial size, the use of salting out, as well as equilibration time. The use of salting out is rather controversial as salt alters the equilibrium space between SPME fiber coatings and headspace. The results with and without addition of salt should always be compared to understand the effect of salt addition.\nIn addition, internal standard was used as a semi-quantitative analysis for relative concentration of volatile compounds. This would be better than just comparing percentage area of compounds because it gives the concentration in “absolute” value. However, it is still a semi-quantitative method as the IS cannot correct for differences in ionization during analysis, but it is better than nothing.\nFlavor analysis is not straightforward as numbers used to describe concentration do not indicate odor threshold and intensity perceived. They also do not descripe the type of odor. I wonder if text analysis could be applied to odor descriptions in flavor analysis? Odor threshold is further influenced by chemical structure, and extraction efficiency is also affected by sample matrix and volatility of compound when SPME is used as extraction. SPME offers a snapshot of flavor of food, but it would be more robust to compare against other extraction techniques as well. The ideal extraction method should not introduce artefacts (high temperature extraction, use of solvents etc), and requires high-end techniques. Alas, not every lab is that well-equipped. However, we should always make sure that our data is “clean,” so that our insights are factually correct and not contaminated by errors in extraction. The most advanced data analytics cannot correct for erroneous data, and any further analysis on such data carries no meaning.\n\n\n\nChin, S. T., S. A. H. Nazimah, S. Y. Quek, Y. B. Che Man, R. Abdul Rahman, and D. Mat Hashim. 2007. “Analysis of Volatile Compounds from Malaysian Durians (Durio Zibethinus) Using Headspace SPME Coupled to Fast GC-MS.” Journal of Food Composition and Analysis 20 (1): 31–44. https://doi.org/10.1016/j.jfca.2006.04.011.\n\n\nTakeoka, Gary R., Ron G. Buttery, Jean G. Turnbaugh, and Mabry Benson. 1995. “Odor Thresholds of Various Branched Esters.” LWT - Food Science and Technology 28 (1): 153–56. https://doi.org/10.1016/S0023-6438(95)80028-X.\n\n\nTeh, Bin Tean, Kevin Lim, Chern Han Yong, Cedric Chuan Young Ng, Sushma Ramesh Rao, Vikneswari Rajasegaran, Weng Khong Lim, et al. 2017. “The Draft Genome of Tropical Fruit Durian ( Durio Zibethinus ).” Nature Genetics 49 (11): 1633–41. https://doi.org/10.1038/ng.3972.\n\n\n\n\n",
    "preview": "posts/20210216_durian volatiles/Durian-Volatiles_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2021-02-16T23:53:30+08:00",
    "input_file": {},
    "preview_width": 2304,
    "preview_height": 1152
  },
  {
    "path": "posts/20210209_tidy_tuesday_coffee_ratings/",
    "title": "Tidy Tuesday on Coffee Ratings Dataset",
    "description": "Exploratory Data Analysis on Coffee Ratings",
    "author": [
      {
        "name": "lruolin",
        "url": {}
      }
    ],
    "date": "2021-02-09",
    "categories": [],
    "contents": "\nObjective\nTo practice data transformation and visualization on a tidytuesday dataset that is relatable to food (since I am a food science graduate).\nThe main areas that I will focus on would be the scoring differences between types of coffee (Arabica vs Robusta), processing methods (Wet vs Dry), country of origin/companies (top 6 by score), as well as varieties (top 6 by count).\nLoad packages\n\n\nlibrary(pacman)\np_load(tidyverse,skimr,tidytuesdayR, ggthemes, GGally, broom)\n\n\n\nImport\n\n\ntuesdata <- tidytuesdayR::tt_load(2020, week = 28)\n\n\n\n    Downloading file 1 of 1: `coffee_ratings.csv`\n\ncoffee_ratings <- tuesdata$coffee_ratings\n\n\n\nUnderstanding the data\nSkimming the data using the skimr package.\n\n\nskim(coffee_ratings)\n\n\nTable 1: Data summary\nName\ncoffee_ratings\nNumber of rows\n1339\nNumber of columns\n43\n_______________________\n\nColumn type frequency:\n\ncharacter\n24\nnumeric\n19\n________________________\n\nGroup variables\nNone\nVariable type: character\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\nspecies\n0\n1.00\n7\n7\n0\n2\n0\nowner\n7\n0.99\n3\n50\n0\n315\n0\ncountry_of_origin\n1\n1.00\n4\n28\n0\n36\n0\nfarm_name\n359\n0.73\n1\n73\n0\n571\n0\nlot_number\n1063\n0.21\n1\n71\n0\n227\n0\nmill\n315\n0.76\n1\n77\n0\n460\n0\nico_number\n151\n0.89\n1\n40\n0\n847\n0\ncompany\n209\n0.84\n3\n73\n0\n281\n0\naltitude\n226\n0.83\n1\n41\n0\n396\n0\nregion\n59\n0.96\n2\n76\n0\n356\n0\nproducer\n231\n0.83\n1\n100\n0\n691\n0\nbag_weight\n0\n1.00\n1\n8\n0\n56\n0\nin_country_partner\n0\n1.00\n7\n85\n0\n27\n0\nharvest_year\n47\n0.96\n3\n24\n0\n46\n0\ngrading_date\n0\n1.00\n13\n20\n0\n567\n0\nowner_1\n7\n0.99\n3\n50\n0\n319\n0\nvariety\n226\n0.83\n4\n21\n0\n29\n0\nprocessing_method\n170\n0.87\n5\n25\n0\n5\n0\ncolor\n218\n0.84\n4\n12\n0\n4\n0\nexpiration\n0\n1.00\n13\n20\n0\n566\n0\ncertification_body\n0\n1.00\n7\n85\n0\n26\n0\ncertification_address\n0\n1.00\n40\n40\n0\n32\n0\ncertification_contact\n0\n1.00\n40\n40\n0\n29\n0\nunit_of_measurement\n0\n1.00\n1\n2\n0\n2\n0\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\ntotal_cup_points\n0\n1.00\n82.09\n3.50\n0\n81.08\n82.50\n83.67\n90.58\n▁▁▁▁▇\nnumber_of_bags\n0\n1.00\n154.18\n129.99\n0\n14.00\n175.00\n275.00\n1062.00\n▇▇▁▁▁\naroma\n0\n1.00\n7.57\n0.38\n0\n7.42\n7.58\n7.75\n8.75\n▁▁▁▁▇\nflavor\n0\n1.00\n7.52\n0.40\n0\n7.33\n7.58\n7.75\n8.83\n▁▁▁▁▇\naftertaste\n0\n1.00\n7.40\n0.40\n0\n7.25\n7.42\n7.58\n8.67\n▁▁▁▁▇\nacidity\n0\n1.00\n7.54\n0.38\n0\n7.33\n7.58\n7.75\n8.75\n▁▁▁▁▇\nbody\n0\n1.00\n7.52\n0.37\n0\n7.33\n7.50\n7.67\n8.58\n▁▁▁▁▇\nbalance\n0\n1.00\n7.52\n0.41\n0\n7.33\n7.50\n7.75\n8.75\n▁▁▁▁▇\nuniformity\n0\n1.00\n9.83\n0.55\n0\n10.00\n10.00\n10.00\n10.00\n▁▁▁▁▇\nclean_cup\n0\n1.00\n9.84\n0.76\n0\n10.00\n10.00\n10.00\n10.00\n▁▁▁▁▇\nsweetness\n0\n1.00\n9.86\n0.62\n0\n10.00\n10.00\n10.00\n10.00\n▁▁▁▁▇\ncupper_points\n0\n1.00\n7.50\n0.47\n0\n7.25\n7.50\n7.75\n10.00\n▁▁▁▇▁\nmoisture\n0\n1.00\n0.09\n0.05\n0\n0.09\n0.11\n0.12\n0.28\n▃▇▅▁▁\ncategory_one_defects\n0\n1.00\n0.48\n2.55\n0\n0.00\n0.00\n0.00\n63.00\n▇▁▁▁▁\nquakers\n1\n1.00\n0.17\n0.83\n0\n0.00\n0.00\n0.00\n11.00\n▇▁▁▁▁\ncategory_two_defects\n0\n1.00\n3.56\n5.31\n0\n0.00\n2.00\n4.00\n55.00\n▇▁▁▁▁\naltitude_low_meters\n230\n0.83\n1750.71\n8669.44\n1\n1100.00\n1310.64\n1600.00\n190164.00\n▇▁▁▁▁\naltitude_high_meters\n230\n0.83\n1799.35\n8668.81\n1\n1100.00\n1350.00\n1650.00\n190164.00\n▇▁▁▁▁\naltitude_mean_meters\n230\n0.83\n1775.03\n8668.63\n1\n1100.00\n1310.64\n1600.00\n190164.00\n▇▁▁▁▁\n\nThis is an incomplete dataset. I am not familiar with all the terms, such as ICO number, altitude, certification details.\nTo address my focal questions, I would need to take note that there are missing values in:\ncountry of origin\nvariety\nprocessing method\nThe distribution for scoring criteria is quite right-skewed. The total cup points is also very right skewed, most of the coffee graded are probably good coffee, so this may not be a representative dataset since it only contains information on above average coffee, but does not show data for average and sub-par coffee.\nSpecies: Arabica vs Robusta\n\n\ncoffee_ratings %>% \n  select(species) %>% \n  count(species) %>% # equivalent to df %>% group_by(a, b) %>% summarise(n = n()).\n  mutate(percentage = n/sum(n)*100) %>%  # need not group by first\n  ggplot(aes(species,percentage)) +\n  geom_col(aes(fill = species)) +\n  scale_fill_few() + # ggthemes: Color scales from Few's \"Practical Rules for Using Color in Charts\"\n  labs(title = \"Distribution of Arabica and Robusta coffe\",\n       subtitle = \"Most of the coffee graded are Arabica coffee\",\n       x = \"Species\",\n       y = \"Percentage of samples\",\n       caption = \"Source: Coffee Quality Institute\") +\n  theme_clean()\n\n\n\n\nEven though there is very little representation from Robusta coffee, which is considered to be a more inferior type, out of curiosity and for data exploratory purposes, I will look at the averate total cup score. Personally, I prefer the Robusta type of coffee unique to Singapore and Malaysia because of the way coffee beans are fried with butter and sugar, which gives it a unique aromatic taste.\n\n\ncoffee_ratings %>% \n  select(species,total_cup_points) %>% \n  group_by(species) %>% \n  summarise(mean = mean(total_cup_points)) %>% \n  ggplot(aes(x = species, y = mean, label = round(mean,1))) +\n  geom_col(aes(fill = species)) +\n  geom_text(aes(label = round(mean,1)), vjust = -0.5) +\n  scale_fill_few() +\n  labs(title = \"Mean Total Cup Points for Arabica and Robusta\",\n       subtitle = \"Arabica has higher mean score than Robusta\",\n       caption  = \"Source: Coffee Quality Institute\") +\n  ylim(0,100) +\n  theme_clean()\n\n\n\n\nProcessing method\nTo compare like with like, I will look the effect of processing methods on scores for Arabica coffee only.\n\n\narabica <- coffee_ratings %>% \n  filter(species == \"Arabica\")\n\n\n\nThe plot below shows what the commonly used processing methods are.\n\n\narabica %>% \n  filter(!is.na(processing_method)) %>% \n  count(processing_method) %>% \n  mutate(percentage = n/sum(n)*100) %>% \n  arrange(desc(percentage)) %>% \n  ggplot(aes(reorder(processing_method, percentage),percentage),\n         label = round(percentage,1)) +\n  geom_col(aes(fill = processing_method), width = 0.75) +\n  scale_color_few() +\n  geom_text(aes(label = round(percentage,1), hjust = -0.15)) +\n  labs(title = \"Distribution by Processing Method\",\n       subtitle = \"Most of the Arabica Coffee were either Wet or Dry Processed\",\n       caption = \"Source: Coffee Quality Institute\",\n       x = NULL) +\n  coord_flip() +\n  theme_clean() +\n  theme(legend.position = \"none\")\n\n\n\n\nI did some reading online (see Reference section below), and found that there were three main types of processing methods:\nWet/Washed: Most specialty coffees are washed, and the fruit flesh is removed from the bean before the beans are dried. There should be enough inherently present natural sugars in the bean so that sweetness will not be compromised.\nDry/Natural: The fruit remains on the bean and dries undisturbed. This is considered to be a lower quality method that may lead to inconsistent flavors due to unripe fruit drying and turning brown alongside ripe fruits.\nHoney: Often has a rounded acidity than washed coffees, with intense sweetness and complex mouthfeel.\nOthers: May include anaerobic processing, carbonic maceration etc.\nFor the purpose of comparing the scores across processing methods, I will just look at Wet vs Dry processing.\nHowever, it is important to compare like with like for different processing methods. What does the total cup points mean? The total cup points could be used as a classifier:\n95 - 100: Super Premium Specialty\n90 - 94: Premium Specialty\n85 - 89: Specialty\n80 - 84: Premium\n75 - 79: Usual Good Quality\n70 - 74: Average Quality\n60 - 70: Exchange grade\n50 - 60: Commercial grade\nI will add in the class into the dataset to compare effect of processing method in the class with the most datapoints.\nEDA on total cup points\n\n\nsensory <- coffee_ratings %>% \n  select(total_cup_points, species, country_of_origin,\n         processing_method:category_two_defects)\n\nsensory %>% \n  ggplot(aes(total_cup_points)) +\n  geom_histogram(fill = \"chocolate4\") +\n  theme_few()\n\n\n\nmin(sensory$total_cup_points)  # 0 : has missing values\n\n\n[1] 0\n\ntable(sensory$total_cup_points) # 1 missing value, lowest is 59.83\n\n\n\n    0 59.83 63.08 67.92 68.33 69.17 69.33 70.67 70.75    71 71.08 \n    1     1     1     1     1     2     1     1     1     1     1 \n71.75 72.33 72.58 72.83 72.92 73.42  73.5 73.67 73.75 73.83    74 \n    1     1     1     1     1     1     1     1     1     1     1 \n74.33 74.42 74.67 74.75 74.83 74.92    75 75.08 75.17  75.5 75.58 \n    2     1     1     2     1     1     1     1     3     1     2 \n75.67 75.83    76 76.08 76.17 76.25 76.33 76.42  76.5 76.75 76.83 \n    1     1     1     1     3     1     2     1     1     1     1 \n   77 77.17 77.25 77.33 77.42  77.5 77.58 77.67 77.83 77.92    78 \n    1     2     2     3     1     1     1     1     3     3     8 \n78.08 78.17 78.25 78.33 78.42  78.5 78.58 78.67 78.75 78.83 78.92 \n    2     1     2     5     2     3     7     2     6     1     2 \n   79 79.08 79.17 79.25 79.33 79.42  79.5 79.58 79.67 79.75 79.83 \n    6     6     8     2     6     3     5     4     8    13     5 \n79.92    80 80.08 80.17 80.25 80.33 80.42  80.5 80.58 80.67 80.75 \n    9     8     8    11    11     8     7    12     9    11    12 \n80.83 80.92    81 81.08 81.17 81.25 81.33 81.42  81.5 81.58 81.67 \n    7    18    15    12    15    10    12    17    26    17    25 \n81.75 81.83 81.92    82 82.08 82.17 82.25 82.33 82.42  82.5 82.58 \n   12    26    18    21    17    21    22    29    32    23    21 \n82.67 82.75 82.83 82.92    83 83.08 83.17 83.25 83.33 83.38 83.42 \n   26    30    19    26    39    18    38    25    20     1    20 \n 83.5 83.58 83.67 83.75 83.83 83.92    84 84.08 84.13 84.17 84.25 \n   25    16    21    20    21    16    18     8     1    21    19 \n84.33 84.42  84.5 84.58 84.67 84.75 84.83 84.92    85 85.08 85.17 \n   12     8    13    14    19     5     5     9    10     8     2 \n85.25 85.33 85.42  85.5 85.58 85.75 85.83 85.92    86 86.08 86.17 \n    3     8     5     5     3     3     4     3     6     3     4 \n86.25 86.33 86.42  86.5 86.58 86.67 86.83 86.92 87.08 87.17 87.25 \n    5     1     1     1     2     1     1     2     2     2     3 \n87.33 87.42 87.58 87.83 87.92 88.08 88.25 88.42 88.67 88.75 88.83 \n    1     1     1     1     3     1     1     1     1     1     2 \n   89 89.75 89.92 90.58 \n    1     1     1     1 \n\nCreating a classification variable\n\n\nsensory_with_category <- sensory %>% \n  filter(total_cup_points != 0) %>% # remove zero score\n  mutate(classification = ifelse(total_cup_points > 95, \"Super Premium Specialty\",\n                                 ifelse(total_cup_points >90, \"Premium Specialty\",\n                                        ifelse(total_cup_points >85, \"Specialty\",\n                                               ifelse(total_cup_points >80, \"Premium\",\n                                                      ifelse(total_cup_points >75, \"Usual Good Quality\",\n                                                             ifelse(total_cup_points >70, \"Average Quality\",\n                                                                    ifelse(total_cup_points >60, \"Exchange grade\",\n                                                                           \"Commercial grade\"))))))))\n\n\n\nUnderstanding the coffee with the highest score:\n\n\nsensory_with_category %>% \n  select(total_cup_points, classification) %>% \n  arrange(desc(total_cup_points))\n\n\n# A tibble: 1,338 x 2\n   total_cup_points classification   \n              <dbl> <chr>            \n 1             90.6 Premium Specialty\n 2             89.9 Specialty        \n 3             89.8 Specialty        \n 4             89   Specialty        \n 5             88.8 Specialty        \n 6             88.8 Specialty        \n 7             88.8 Specialty        \n 8             88.7 Specialty        \n 9             88.4 Specialty        \n10             88.2 Specialty        \n# … with 1,328 more rows\n\nmin(coffee_ratings$total_cup_points)\n\n\n[1] 0\n\n# which coffee had the highest score?\ncoffee_ratings %>% \n  filter(total_cup_points == max(coffee_ratings$total_cup_points)) %>% \n  t() # transpose\n\n\n                      [,1]                                      \ntotal_cup_points      \"90.58\"                                   \nspecies               \"Arabica\"                                 \nowner                 \"metad plc\"                               \ncountry_of_origin     \"Ethiopia\"                                \nfarm_name             \"metad plc\"                               \nlot_number            NA                                        \nmill                  \"metad plc\"                               \nico_number            \"2014/2015\"                               \ncompany               \"metad agricultural developmet plc\"       \naltitude              \"1950-2200\"                               \nregion                \"guji-hambela\"                            \nproducer              \"METAD PLC\"                               \nnumber_of_bags        \"300\"                                     \nbag_weight            \"60 kg\"                                   \nin_country_partner    \"METAD Agricultural Development plc\"      \nharvest_year          \"2014\"                                    \ngrading_date          \"April 4th, 2015\"                         \nowner_1               \"metad plc\"                               \nvariety               NA                                        \nprocessing_method     \"Washed / Wet\"                            \naroma                 \"8.67\"                                    \nflavor                \"8.83\"                                    \naftertaste            \"8.67\"                                    \nacidity               \"8.75\"                                    \nbody                  \"8.5\"                                     \nbalance               \"8.42\"                                    \nuniformity            \"10\"                                      \nclean_cup             \"10\"                                      \nsweetness             \"10\"                                      \ncupper_points         \"8.75\"                                    \nmoisture              \"0.12\"                                    \ncategory_one_defects  \"0\"                                       \nquakers               \"0\"                                       \ncolor                 \"Green\"                                   \ncategory_two_defects  \"0\"                                       \nexpiration            \"April 3rd, 2016\"                         \ncertification_body    \"METAD Agricultural Development plc\"      \ncertification_address \"309fcf77415a3661ae83e027f7e5f05dad786e44\"\ncertification_contact \"19fef5a731de2db57d16da10287413f5f99bc2dd\"\nunit_of_measurement   \"m\"                                       \naltitude_low_meters   \"1950\"                                    \naltitude_high_meters  \"2200\"                                    \naltitude_mean_meters  \"2075\"                                    \n\n# which coffee had the lowest score?\ncoffee_ratings %>% \n  filter(total_cup_points == 59.83) %>% \n  t() # transpose\n\n\n                      [,1]                                      \ntotal_cup_points      \"59.83\"                                   \nspecies               \"Arabica\"                                 \nowner                 \"juan luis alvarado romero\"               \ncountry_of_origin     \"Guatemala\"                               \nfarm_name             \"finca el limon\"                          \nlot_number            NA                                        \nmill                  \"beneficio serben\"                        \nico_number            \"11/853/165\"                              \ncompany               \"unicafe\"                                 \naltitude              \"4650\"                                    \nregion                \"nuevo oriente\"                           \nproducer              \"WILLIAM ESTUARDO MARTINEZ PACHECO\"       \nnumber_of_bags        \"275\"                                     \nbag_weight            \"1 kg\"                                    \nin_country_partner    \"Asociacion Nacional Del Café\"            \nharvest_year          \"2012\"                                    \ngrading_date          \"May 24th, 2012\"                          \nowner_1               \"Juan Luis Alvarado Romero\"               \nvariety               \"Catuai\"                                  \nprocessing_method     \"Washed / Wet\"                            \naroma                 \"7.5\"                                     \nflavor                \"6.67\"                                    \naftertaste            \"6.67\"                                    \nacidity               \"7.67\"                                    \nbody                  \"7.33\"                                    \nbalance               \"6.67\"                                    \nuniformity            \"8\"                                       \nclean_cup             \"1.33\"                                    \nsweetness             \"1.33\"                                    \ncupper_points         \"6.67\"                                    \nmoisture              \"0.1\"                                     \ncategory_one_defects  \"0\"                                       \nquakers               \"0\"                                       \ncolor                 \"Green\"                                   \ncategory_two_defects  \"4\"                                       \nexpiration            \"May 24th, 2013\"                          \ncertification_body    \"Asociacion Nacional Del Café\"            \ncertification_address \"b1f20fe3a819fd6b2ee0eb8fdc3da256604f1e53\"\ncertification_contact \"724f04ad10ed31dbb9d260f0dfd221ba48be8a95\"\nunit_of_measurement   \"ft\"                                      \naltitude_low_meters   \"1417.32\"                                 \naltitude_high_meters  \"1417.32\"                                 \naltitude_mean_meters  \"1417.32\"                                 \n\n# min score is actually 0, which is a missing datapoint.\n\n\n\n\n\n# distribution of types of coffee\nsensory_with_category %>% \n  filter(species == \"Arabica\",\n         processing_method %in% c(\"Natural / Dry\", \"Washed / Wet\")) %>% \n  count(classification, processing_method) %>% \n  ggplot(aes(fct_reorder(classification, n), n, label = n)) + \n  geom_col(aes(fill = classification)) +\n  scale_color_few() +\n  labs(title = \"Distribution of types of Arabica coffees, by processing method\",\n       subtitle = \"Most of the premium coffee (with cup scores 80 - 84) are processed by Washed/Wet method.\",\n       caption = \"Source: Coffee Quality Institute\") +\n  facet_grid(processing_method ~. ) +\n  theme_clean() +\n  coord_flip() +\n  theme(legend.position = \"none\")\n\n\n\n\nThe Premium category has the most number of datapoints, and I will focus on this category for analysis.\n\n\nplot_sensory_total_boxplot <- sensory_with_category %>% \n  filter(classification == \"Premium\",\n         species == \"Arabica\",\n         processing_method %in% c(\"Natural / Dry\", \"Washed / Wet\")) %>% \n  mutate(processing_mtd_fct = ifelse(processing_method == c(\"Natural / Dry\"), \"Dry\",\n                                     \"Wet\")) %>% \n  select(total_cup_points, processing_mtd_fct) %>% \n  ggplot(aes(x = processing_mtd_fct, y = total_cup_points)) +\n  geom_boxplot(aes(col = processing_mtd_fct),notch = T) +\n  stat_summary(fun.data = \"mean_cl_normal\",\n           geom = \"errorbar\",\n           fun.args = (conf.int = 0.95),\n           color = \"forestgreen\") +\n  geom_jitter(aes(col = processing_mtd_fct), alpha = 0.3) +\n  scale_color_manual(values = c(\"Dry\" = \"chocolate4\",\n                                \"Wet\" = \"cadetblue4\")) +\n  labs(title = \"Comparison of Mean Total Cup Points for Dry vs Wet Processing in Arabica Coffee\",\n       subtitle = \"The Mean Total Cup Points are very similar for both processing methods\",\n       caption = \"Source: Coffee Quality Institute\",\n       x = \"Processing Method\",\n       y = \"Total Cup Points\") +\n  theme_few() +\n  theme(legend.position = \"none\")\n\nplot_sensory_total_boxplot \n\n\n\n\n\n\nplot_sensory_boxplot <- sensory_with_category %>% \n  filter(classification == \"Premium\",\n         species == \"Arabica\",\n         processing_method %in% c(\"Natural / Dry\", \"Washed / Wet\")) %>% \n  mutate(processing_mtd_fct = ifelse(processing_method == c(\"Natural / Dry\"), \"Dry\",\n                                     \"Wet\")) %>% \n  select(-quakers, -color, - category_one_defects, \n         - category_two_defects, - processing_method) %>% \n  pivot_longer(cols = aroma:cupper_points,\n               names_to = \"parameters\",\n               values_to = \"score\") %>% \n  mutate(parameters_fct = factor(parameters,\n                                 levels = c(\"acidity\", \"aroma\", \"clean_cup\",\n                                            \"sweetness\", \"uniformity\", \"aftertaste\",\n                                            \"balance\", \"body\", \"cupper_points\", \"flavor\"\n                                 ))) %>% \n  ggplot(aes(x = processing_mtd_fct, y = score)) +\n  geom_boxplot(aes(col = processing_mtd_fct), notch = T, size = 1) +\n  geom_jitter(aes(col = processing_mtd_fct), alpha = 0.1) +\n  scale_color_manual(values = c(\"Dry\" = \"chocolate4\",\n                                \"Wet\" = \"cadetblue4\")) +\n  facet_wrap(vars(parameters_fct), scales = \"free\", ncol= 5) +\n  labs(x = NULL,\n       title = \"Comparison of mean score for Arabica coffee: Dry vs Wet Processing\",\n       subtitle = \"Wet processed coffee has higher average scores for acidity, aroma, clean_cup, sweetness, uniformity.\",\n       caption = \"Source: Coffee Quality Institute\") +\n  theme_few() +\n  theme(legend.position = \"none\")\n\nplot_sensory_boxplot\n\n\n\n\nCountry of origin/Owner\n\n\n# plot to see which countries are above/below mean rating\n\narabica_dotplot <- arabica %>% \n  filter(!is.na(country_of_origin)) %>% # 1 missing value\n  group_by(country_of_origin) %>% \n  summarise(mean_rating = mean(total_cup_points)) %>% \n  mutate(above_below_mean = as.factor(ifelse(mean_rating > mean(arabica$total_cup_points),\n                                             \"above_mean\", \"below_mean\"))) %>% \n  ggplot(aes(x = reorder(country_of_origin, mean_rating), \n             y = mean_rating, \n             col = above_below_mean,\n             label = round(mean_rating,1))) +\n  geom_point(aes(col = above_below_mean), stat = \"identity\", size = 9) +\n  scale_color_few() +\n  geom_text(col = \"black\", size = 4) +\n  geom_hline(aes(yintercept = mean(arabica$total_cup_points)), size = 2,\n             col = \"grey\")+\n  labs(title = \"Dot plot for Arabica Coffee Ratings\",\n       subtitle = \"Countries with ratings above mean values are coloured blue,\\nand countries below mean values are colored orange.\",\n       x =  \"Country of Origin\",\n       y = \"Mean Rating\",\n       caption = \"Source: Coffee Quality Institute\") +\n  coord_flip() +\n  theme_clean() +\n  theme(legend.position = \"none\",\n        axis.title = element_text(size = 16, face = \"bold\"),\n        axis.text = element_text(size = 14),\n        title = element_text(size = 20, face = \"bold\"))\n\narabica_dotplot\n\n\n\n\n\n\n# sensory scores for arabica coffee, top scorers for sensory\n\nsensory_by_country <- coffee_ratings %>% \n  filter(species == \"Arabica\",\n         !total_cup_points %in% 0,\n         !is.na(country_of_origin),\n         !is.na(owner)) %>% \n  select(country_of_origin, owner, \n         total_cup_points, aroma:cupper_points)\n\n\n\n\n\nskim(sensory_by_country)\n\n\nTable 2: Data summary\nName\nsensory_by_country\nNumber of rows\n1302\nNumber of columns\n13\n_______________________\n\nColumn type frequency:\n\ncharacter\n2\nnumeric\n11\n________________________\n\nGroup variables\nNone\nVariable type: character\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\ncountry_of_origin\n0\n1\n4\n28\n0\n36\n0\nowner\n0\n1\n3\n50\n0\n305\n0\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\ntotal_cup_points\n0\n1\n82.18\n2.69\n59.83\n81.17\n82.50\n83.67\n90.58\n▁▁▁▇▁\naroma\n0\n1\n7.57\n0.32\n5.08\n7.42\n7.58\n7.75\n8.75\n▁▁▂▇▁\nflavor\n0\n1\n7.52\n0.34\n6.08\n7.33\n7.58\n7.75\n8.83\n▁▂▇▃▁\naftertaste\n0\n1\n7.40\n0.35\n6.17\n7.25\n7.42\n7.58\n8.67\n▁▃▇▂▁\nacidity\n0\n1\n7.54\n0.32\n5.25\n7.33\n7.50\n7.75\n8.75\n▁▁▃▇▁\nbody\n0\n1\n7.52\n0.29\n5.25\n7.33\n7.50\n7.67\n8.58\n▁▁▁▇▁\nbalance\n0\n1\n7.52\n0.35\n6.08\n7.33\n7.50\n7.75\n8.75\n▁▂▇▃▁\nuniformity\n0\n1\n9.84\n0.49\n6.00\n10.00\n10.00\n10.00\n10.00\n▁▁▁▁▇\nclean_cup\n0\n1\n9.84\n0.72\n0.00\n10.00\n10.00\n10.00\n10.00\n▁▁▁▁▇\nsweetness\n0\n1\n9.91\n0.46\n1.33\n10.00\n10.00\n10.00\n10.00\n▁▁▁▁▇\ncupper_points\n0\n1\n7.50\n0.43\n5.17\n7.25\n7.50\n7.75\n10.00\n▁▂▇▁▁\n\nLooking at the coffee with clean cup score = 0: Is it really that the coffee had a score of 0? Or was it a data entry mistake?\n\n\n# there is one datapoint in which clean_cup score = 0\ncoffee_ratings %>% \n  filter(clean_cup == 0) %>% \n  t() # transpose\n\n\n                      [,1]                                                  \ntotal_cup_points      \"68.33\"                                               \nspecies               \"Arabica\"                                             \nowner                 \"juan carlos garcia lopez\"                            \ncountry_of_origin     \"Mexico\"                                              \nfarm_name             \"el centenario\"                                       \nlot_number            NA                                                    \nmill                  \"la esperanza, municipio juchique de ferrer, veracruz\"\nico_number            \"1104328663\"                                          \ncompany               \"terra mia\"                                           \naltitude              \"900\"                                                 \nregion                \"juchique de ferrer\"                                  \nproducer              \"JUAN CARLOS GARCÍA LOPEZ\"                            \nnumber_of_bags        \" 12\"                                                 \nbag_weight            \"1 kg\"                                                \nin_country_partner    \"AMECAFE\"                                             \nharvest_year          \"2012\"                                                \ngrading_date          \"September 17th, 2012\"                                \nowner_1               \"JUAN CARLOS GARCIA LOPEZ\"                            \nvariety               \"Bourbon\"                                             \nprocessing_method     \"Washed / Wet\"                                        \naroma                 \"7.08\"                                                \nflavor                \"6.83\"                                                \naftertaste            \"6.25\"                                                \nacidity               \"7.42\"                                                \nbody                  \"7.25\"                                                \nbalance               \"6.75\"                                                \nuniformity            \"10\"                                                  \nclean_cup             \"0\"                                                   \nsweetness             \"10\"                                                  \ncupper_points         \"6.75\"                                                \nmoisture              \"0.11\"                                                \ncategory_one_defects  \"0\"                                                   \nquakers               \"0\"                                                   \ncolor                 \"None\"                                                \ncategory_two_defects  \"20\"                                                  \nexpiration            \"September 17th, 2013\"                                \ncertification_body    \"AMECAFE\"                                             \ncertification_address \"59e396ad6e22a1c22b248f958e1da2bd8af85272\"            \ncertification_contact \"0eb4ee5b3f47b20b049548a2fd1e7d4a2b70d0a7\"            \nunit_of_measurement   \"m\"                                                   \naltitude_low_meters   \" 900\"                                                \naltitude_high_meters  \" 900\"                                                \naltitude_mean_meters  \" 900\"                                                \n                      [,2]                                      \ntotal_cup_points      \" 0.00\"                                   \nspecies               \"Arabica\"                                 \nowner                 \"bismarck castro\"                         \ncountry_of_origin     \"Honduras\"                                \nfarm_name             \"los hicaques\"                            \nlot_number            \"103\"                                     \nmill                  \"cigrah s.a de c.v.\"                      \nico_number            \"13-111-053\"                              \ncompany               \"cigrah s.a de c.v\"                       \naltitude              \"1400\"                                    \nregion                \"comayagua\"                               \nproducer              \"Reinerio Zepeda\"                         \nnumber_of_bags        \"275\"                                     \nbag_weight            \"69 kg\"                                   \nin_country_partner    \"Instituto Hondureño del Café\"            \nharvest_year          \"2017\"                                    \ngrading_date          \"April 28th, 2017\"                        \nowner_1               \"Bismarck Castro\"                         \nvariety               \"Caturra\"                                 \nprocessing_method     NA                                        \naroma                 \"0.00\"                                    \nflavor                \"0.00\"                                    \naftertaste            \"0.00\"                                    \nacidity               \"0.00\"                                    \nbody                  \"0.00\"                                    \nbalance               \"0.00\"                                    \nuniformity            \" 0\"                                      \nclean_cup             \"0\"                                       \nsweetness             \" 0\"                                      \ncupper_points         \"0.00\"                                    \nmoisture              \"0.12\"                                    \ncategory_one_defects  \"0\"                                       \nquakers               \"0\"                                       \ncolor                 \"Green\"                                   \ncategory_two_defects  \" 2\"                                      \nexpiration            \"April 28th, 2018\"                        \ncertification_body    \"Instituto Hondureño del Café\"            \ncertification_address \"b4660a57e9f8cc613ae5b8f02bfce8634c763ab4\"\ncertification_contact \"7f521ca403540f81ec99daec7da19c2788393880\"\nunit_of_measurement   \"m\"                                       \naltitude_low_meters   \"1400\"                                    \naltitude_high_meters  \"1400\"                                    \naltitude_mean_meters  \"1400\"                                    \n\n# one is missing value, already filtered out for total_cup_points = 0\n# the remaining one looks like it really has 0 for clean cup score\n\n7.08 + 6.83 + 6.25 + 7.42 + 7.25 + 6.75 + 10 + 10  + 6.75 # 68.33\n\n\n[1] 68.33\n\nIt turned out that total cup points is a summation of scores for aroma, flavor, aftertaste, acidity, body, balance, uniformity, clean_cup, sweetness and cupper_points.\n\n\ncountry_mean_score <- sensory_by_country %>% \n  group_by(country_of_origin, owner) %>% \n  summarise(mean_score = mean(total_cup_points)) %>% \n  arrange(desc(mean_score)) \n\ncountry_mean_score\n\n\n# A tibble: 350 x 3\n# Groups:   country_of_origin [36]\n   country_of_origin owner                              mean_score\n   <chr>             <chr>                                   <dbl>\n 1 Ethiopia          metad plc                                89.8\n 2 Guatemala         grounds for health admin                 89.8\n 3 Ethiopia          yidnekachew dabessa                      89  \n 4 Brazil            ji-ae ahn                                88.8\n 5 Peru              hugo valdivia                            88.8\n 6 Ethiopia          diamond enterprise plc                   88.2\n 7 Ethiopia          mohammed lalo                            88.1\n 8 Indonesia         grounds for health admin                 87.4\n 9 United States     cqi q coffee sample representative       87.3\n10 Mexico            roberto licona franco                    87.2\n# … with 340 more rows\n\nmin(country_mean_score$mean_score) # 68.33\n\n\n[1] 68.33\n\nmax(country_mean_score$mean_score) # 89.7767\n\n\n[1] 89.77667\n\nHow do the top 8 coffee owners by country compare against each other in terms of the ten scoring criteria?\n\n\n# plot profile for top 8 owners\n\ntop_owners_data <- sensory_by_country%>% \n  group_by(country_of_origin, owner) %>% \n  summarise_at(.vars = vars(total_cup_points:cupper_points),\n               .funs = c(mean = \"mean\")) %>% \n  ungroup() %>% \n  mutate(country_owner = str_c(country_of_origin, owner, sep = \",\"),\n         country_owner_fct = factor(country_owner, \n                                    levels =c(\"Ethiopia,metad plc\", \n                                             \"Guatemala,grounds for health admin\", \n                                             \"Ethiopia,yidnekachew dabessa\",\n                                             \"Brazil,ji-ae ahn\",\n                                             \"Peru,hugo valdivia\",\n                                             \"Ethiopia,diamond enterprise plc\",\n                                             \"Ethiopia,mohammed lalo\",\n                                             \"Indonesia,grounds for health admin\"))) %>% \n  group_by(country_owner_fct) %>% \n  arrange(desc(total_cup_points_mean)) %>% \n  ungroup() %>% \n  slice_max(total_cup_points_mean, n = 8) %>% \n  pivot_longer(cols = c(aroma_mean:cupper_points_mean),\n               names_to = \"parameters\",\n               values_to = \"score\") %>% \n\n  ggplot(aes(x = fct_rev(factor(parameters)), y = score, label = round(score, 1))) +\n  geom_point(stat = \"identity\", aes(col = factor(parameters)), size = 8) +\n  geom_text(col = \"black\", size = 4) +\n  facet_wrap(country_owner_fct~., scales = \"free_y\", ncol = 4) +\n  coord_flip() +\n  theme_few() +\n  theme(legend.position = \"none\")\n  \ntop_owners_data\n\n\n\n\nThe scores for clean_cup, sweetness, uniformity is a perfect 10 for all 8 owners. Slight differences were observed for mean scores for cupper_points, aftertaste and body. These were probably the distinguishing parameters.\nVariety\nThe first few sections above looked mainly at highly scored coffee. Would there be any differenced in scoring profile, if I were to look at different varieties of coffee?\n\n\nvariety_count <- coffee_ratings %>% \n  count(variety) %>% \n  arrange(desc(n)) # 30 observations\n\nhead(variety_count, 8) # NA: 226, Other: 226\n\n\n# A tibble: 8 x 2\n  variety            n\n  <chr>          <int>\n1 Caturra          256\n2 Bourbon          226\n3 <NA>             226\n4 Typica           211\n5 Other            110\n6 Catuai            74\n7 Hawaiian Kona     44\n8 Yellow Bourbon    35\n\ntail(variety_count)\n\n\n# A tibble: 6 x 2\n  variety                 n\n  <chr>               <int>\n1 Ethiopian Heirlooms     1\n2 Marigojipe              1\n3 Moka Peaberry           1\n4 Pache Comun             1\n5 Sulawesi                1\n6 Sumatra Lintong         1\n\ndata_variety <- coffee_ratings %>% \n  select(total_cup_points, species, owner, country_of_origin, processing_method,\n         variety, aroma:cupper_points, color) %>% \n  filter(variety %in% c(\"Caturra\", \"Bourbon\", \"Typica\", \"Catuai\", \n                        \"Hawaiian Kona\", \"Yellow Bourbon\")) %>% \n  group_by(variety)\n\nglimpse(data_variety)\n\n\nRows: 846\nColumns: 17\nGroups: variety [6]\n$ total_cup_points  <dbl> 89.75, 87.17, 86.92, 86.67, 86.42, 86.33,…\n$ species           <chr> \"Arabica\", \"Arabica\", \"Arabica\", \"Arabica…\n$ owner             <chr> \"grounds for health admin\", \"the coffee s…\n$ country_of_origin <chr> \"Guatemala\", \"Costa Rica\", \"Brazil\", \"Hon…\n$ processing_method <chr> NA, \"Washed / Wet\", \"Natural / Dry\", NA, …\n$ variety           <chr> \"Bourbon\", \"Caturra\", \"Bourbon\", \"Caturra…\n$ aroma             <dbl> 8.42, 8.08, 8.50, 8.17, 8.50, 8.17, 8.08,…\n$ flavor            <dbl> 8.50, 8.25, 8.50, 8.08, 8.17, 7.83, 8.17,…\n$ aftertaste        <dbl> 8.42, 8.00, 8.00, 8.08, 8.00, 8.00, 8.00,…\n$ acidity           <dbl> 8.42, 8.17, 8.00, 8.00, 7.75, 8.08, 7.92,…\n$ body              <dbl> 8.33, 8.00, 8.00, 8.08, 8.00, 7.83, 7.92,…\n$ balance           <dbl> 8.42, 8.33, 8.00, 8.00, 8.00, 8.00, 7.83,…\n$ uniformity        <dbl> 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1…\n$ clean_cup         <dbl> 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1…\n$ sweetness         <dbl> 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1…\n$ cupper_points     <dbl> 9.25, 8.33, 7.92, 8.25, 8.00, 8.42, 8.33,…\n$ color             <chr> NA, \"Green\", \"Green\", \"Green\", \"Green\", \"…\n\n# Top 6 coffee by number of datapoints\n\ndata_variety %>% \n  count(species) # all arabica\n\n\n# A tibble: 6 x 3\n# Groups:   variety [6]\n  variety        species     n\n  <chr>          <chr>   <int>\n1 Bourbon        Arabica   226\n2 Catuai         Arabica    74\n3 Caturra        Arabica   256\n4 Hawaiian Kona  Arabica    44\n5 Typica         Arabica   211\n6 Yellow Bourbon Arabica    35\n\ndata_variety %>% \n  count(processing_method) # quite varied\n\n\n# A tibble: 30 x 3\n# Groups:   variety [6]\n   variety processing_method             n\n   <chr>   <chr>                     <int>\n 1 Bourbon Natural / Dry                38\n 2 Bourbon Other                         2\n 3 Bourbon Pulped natural / honey        2\n 4 Bourbon Semi-washed / Semi-pulped    11\n 5 Bourbon Washed / Wet                170\n 6 Bourbon <NA>                          3\n 7 Catuai  Natural / Dry                18\n 8 Catuai  Pulped natural / honey        2\n 9 Catuai  Semi-washed / Semi-pulped     6\n10 Catuai  Washed / Wet                 48\n# … with 20 more rows\n\ndata_variety %>% \n  ungroup() %>% \n  count(country_of_origin) %>% \n  arrange(desc(n))\n\n\n# A tibble: 25 x 2\n   country_of_origin          n\n   <chr>                  <int>\n 1 Mexico                   195\n 2 Guatemala                157\n 3 Colombia                 132\n 4 Brazil                    92\n 5 Taiwan                    66\n 6 Costa Rica                44\n 7 Honduras                  44\n 8 United States (Hawaii)    44\n 9 El Salvador               13\n10 Nicaragua                 13\n# … with 15 more rows\n\n\n\ndata_variety %>% \n  ungroup() %>% \n  group_by(variety) %>% \n  skim()\n\n\nTable 3: Data summary\nName\nPiped data\nNumber of rows\n846\nNumber of columns\n17\n_______________________\n\nColumn type frequency:\n\ncharacter\n5\nnumeric\n11\n________________________\n\nGroup variables\nvariety\nVariable type: character\nskim_variable\nvariety\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\nspecies\nBourbon\n0\n1.00\n7\n7\n0\n1\n0\nspecies\nCatuai\n0\n1.00\n7\n7\n0\n1\n0\nspecies\nCaturra\n0\n1.00\n7\n7\n0\n1\n0\nspecies\nHawaiian Kona\n0\n1.00\n7\n7\n0\n1\n0\nspecies\nTypica\n0\n1.00\n7\n7\n0\n1\n0\nspecies\nYellow Bourbon\n0\n1.00\n7\n7\n0\n1\n0\nowner\nBourbon\n0\n1.00\n4\n50\n0\n44\n0\nowner\nCatuai\n2\n0.97\n5\n41\n0\n29\n0\nowner\nCaturra\n5\n0.98\n4\n45\n0\n45\n0\nowner\nHawaiian Kona\n0\n1.00\n15\n32\n0\n2\n0\nowner\nTypica\n0\n1.00\n8\n47\n0\n83\n0\nowner\nYellow Bourbon\n0\n1.00\n8\n25\n0\n6\n0\ncountry_of_origin\nBourbon\n0\n1.00\n6\n28\n0\n11\n0\ncountry_of_origin\nCatuai\n0\n1.00\n6\n10\n0\n8\n0\ncountry_of_origin\nCaturra\n0\n1.00\n4\n10\n0\n13\n0\ncountry_of_origin\nHawaiian Kona\n0\n1.00\n22\n22\n0\n1\n0\ncountry_of_origin\nTypica\n0\n1.00\n4\n11\n0\n9\n0\ncountry_of_origin\nYellow Bourbon\n0\n1.00\n6\n6\n0\n2\n0\nprocessing_method\nBourbon\n3\n0.99\n5\n25\n0\n5\n0\nprocessing_method\nCatuai\n0\n1.00\n12\n25\n0\n4\n0\nprocessing_method\nCaturra\n7\n0.97\n5\n25\n0\n5\n0\nprocessing_method\nHawaiian Kona\n0\n1.00\n12\n13\n0\n2\n0\nprocessing_method\nTypica\n3\n0.99\n5\n25\n0\n5\n0\nprocessing_method\nYellow Bourbon\n3\n0.91\n5\n25\n0\n5\n0\ncolor\nBourbon\n12\n0.95\n4\n12\n0\n4\n0\ncolor\nCatuai\n2\n0.97\n4\n12\n0\n4\n0\ncolor\nCaturra\n21\n0.92\n4\n12\n0\n4\n0\ncolor\nHawaiian Kona\n6\n0.86\n5\n12\n0\n3\n0\ncolor\nTypica\n27\n0.87\n4\n12\n0\n4\n0\ncolor\nYellow Bourbon\n3\n0.91\n4\n12\n0\n4\n0\nVariable type: numeric\nskim_variable\nvariety\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\ntotal_cup_points\nBourbon\n0\n1\n81.95\n2.54\n68.33\n81.00\n82.33\n83.40\n89.75\n▁▁▂▇▁\ntotal_cup_points\nCatuai\n0\n1\n81.30\n3.91\n59.83\n81.17\n81.88\n83.06\n85.83\n▁▁▁▁▇\ntotal_cup_points\nCaturra\n0\n1\n82.44\n5.59\n0.00\n82.00\n83.12\n83.77\n87.17\n▁▁▁▁▇\ntotal_cup_points\nHawaiian Kona\n0\n1\n81.58\n3.10\n72.58\n80.31\n82.62\n83.33\n86.25\n▁▁▃▇▃\ntotal_cup_points\nTypica\n0\n1\n81.02\n2.59\n67.92\n79.79\n81.50\n82.67\n85.33\n▁▁▁▇▇\ntotal_cup_points\nYellow Bourbon\n0\n1\n82.43\n1.58\n78.00\n81.54\n82.42\n83.16\n86.17\n▁▃▇▅▁\naroma\nBourbon\n0\n1\n7.56\n0.32\n6.17\n7.42\n7.58\n7.67\n8.50\n▁▁▆▇▁\naroma\nCatuai\n0\n1\n7.49\n0.30\n6.67\n7.33\n7.50\n7.67\n8.50\n▁▃▇▂▁\naroma\nCaturra\n0\n1\n7.58\n0.56\n0.00\n7.50\n7.67\n7.75\n8.25\n▁▁▁▁▇\naroma\nHawaiian Kona\n0\n1\n7.51\n0.24\n6.92\n7.33\n7.50\n7.67\n8.08\n▁▅▇▃▂\naroma\nTypica\n0\n1\n7.47\n0.28\n6.67\n7.25\n7.50\n7.67\n8.17\n▁▅▇▇▂\naroma\nYellow Bourbon\n0\n1\n7.50\n0.33\n6.92\n7.25\n7.42\n7.62\n8.42\n▂▇▃▂▂\nflavor\nBourbon\n0\n1\n7.50\n0.36\n6.08\n7.33\n7.50\n7.67\n8.50\n▁▁▇▇▁\nflavor\nCatuai\n0\n1\n7.43\n0.34\n6.17\n7.33\n7.50\n7.58\n8.00\n▁▁▂▇▃\nflavor\nCaturra\n0\n1\n7.53\n0.54\n0.00\n7.42\n7.58\n7.75\n8.33\n▁▁▁▁▇\nflavor\nHawaiian Kona\n0\n1\n7.53\n0.29\n6.92\n7.33\n7.50\n7.75\n8.17\n▃▆▆▇▁\nflavor\nTypica\n0\n1\n7.38\n0.34\n6.33\n7.17\n7.42\n7.58\n8.17\n▁▃▇▇▂\nflavor\nYellow Bourbon\n0\n1\n7.54\n0.24\n7.00\n7.38\n7.58\n7.67\n8.00\n▂▃▇▃▃\naftertaste\nBourbon\n0\n1\n7.32\n0.36\n6.17\n7.17\n7.33\n7.50\n8.42\n▁▂▇▂▁\naftertaste\nCatuai\n0\n1\n7.31\n0.35\n6.17\n7.17\n7.33\n7.50\n8.00\n▁▁▅▇▂\naftertaste\nCaturra\n0\n1\n7.44\n0.54\n0.00\n7.33\n7.50\n7.67\n8.08\n▁▁▁▁▇\naftertaste\nHawaiian Kona\n0\n1\n7.47\n0.31\n6.83\n7.33\n7.50\n7.69\n8.00\n▃▂▇▇▅\naftertaste\nTypica\n0\n1\n7.28\n0.33\n6.17\n7.08\n7.33\n7.50\n8.00\n▁▂▇▇▃\naftertaste\nYellow Bourbon\n0\n1\n7.40\n0.27\n6.83\n7.25\n7.42\n7.58\n8.00\n▂▃▇▅▁\nacidity\nBourbon\n0\n1\n7.55\n0.27\n6.83\n7.42\n7.54\n7.67\n8.42\n▁▅▇▂▁\nacidity\nCatuai\n0\n1\n7.49\n0.32\n6.50\n7.33\n7.50\n7.67\n8.33\n▁▂▇▃▁\nacidity\nCaturra\n0\n1\n7.52\n0.57\n0.00\n7.33\n7.58\n7.75\n8.25\n▁▁▁▁▇\nacidity\nHawaiian Kona\n0\n1\n7.59\n0.27\n6.92\n7.40\n7.58\n7.83\n8.00\n▁▅▂▇▇\nacidity\nTypica\n0\n1\n7.40\n0.27\n6.67\n7.25\n7.42\n7.58\n8.33\n▂▇▇▃▁\nacidity\nYellow Bourbon\n0\n1\n7.47\n0.23\n6.92\n7.33\n7.50\n7.67\n8.00\n▂▇▆▇▁\nbody\nBourbon\n0\n1\n7.50\n0.27\n6.33\n7.33\n7.50\n7.67\n8.33\n▁▁▇▆▁\nbody\nCatuai\n0\n1\n7.41\n0.28\n6.50\n7.27\n7.42\n7.58\n7.92\n▁▂▇▇▅\nbody\nCaturra\n0\n1\n7.54\n0.54\n0.00\n7.48\n7.58\n7.75\n8.17\n▁▁▁▁▇\nbody\nHawaiian Kona\n0\n1\n7.61\n0.26\n6.92\n7.42\n7.67\n7.83\n8.08\n▁▂▇▇▅\nbody\nTypica\n0\n1\n7.40\n0.25\n6.75\n7.25\n7.42\n7.50\n8.33\n▁▇▇▂▁\nbody\nYellow Bourbon\n0\n1\n7.57\n0.27\n6.92\n7.42\n7.50\n7.71\n8.33\n▁▅▇▁▁\nbalance\nBourbon\n0\n1\n7.47\n0.32\n6.50\n7.33\n7.50\n7.67\n8.42\n▁▃▇▅▁\nbalance\nCatuai\n0\n1\n7.40\n0.37\n6.17\n7.25\n7.42\n7.67\n8.00\n▁▁▃▇▆\nbalance\nCaturra\n0\n1\n7.57\n0.58\n0.00\n7.42\n7.58\n7.75\n8.58\n▁▁▁▁▇\nbalance\nHawaiian Kona\n0\n1\n7.64\n0.34\n6.83\n7.42\n7.67\n7.92\n8.25\n▁▃▇▅▅\nbalance\nTypica\n0\n1\n7.35\n0.31\n6.58\n7.17\n7.33\n7.50\n8.25\n▁▃▇▂▁\nbalance\nYellow Bourbon\n0\n1\n7.57\n0.24\n7.17\n7.42\n7.50\n7.67\n8.17\n▅▇▇▃▂\nuniformity\nBourbon\n0\n1\n9.87\n0.39\n8.00\n10.00\n10.00\n10.00\n10.00\n▁▁▁▁▇\nuniformity\nCatuai\n0\n1\n9.85\n0.51\n8.00\n10.00\n10.00\n10.00\n10.00\n▁▁▁▁▇\nuniformity\nCaturra\n0\n1\n9.89\n0.72\n0.00\n10.00\n10.00\n10.00\n10.00\n▁▁▁▁▇\nuniformity\nHawaiian Kona\n0\n1\n9.47\n0.81\n6.67\n9.33\n10.00\n10.00\n10.00\n▁▁▁▅▇\nuniformity\nTypica\n0\n1\n9.75\n0.60\n6.00\n10.00\n10.00\n10.00\n10.00\n▁▁▁▁▇\nuniformity\nYellow Bourbon\n0\n1\n9.83\n0.59\n6.67\n10.00\n10.00\n10.00\n10.00\n▁▁▁▁▇\nclean_cup\nBourbon\n0\n1\n9.85\n0.80\n0.00\n10.00\n10.00\n10.00\n10.00\n▁▁▁▁▇\nclean_cup\nCatuai\n0\n1\n9.77\n1.10\n1.33\n10.00\n10.00\n10.00\n10.00\n▁▁▁▁▇\nclean_cup\nCaturra\n0\n1\n9.89\n0.79\n0.00\n10.00\n10.00\n10.00\n10.00\n▁▁▁▁▇\nclean_cup\nHawaiian Kona\n0\n1\n9.53\n0.94\n6.67\n9.33\n10.00\n10.00\n10.00\n▁▁▁▂▇\nclean_cup\nTypica\n0\n1\n9.76\n0.89\n2.67\n10.00\n10.00\n10.00\n10.00\n▁▁▁▁▇\nclean_cup\nYellow Bourbon\n0\n1\n9.96\n0.16\n9.33\n10.00\n10.00\n10.00\n10.00\n▁▁▁▁▇\nsweetness\nBourbon\n0\n1\n9.91\n0.35\n6.67\n10.00\n10.00\n10.00\n10.00\n▁▁▁▁▇\nsweetness\nCatuai\n0\n1\n9.75\n1.13\n1.33\n10.00\n10.00\n10.00\n10.00\n▁▁▁▁▇\nsweetness\nCaturra\n0\n1\n9.92\n0.71\n0.00\n10.00\n10.00\n10.00\n10.00\n▁▁▁▁▇\nsweetness\nHawaiian Kona\n0\n1\n9.67\n0.75\n6.67\n9.33\n10.00\n10.00\n10.00\n▁▁▁▂▇\nsweetness\nTypica\n0\n1\n9.94\n0.36\n6.00\n10.00\n10.00\n10.00\n10.00\n▁▁▁▁▇\nsweetness\nYellow Bourbon\n0\n1\n9.98\n0.11\n9.33\n10.00\n10.00\n10.00\n10.00\n▁▁▁▁▇\ncupper_points\nBourbon\n0\n1\n7.43\n0.41\n6.00\n7.25\n7.50\n7.67\n9.25\n▁▃▇▁▁\ncupper_points\nCatuai\n0\n1\n7.41\n0.36\n6.33\n7.27\n7.42\n7.58\n8.17\n▁▁▇▆▂\ncupper_points\nCaturra\n0\n1\n7.55\n0.57\n0.00\n7.42\n7.58\n7.75\n8.50\n▁▁▁▁▇\ncupper_points\nHawaiian Kona\n0\n1\n7.56\n0.35\n6.92\n7.33\n7.50\n7.83\n8.33\n▅▇▇▆▂\ncupper_points\nTypica\n0\n1\n7.30\n0.39\n5.25\n7.00\n7.33\n7.58\n8.17\n▁▁▃▇▃\ncupper_points\nYellow Bourbon\n0\n1\n7.60\n0.31\n7.00\n7.38\n7.58\n7.75\n8.25\n▅▇▇▃▃\n\n\n\ndata_variety %>% \n  select(variety, total_cup_points) %>% \n  filter(total_cup_points != 0) %>% \n  ggplot(aes(fct_reorder(variety, total_cup_points), total_cup_points)) +\n  geom_boxplot(aes(col = variety), show.legend = F) +\n  labs(title = \"Comparison of Total Cup Points across top 6 varieties \\n(by count)\",\n       subtitle = \"Caturra has the higest mean Total Cup Score. Catuai had a wider distribution of scores.\",\n       x = NULL,\n       y = \"Total Cup Points\",\n       caption = \"Source: Coffee Quality Institute\") +\n  geom_jitter(aes(col = variety), alpha = 0.2, show.legend = F) +\n  scale_color_few() +\n  coord_flip()  +\n  theme_few()\n\n\n\n\n\n\ndot_plot_variety <- data_variety %>% \n  filter(total_cup_points != 0) %>% \n  select(variety, aroma:cupper_points) %>% \n  group_by(variety) %>% \n  summarise(across(c(aroma:cupper_points), mean)) %>% \n  pivot_longer(cols = c(aroma:cupper_points),\n               names_to = \"parameters\",\n               values_to = \"score\") %>% \n  ggplot(aes(x = fct_reorder(factor(variety), score), y = score, label = round(score, 1))) +\n  geom_point(stat = \"identity\", aes(col = factor(variety)), size = 8) +\n  geom_text(col = \"black\", size = 4) +\n  facet_wrap(parameters~., scales = \"free\", ncol = 4) +\n  labs(title = \"Breakdown of scoring criteria for top 5 coffee (by count)\",\n       subtitle = \"Scores were quite close for all categories, within +/- 0.2. \nMain areas of differences were in balance, clean_cup, cupper_points, sweetness, uniformity\",\n       caption = \"Source: Coffee Quality Institute\",\n       x = \"Variety\",\n       y = \"Score\") +\n  coord_flip() +\n  theme_few() +\n  theme(legend.position = \"none\",\n        axis.title = element_text(face = \"bold\"))\n\ndot_plot_variety\n\n\n\n\nCanturra had an edge over Hawaiian Kona for aroma, clean_cup, sweetness and uniformity, resulting in higher mean total_cup_points. What is Canturra coffee? It’s actually a mutated type of Bourbon coffee that is known for great flavor.\nAs mentioned at the beginning, most of the coffee had very high scores in this dataset. Hence, the plots only show a snapshot of the flavor profiles of the scored coffee, but not all the coffee.\nMain Learning Pointers\nI am really glad to have found this #tidytuesday hashtag, which allows me to practice on readily available datasets and understand how different people in the community approach exploratory data analysis! I am really amazed that there is a dedicated package for loading the dataset with convenience, and this dataset even comes with a data dictionary to understand what each variable means. The R community is really committed to sharing and becoming better, together.\nThe process of EDA is about getting to know your dataset, through asking questions, which are to be answered by carrying out data transformations and creating data visualizations. One question often leads to another, and EDA is a repetitive process until you finish getting to know your data. There were several aspects that I did not look at, such as the effect of altitude, and the grading dates. I may have concentrated too much on the sensory aspect of coffee since that was the more familiar aspect to me, and should have also looked at geographical region and coffee varieties. As an initial learning exercise, I sharpened my focus and concentrated on the effect of species, variety, processing methods, country/owners.\nAs the total cup points is a summation of the scores for attributes such as aroma, flavor, etc, I think it is hard to do classification based on these scores. I would prefer to have physicochemical data as well so that differentiation is more objective and to better countercheck the sensorial data. However, this may be a personal bias as I work in the analytical chemistry field. :)\nI think coffee is really complex. You can have a poorer grade (Robusta), but the roasting process plays a very important role in flavor development. You can have a very good variety, but the processing method may spoil/enhance its flavor profile. You can have a very good farm/owner, but maybe the year of harvest was particularly good or bad. Hence, it is really important to consider all (both familar and unfamilar) aspects when carrying out data analysis, and this is one area I need to improve on.\nCoding wise, I got a chance to practice ggplots, data transformation, filtering and selecting rows and columns, as well as calculating means efficiently by using summarise(across, var, mean). I also managed to create new classifications using ifelse, and used fct_reorder to make my plot better. I like to use theme_clean and scale_color_few for my plots, making aesthetically pleasant plots are a breeze as compared to using Microsoft Excel.\nReferences\nhttps://perfectdailygrind.com/2016/07/washed-natural-honey-coffee-processing-101/ https://www.baristainstitute.com/blog/jori-korhonen/january-2020/coffee-processing-methods-drying-washing-or-honey https://www.coffeechemistry.com/cupping-fundamentals https://www.data-to-viz.com/caveat/spider.html https://www.javapresse.com/blogs/buying-coffee/beginners-guide-coffee-varieties\n\n\n\n",
    "preview": "posts/20210209_tidy_tuesday_coffee_ratings/Tidy-Tuesday---Coffee-Ratings_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2021-02-12T00:21:12+08:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/20210202_Clustering wine/",
    "title": "Clustering Analysis on Wine Dataset",
    "description": "A continuation from PCA analysis of wine dataset: k-means clustering and hierarchical clustering",
    "author": [
      {
        "name": "lruolin",
        "url": {}
      }
    ],
    "date": "2021-02-02",
    "categories": [],
    "contents": "\nSummary\nPCA is used as an exploratory data analysis tool, and may be used for feature engineering and/or clustering. This is a continuation of clustering analysis on the wines dataset in the kohonen package, in which I carry out k-means clustering using the tidymodels framework, as well as hierarchical clustering using factoextra pacage.\nWorkflow\nImport data\nExploratory data analysis\nskim\nggcorr\nggpairs\nCheck assumptions on whether PCA can be carried out\nKMO\nBartlett\nCarry out PCA using tidymodels workflow\nAlways use only continuous variables, ensure that there are no missing data. Determine the number of components using eigenvalues, scree plots and parallel analysis.\nrecipe : preprocess the data (missing values, center and scale, ensuring that variables are continuous)\nprep : evaluate the data\nbake : get the PCA Scores results\nvisualize\ncommunicate results: show the scree plot, PCA loadings, variance explained by each component, loadings and score plot.\nThe loading shows the linear combinations of the original variables - ie the new dimension.\nThe scores show the coordinates of the individual wine samples in the new low-dimensional space.\nUse the loadings to carry out k-means clustering and hierarchical clustering.\nLoading packages\n\n\nlibrary(pacman)\np_load(corrr, GGally, tidymodels, tidytext, tidyverse, psych,\n       skimr, gridExtra, kohonen, janitor, learntidymodels, kohonen,\n       cluster, factoextra)\n\n\n\nImport\nThis dataset is from the kohonen package. It contains 177 rows and 13 columns.\nThese data are the results of chemical analyses of wines grown in the same region in Italy (Piedmont) but derived from three different cultivars: Nebbiolo, Barberas and Grignolino grapes. The wine from the Nebbiolo grape is called Barolo. The data contain the quantities of several constituents found in each of the three types of wines, as well as some spectroscopic variables.\nPCA analysis was performed earlier, and k-means clustering and hierarchical clustering analysis (HCA) will be built upon the PCA loadings.\n\n\ndata(wines)\n\nwines <- as.data.frame(wines) %>% \n  janitor::clean_names() %>%  # require data.frame\n  as_tibble() \n \nglimpse(wines) # does not contain the types of wine (Y variable)\n\n\nRows: 177\nColumns: 13\n$ alcohol          <dbl> 13.20, 13.16, 14.37, 13.24, 14.20, 14.39, …\n$ malic_acid       <dbl> 1.78, 2.36, 1.95, 2.59, 1.76, 1.87, 2.15, …\n$ ash              <dbl> 2.14, 2.67, 2.50, 2.87, 2.45, 2.45, 2.61, …\n$ ash_alkalinity   <dbl> 11.2, 18.6, 16.8, 21.0, 15.2, 14.6, 17.6, …\n$ magnesium        <dbl> 100, 101, 113, 118, 112, 96, 121, 97, 98, …\n$ tot_phenols      <dbl> 2.65, 2.80, 3.85, 2.80, 3.27, 2.50, 2.60, …\n$ flavonoids       <dbl> 2.76, 3.24, 3.49, 2.69, 3.39, 2.52, 2.51, …\n$ non_flav_phenols <dbl> 0.26, 0.30, 0.24, 0.39, 0.34, 0.30, 0.31, …\n$ proanth          <dbl> 1.28, 2.81, 2.18, 1.82, 1.97, 1.98, 1.25, …\n$ col_int          <dbl> 4.38, 5.68, 7.80, 4.32, 6.75, 5.25, 5.05, …\n$ col_hue          <dbl> 1.05, 1.03, 0.86, 1.04, 1.05, 1.02, 1.06, …\n$ od_ratio         <dbl> 3.40, 3.17, 3.45, 2.93, 2.85, 3.58, 3.58, …\n$ proline          <dbl> 1050, 1185, 1480, 735, 1450, 1290, 1295, 1…\n\nEDA\nRefer to the post for PCA of wine analysis\nTidymodels (PCA)\nRecipe\nThe dataset did not include the y variable (type of wine), so the update_role() function will be omitted.\nstep_normalize() combines step_center() and step_scale()\nNote that step_pca is the second step –> will need to retrieve the PCA results from the second list later.\n\n\nwines_recipe <- recipe(~ ., data = wines) %>% \n  # update_role(vintages, new_role = \"id\") %>%  # skipped\n  # step_naomit(all_predictors()) %>% \n  step_normalize(all_predictors()) %>% \n  step_pca(all_predictors(), id = \"pca\")\n\nwines_recipe # 13 predictors\n\n\nData Recipe\n\nInputs:\n\n      role #variables\n predictor         13\n\nOperations:\n\nCentering and scaling for all_predictors()\nNo PCA components were extracted.\n\nPreparation\n\n\nwines_prep <- prep(wines_recipe)\n\nwines_prep # trained\n\n\nData Recipe\n\nInputs:\n\n      role #variables\n predictor         13\n\nTraining data contained 177 data points and no missing data.\n\nOperations:\n\nCentering and scaling for alcohol, malic_acid, ... [trained]\nPCA extraction with alcohol, malic_acid, ... [trained]\n\ntidy_pca_loadings <- wines_prep %>% \n  tidy(id = \"pca\")\n\ntidy_pca_loadings # values here are the loading\n\n\n# A tibble: 169 x 4\n   terms               value component id   \n   <chr>               <dbl> <chr>     <chr>\n 1 alcohol          -0.138   PC1       pca  \n 2 malic_acid        0.246   PC1       pca  \n 3 ash               0.00432 PC1       pca  \n 4 ash_alkalinity    0.237   PC1       pca  \n 5 magnesium        -0.135   PC1       pca  \n 6 tot_phenols      -0.396   PC1       pca  \n 7 flavonoids       -0.424   PC1       pca  \n 8 non_flav_phenols  0.299   PC1       pca  \n 9 proanth          -0.313   PC1       pca  \n10 col_int           0.0933  PC1       pca  \n# … with 159 more rows\n\nBake\n\n\nwines_bake <- bake(wines_prep, wines)\nwines_bake  # has the PCA SCORES to run HCA and k-means clustering\n\n\n# A tibble: 177 x 5\n     PC1    PC2    PC3      PC4     PC5\n   <dbl>  <dbl>  <dbl>    <dbl>   <dbl>\n 1 -2.22 -0.301 -2.03   0.281   -0.259 \n 2 -2.52  1.06   0.974 -0.734   -0.198 \n 3 -3.74  2.80  -0.180 -0.575   -0.257 \n 4 -1.02  0.886  2.02   0.432    0.274 \n 5 -3.04  2.16  -0.637  0.486   -0.630 \n 6 -2.45  1.20  -0.985  0.00466 -1.03  \n 7 -2.06  1.64   0.143  1.20     0.0105\n 8 -2.51  0.958 -1.78  -0.104   -0.871 \n 9 -2.76  0.822 -0.986 -0.374   -0.437 \n10 -3.48  1.35  -0.428 -0.0399  -0.316 \n# … with 167 more rows\n\nCheck number of PC\nOnly the scree plot is showed below. Refer to PCA analysis of wine for other options in determining number of PCs.\n\n\n# b. Scree plot/Variance plot\n\nwines_prep %>% \n  tidy(id = \"pca\", type = \"variance\") %>% \n  filter(terms ==  \"percent variance\") %>% \n  ggplot(aes(x = component, y = value)) +\n  geom_point(size = 2) +\n  geom_line(size = 1) +\n  scale_x_continuous(breaks = 1:13) +\n  labs(title = \"% Variance explained\",\n       y = \"% total variance\",\n       x = \"PC\",\n       caption = \"Source: Wines dataset from kohonen package\") +\n  theme_classic() +\n  theme(axis.title = element_text(face = \"bold\", size = 12),\n        axis.text = element_text(size = 10),\n        plot.title = element_text(size = 14, face = \"bold\"))  # 2 or 3\n\n\n\n\nVisualize\nLoadings plot\n\n\nplot_loadings <- tidy_pca_loadings %>% \n  filter(component %in% c(\"PC1\", \"PC2\", \"PC3\")) %>% \n  mutate(terms = tidytext::reorder_within(terms, \n                                          abs(value), \n                                          component)) %>% \n  ggplot(aes(abs(value), terms, fill = value>0)) +\n  geom_col() +\n  facet_wrap( ~component, scales = \"free_y\") +\n  scale_y_reordered() + # appends ___ and then the facet at the end of each string\n  scale_fill_manual(values = c(\"deepskyblue4\", \"darkorange\")) +\n  labs( x = \"absolute value of contribution\",\n        y = NULL,\n        fill = \"Positive?\",\n        title = \"PCA Loadings Plot\",\n        subtitle = \"Number of PC should be 3, compare the pos and the neg\",\n        caption = \"Source: ChemometricswithR\") +\n  theme_minimal() +\n  theme(title = element_text(size = 24, face = \"bold\"),\n        axis.text = element_text(size = 16),\n        axis.title = element_text(size = 20))\n\n\nplot_loadings\n\n\n\n# PC1: flavonoids, tot_phenols, od_ratio, proanthocyanidins, col_hue, 36%\n# PC2: col_int, alcohol, proline, ash, magnesium; 19.2%\n# PC3: ash, ash_alkalinity, non_flav phenols; 11.2%\n\n\n\nLoadings only\n\n\n# define arrow style\narrow_style <- arrow(angle = 30,\n                     length = unit(0.2, \"inches\"),\n                     type = \"closed\")\n\n# get pca loadings into wider format\npca_loadings_wider <- tidy_pca_loadings%>% \n  pivot_wider(names_from = component, id_cols = terms)\n\n\npca_loadings_only <- pca_loadings_wider %>% \n  ggplot(aes(x = PC1, y = PC2)) +\n  geom_segment(aes(xend = PC1, yend = PC2),\n               x = 0, \n               y = 0,\n               arrow = arrow_style) +\n  ggrepel::geom_text_repel(aes(x = PC1, y = PC2, label = terms),\n            hjust = 0, \n            vjust = 1,\n            size = 5,\n            color = \"red\") +\n  labs(title = \"Loadings on PCs 1 and 2 for normalized data\") +\n  theme_classic()\n\n\n\nScores plot\n\n\n# Scores plot #####\n# PCA SCORES are in bake\npc1pc2_scores_plot <- wines_bake %>% \n  ggplot(aes(PC1, PC2)) +\n  geom_point(aes(color = vintages, shape = vintages), \n             alpha = 0.8, size = 2) +\n  scale_color_manual(values = c(\"deepskyblue4\", \"darkorange\", \"purple\")) +\n  labs(title = \"Scores on PCs 1 and 2 for normalized data\",\n       x = \"PC1 (36%)\",\n       y = \"PC2 (19.2%)\") +\n  theme_classic() +\n  theme(legend.position = \"none\") \n\n\n\nFinalised plots\n\n\ngrid.arrange(pc1pc2_scores_plot, pca_loadings_only, ncol = 2)\n\n\n\n\nk-means clustering\nThe PCA scores will be used for clustering analysis\n\n\nwines_bake\n\n\n# A tibble: 177 x 5\n     PC1    PC2    PC3      PC4     PC5\n   <dbl>  <dbl>  <dbl>    <dbl>   <dbl>\n 1 -2.22 -0.301 -2.03   0.281   -0.259 \n 2 -2.52  1.06   0.974 -0.734   -0.198 \n 3 -3.74  2.80  -0.180 -0.575   -0.257 \n 4 -1.02  0.886  2.02   0.432    0.274 \n 5 -3.04  2.16  -0.637  0.486   -0.630 \n 6 -2.45  1.20  -0.985  0.00466 -1.03  \n 7 -2.06  1.64   0.143  1.20     0.0105\n 8 -2.51  0.958 -1.78  -0.104   -0.871 \n 9 -2.76  0.822 -0.986 -0.374   -0.437 \n10 -3.48  1.35  -0.428 -0.0399  -0.316 \n# … with 167 more rows\n\nNumber of clusters?\nThere are 3 common ways for determining the number of clusters:\ngap statistic method\nwithin sum of square method\nsilhouette method\nLet us look at all three of them.\nGap Statistic Method\n\n\ngap_statistic <- cluster::clusGap(wines_bake,\n                                  FUN = kmeans,\n                                  nstart = 50, \n                                  K.max = 10, # max number of clusters\n                                  B = 1000) # bootstrap\n\nfactoextra::fviz_gap_stat(gap_statistic) # theoretically should have only 3 clusters\n\n\n\n\nWithin Sum of Square Method\n\n\nfviz_nbclust(wines_bake,\n             kmeans,\n             method = \"wss\") # this suggests 3 clusters, in line with theory\n\n\n\n\nSilhouette Method\n\n\nfviz_nbclust(wines_bake,\n             FUN = hcut,\n             method = \"silhouette\") # this suggests 3 clusters\n\n\n\n\nAll three methods agree that there should be 3 clusters. This may not always be the case. In any case, we know that there are 3 different types of wine in the dataset.\nTidymodels workflow for k-means clustering\n\n\n# exploring different k numbers #####\nkclusts_explore <- tibble(k = 1:10) %>% \n  mutate(kclust = purrr::map(k, ~kmeans(wines_bake, .x)),\n         tidied = purrr::map(kclust, tidy),\n         glanced = purrr::map(kclust, glance),\n         augmented = purrr::map(kclust, augment, wines_bake))\n\nkclusts_explore\n\n\n# A tibble: 10 x 5\n       k kclust   tidied            glanced          augmented        \n   <int> <list>   <list>            <list>           <list>           \n 1     1 <kmeans> <tibble [1 × 8]>  <tibble [1 × 4]> <tibble [177 × 6…\n 2     2 <kmeans> <tibble [2 × 8]>  <tibble [1 × 4]> <tibble [177 × 6…\n 3     3 <kmeans> <tibble [3 × 8]>  <tibble [1 × 4]> <tibble [177 × 6…\n 4     4 <kmeans> <tibble [4 × 8]>  <tibble [1 × 4]> <tibble [177 × 6…\n 5     5 <kmeans> <tibble [5 × 8]>  <tibble [1 × 4]> <tibble [177 × 6…\n 6     6 <kmeans> <tibble [6 × 8]>  <tibble [1 × 4]> <tibble [177 × 6…\n 7     7 <kmeans> <tibble [7 × 8]>  <tibble [1 × 4]> <tibble [177 × 6…\n 8     8 <kmeans> <tibble [8 × 8]>  <tibble [1 × 4]> <tibble [177 × 6…\n 9     9 <kmeans> <tibble [9 × 8]>  <tibble [1 × 4]> <tibble [177 × 6…\n10    10 <kmeans> <tibble [10 × 8]> <tibble [1 × 4]> <tibble [177 × 6…\n\n# turn this into 3 separate datasets, each representing a\n# different type of data\n\n#\nclusters <- kclusts_explore %>% \n  unnest(cols = c(tidied))\n\nclusters\n\n\n# A tibble: 55 x 12\n       k kclust       PC1       PC2       PC3       PC4       PC5\n   <int> <list>     <dbl>     <dbl>     <dbl>     <dbl>     <dbl>\n 1     1 <kmea… -1.03e-15 -2.78e-16 -3.22e-16 -5.39e-17  1.76e-16\n 2     2 <kmea…  1.91e+ 0 -8.65e- 2 -1.73e- 3  7.28e- 2 -1.41e- 2\n 3     2 <kmea… -1.89e+ 0  8.56e- 2  1.71e- 3 -7.20e- 2  1.39e- 2\n 4     3 <kmea…  2.71e+ 0  1.10e+ 0 -2.35e- 1 -6.17e- 2  7.64e- 2\n 5     3 <kmea…  4.43e- 4 -1.76e+ 0  1.85e- 1 -7.36e- 2  7.54e- 2\n 6     3 <kmea… -2.26e+ 0  9.55e- 1 -5.83e- 4  1.30e- 1 -1.44e- 1\n 7     4 <kmea…  2.90e- 1 -1.77e+ 0 -8.54e- 1  4.55e- 1  1.35e- 1\n 8     4 <kmea…  2.76e+ 0  1.21e+ 0 -1.52e- 1 -1.11e- 1  5.10e- 2\n 9     4 <kmea… -2.39e+ 0  1.04e+ 0 -2.57e- 1  1.29e- 1 -2.19e- 1\n10     4 <kmea… -3.41e- 1 -1.30e+ 0  1.28e+ 0 -4.39e- 1  1.17e- 1\n# … with 45 more rows, and 5 more variables: size <int>,\n#   withinss <dbl>, cluster <fct>, glanced <list>, augmented <list>\n\n#\nassignments <- kclusts_explore %>% \n  unnest(cols = c(augmented))\n\nassignments  # can be used to plot, with each point colored according to predicted cluster\n\n\n# A tibble: 1,770 x 10\n       k kclust tidied glanced   PC1    PC2    PC3      PC4     PC5\n   <int> <list> <list> <list>  <dbl>  <dbl>  <dbl>    <dbl>   <dbl>\n 1     1 <kmea… <tibb… <tibbl… -2.22 -0.301 -2.03   0.281   -0.259 \n 2     1 <kmea… <tibb… <tibbl… -2.52  1.06   0.974 -0.734   -0.198 \n 3     1 <kmea… <tibb… <tibbl… -3.74  2.80  -0.180 -0.575   -0.257 \n 4     1 <kmea… <tibb… <tibbl… -1.02  0.886  2.02   0.432    0.274 \n 5     1 <kmea… <tibb… <tibbl… -3.04  2.16  -0.637  0.486   -0.630 \n 6     1 <kmea… <tibb… <tibbl… -2.45  1.20  -0.985  0.00466 -1.03  \n 7     1 <kmea… <tibb… <tibbl… -2.06  1.64   0.143  1.20     0.0105\n 8     1 <kmea… <tibb… <tibbl… -2.51  0.958 -1.78  -0.104   -0.871 \n 9     1 <kmea… <tibb… <tibbl… -2.76  0.822 -0.986 -0.374   -0.437 \n10     1 <kmea… <tibb… <tibbl… -3.48  1.35  -0.428 -0.0399  -0.316 \n# … with 1,760 more rows, and 1 more variable: .cluster <fct>\n\n#\nclusterings <- kclusts_explore %>% \n  unnest(cols = c(glanced))\n\nclusterings\n\n\n# A tibble: 10 x 8\n       k kclust  tidied  totss tot.withinss betweenss  iter augmented \n   <int> <list>  <list>  <dbl>        <dbl>     <dbl> <int> <list>    \n 1     1 <kmean… <tibbl… 1834.        1834. -2.50e-12     1 <tibble […\n 2     2 <kmean… <tibbl… 1834.        1192.  6.42e+ 2     1 <tibble […\n 3     3 <kmean… <tibbl… 1834.         820.  1.01e+ 3     2 <tibble […\n 4     4 <kmean… <tibbl… 1834.         730.  1.10e+ 3     3 <tibble […\n 5     5 <kmean… <tibbl… 1834.         659.  1.18e+ 3     3 <tibble […\n 6     6 <kmean… <tibbl… 1834.         603.  1.23e+ 3     4 <tibble […\n 7     7 <kmean… <tibbl… 1834.         562.  1.27e+ 3     3 <tibble […\n 8     8 <kmean… <tibbl… 1834.         545.  1.29e+ 3     5 <tibble […\n 9     9 <kmean… <tibbl… 1834.         471.  1.36e+ 3     3 <tibble […\n10    10 <kmean… <tibbl… 1834.         465.  1.37e+ 3     4 <tibble […\n\n#  visualize\n\n# number of clusters\nclusterings %>% # from glance\n  ggplot(aes(k, tot.withinss)) + # total within cluster sum of squares, keep low\n  geom_line() +\n  geom_point() +\n  scale_x_continuous(breaks = 1:10) +\n  labs(title = \"Plot of Total Within Sum of Squares for different number of clusters\",\n       subtitle = \"Additional clusters beyond k = 3 have little value\") +\n  theme_classic()\n\n\n\n# how datapoints are separated\nglimpse(assignments)\n\n\nRows: 1,770\nColumns: 10\n$ k        <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ kclust   <list> [<1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ tidied   <list> [<tbl_df[1 x 8]>, <tbl_df[1 x 8]>, <tbl_df[1 x 8]…\n$ glanced  <list> [<tbl_df[1 x 4]>, <tbl_df[1 x 4]>, <tbl_df[1 x 4]…\n$ PC1      <dbl> -2.223934, -2.524760, -3.744056, -1.017245, -3.040…\n$ PC2      <dbl> -0.30145757, 1.05925179, 2.79737289, 0.88586726, 2…\n$ PC3      <dbl> -2.0271695, 0.9739613, -0.1798599, 2.0181445, -0.6…\n$ PC4      <dbl> 0.281108579, -0.733645703, -0.575492236, 0.4315681…\n$ PC5      <dbl> -0.25880549, -0.19804048, -0.25714173, 0.27445613,…\n$ .cluster <fct> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n\nassignments %>% # from augment\n  ggplot(aes(x = PC1, y = PC2)) + # use PCA data\n  geom_point(aes(color = .cluster), size = 2, alpha = 0.8) +\n  facet_wrap( ~ k) +\n  # to see the center of the clusters\n  geom_point(data = clusters, size = 9, shape  = \"x\") +\n  labs(x = \"PC1 (36% variance)\",\n       y = \"PC2 (19.2% variance\",\n       title = \"Visualization of k-means clustering\",\n       subtitle = \"Optimal k = 3\",\n       caption = \"Source: Wines dataset from kohonen package\") +\n  theme_minimal()\n\n\n\n\nHierarchical Clustering Analysis\n\n\nwines_HC <- wines_bake %>% \n    dist(.,method = \"euclidean\") %>% \n    hclust(., method = \"ward.D2\")\n\n# 3 clusters:\nfviz_dend(wines_HC,\n          k = 3,\n          rect = T,\n          rect_border = \"jco\",\n          rect_fill = T)\n\n\n\n\nLearning pointers:\nInitially, I was stuck at the visualization part for k-means clustering as I didn’t know how to bring in my x and y-axis data. I had been using the original dataset all along, and was wondering why plots created using the factoextra::fviz_cluster() could report Dim 1 for x axis and Dim 2 for y axis. I finally had the eureka moment when I realised I should use the PCA scores from the bake step earlier.\nI really like the tidymodels way of allowing for visualizing how the clusters are separated when different values of k are used. The functions augment, tidy and glance were very efficient in reporting the results for k-means clustering. Previously I only used tidy and glance for regression, and I didn’t know they could be extended to cluster analysis as well.\nLastly, I find dendrograms very aesthetically intuitive and I like how the colors and types of dendrograms could be customised. However, the assumption is that there must be some structure in the data in the first place, otherwise HCA would give very misleading results.\nReferences\nhttps://rdrr.io/github/tidymodels/learntidymodels/f/inst/tutorials/pca_recipes/pca_recipes.Rmd\nhttps://allisonhorst.github.io/palmerpenguins/articles/articles/pca.html\nhttps://www.ibm.com/support/knowledgecenter/en/SSLVMB_subs/statistics_casestudies_project_ddita/spss/tutorials/fac_telco_kmo_01.html\nhttps://www.tidymodels.org/learn/statistics/k-means/\nhttps://www.r-bloggers.com/2019/07/use-the-k-means-clustering-luke/\nhttps://statsandr.com/blog/clustering-analysis-k-means-and-hierarchical-clustering-by-hand-and-in-r/\nhttps://agroninfotech.blogspot.com/2020/06/visualizing-clusters-in-r-hierarchical.html\n\n\n\n",
    "preview": "posts/20210202_Clustering wine/Clustering-wine_files/figure-html5/unnamed-chunk-6-1.png",
    "last_modified": "2021-02-03T00:24:11+08:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/20210130_Volatiles_tomato/",
    "title": "Volatile Compounds in Tomato and Tomato Products",
    "description": "Scraping information from journal article",
    "author": [
      {
        "name": "lruolin",
        "url": {}
      }
    ],
    "date": "2021-02-01",
    "categories": [],
    "contents": "\nOverview of tomato volatiles\nTomato flavor is the result of interaction of aroma and taste, arising from the interplay of mixture of acids, sugars, amino acids, minerals and volatile compounds. Presence of sugar or organic acids alters taste panel perception of aroma descriptions of samples with the same concentration of volatile compounds.\nVolatile compounds may originate from different biosynthesis pathways (Buttery, Teranishi, and Ling 1987), (Baldwin et al. 1998), (Yilmaz 2001):\nDerived from amino acids: Amino acids are acted upon by transaminase enzymes and converted into alpha-keto acids; which then undergo decarboxylation to form aldehydes, which may be reduced to form ketones.\nDerived from carotenoids: eg 6-methyl-5-hepten-2-one and geranial\nDerived from lipid degradation by lipoxygenase: eg C6 volatiles\nDerived from peroxide lyase and alcohol dehydrogenase enzymes (ADH catalysed alcohol formation from aldehydes)\nMaillard reaction products: furans, pyrroles (Strecker degradation products), pyrazines. These are usually seen in thermally processed tomato products/flavors\nDerived from action of endogenous glycosidases (eg guaiacol, eugenol, methyl salicylate)\nThe amount and types of volatiles are also influenced by:\nTissue disruption\nRipening of fruit\nCultivar\nProcessing/Heating\nAddition of other ingredients (eg herbs and spices for pasta sauces)\nAim of this exercise:\nThe aim of this exercise was to scrape the table of approximately 400 compounds from the pdf, and to visualize them by chemical categories.\nThere is a very handy package, tabulizer, which allows for scraping of information from pdf articles. I tried out text scraping, and text cleaning, from the article (Petro‐Turza 1986)\nWorkflow\nImport data using tabulizer\nText cleaning using stringr package\nVisualize using ggplot2\nLoading packages\n\n\nlibrary(rJava)\nlibrary(tabulizer)\nlibrary(tidyverse)\nlibrary(stringr)\nlibrary(stringi)\n\n\n\nImport & Tidy\nI am interested in scraping the table of approximately 400 volatiles from page 18 to page 28. A copy of the pdf is saved in my working directory. I used the locate_area() function to determine the coordinates for scraping, and then extracted the text using extract_text() function.\n\n\nfile <- \"1986-tomato volatiles.pdf\"\n# locate_areas(file)\n\np18 <- extract_text(file, pages = 18, area = list(c(115.5, 33.05, 641.923, 443.94)))\n\np19 <- extract_text(file, pages = 19, \n                    area = list(c(117.15636,  53.20364, 651.60000, 465.22545 )))\n\np20 <- extract_text(file, pages = 20, \n                    area = list(c(114.52364,  38.72364, 650.28364, 449.42909 )))\n\np21 <- extract_text(file, pages = 21, \n                    area = list(c(119.29273 , 48.89727, 656.76545, 457.90091 )))\n\np22 <- extract_text(file, pages = 22, \n                    area = list(c(113.20727,  30.32545, 643.70182, 466.04182)))\n\np23 <- extract_text(file, pages = 23, \n                    area = list(c(122.25273,  49.84636, 652.01455, 473.13000 )))\n\np24 <- extract_text(file, pages = 24, \n                    area = list(c(113.,  34, 645.01818, 430.50000 )))\n\np25 <- extract_text(file, pages = 25, \n                    area = list(c(119,  58 ,642.81273, 478.38818)))\n\np26 <- extract_text(file, pages = 26, \n                    area = list(c(114,  35, 668.17818, 443.44000)))\n\np27 <- extract_text(file, pages = 27, \n                    area = list(c(114.20727,  41.24545, 656.36364, 442.94000)))\n\np28 <- extract_text(file, pages = 28, \n                    area = list(c(115.52000,  33.86909, 404.32000, 469.69455 )))\n\ncombined <- tribble(~page, ~text,\n                    \"p18\", p18,\n                    \"p19\", p19,\n                    \"p20\", p20,\n                    \"p20\", p20,\n                    \"p21\", p21,\n                    \"p22\", p22,\n                    \"p23\", p23,\n                    \"p24\", p24,\n                    \"p25\", p25,\n                    \"p26\", p26,\n                    \"p27\", p27,\n                    \"p28\", p28) %>% \n  dplyr::mutate(text_2 = gsub(\"\\\\n\", \"; \", text),\n         text_3 = str_split(text_2, \"; \")) %>% # split by ; into new columns\n  unnest() \n\n\n\nI combined all the text that was extracted into a tibble. Then I replaced all the “” with “;” and then used str_split() to split the compounds into individual rows.\nFollowing which, I used a series to str_replace_all to clean up the text. The list of things to remove include:\ndigits that followed after chemical names\nseries of commars\ntext that mentioned unknown structure\nalternative synonoyms of chemical compounds that were located within square brackets\nodd chemical names\nAs I replaced the commars, some of the chemical names were also changed. For example, 2,6-dimethylpyrazine became 26-dimethylpyrazine. I had to change the names by looking for numbers 26, and replacing them as 2,6.\nI visually scanned through the list again and made changes where necessary, for eg, 2-formylpyiTole is actually 2-formylpyrrole.\n\n\ncleaned_text <- combined %>% \n  dplyr::select(text_3) # 521\n\n\ncleaned_text_b <- cleaned_text %>% \n  filter(!text_3 %in% c(\"(Continued)\", \"\")) %>%  # 503\n  filter(!is.na(text_3)) %>% \n  mutate(text_4 = str_replace_all(text_3, \"[0-9]{2,3}\", \"\"),\n         text_4 = str_replace_all(text_4, \"\\\\ , \", \"\"),\n         text_4 = str_replace_all(text_4, \"\\\\,,+\", \"\"),\n         text_4 = str_replace_all(text_4, \"\\\\(unknown structure\\\\)\", \"\"),\n         text_4 = str_replace_all(text_4, \"\\\\[[^\\\\]\\\\[]*]\", \"\"),\n         text_4 = str_replace_all(text_4, \"\\\\[[^\\\\[]*\", \"\"),\n         text_4 = str_replace_all(text_4, \" \\\\,\", \"\"),\n         text_4 = str_replace_all(text_4, \" \\\\/\", \"\"),\n         # replace last commar, dash\n         text_4 = stri_replace_last(text_4, fixed = \",\", \"\"),\n         text_4 = str_replace_all(text_4, \"PJ-dimethyl-ö-octen-l-ol]\", \"\"),\n         text_4 = str_replace_all(text_4, \"/\", \"\"),\n         \n         # correct for commar replacement\n         text_4 = str_replace_all(text_4, \"45\", \"4,5\"),\n         text_4 = str_replace_all(text_4, \"26\", \"2,6\"),\n         text_4 = str_replace_all(text_4, \"25\", \"2,5\"),\n         text_4 = str_replace_all(text_4, \"33\", \"3,3\"),\n         text_4 = str_replace_all(text_4, \"23\", \"2,3\"),\n         text_4 = str_replace_all(text_4, \"14\", \"1,4\"),\n         text_4 = str_replace_all(text_4, \"12\", \"1,2\"),\n         text_4 = str_replace_all(text_4, \"24\", \"2,4\"),\n         text_4 = str_replace_all(text_4, \"34\", \"3,4\"),\n         text_4 = str_replace_all(text_4, \"11\", \"1,1\"),\n         text_4 = str_replace_all(text_4, \"2E 4Z\", \"2E,4Z\"),\n         text_4 = str_replace_all(text_4, \"2E4E\", \"2E,4E\"),\n         text_4 = str_replace_all(text_4, \"2E4Z\", \"2E,4Z\"),\n         text_4 = str_replace_all(text_4, \"hy droxy\", \"hydroxy\"),\n         text_4 = str_replace_all(text_4, \"66\", \"6,6\"),\n         text_4 = str_replace_all(text_4, \"3E5E\", \"3E,5E\"),\n         \n         # further clean up\n         text_4 = str_replace_all(text_4, \"\\\\(unknownstructure\\\\)\", \"\"),\n         text_4 = str_replace_all(text_4, \"\\\\(unknown\", \"\"),\n         text_4 = str_replace_all(text_4, \"2-formylpyiTole \", \"2-formylpyrrole\"),\n         text_4 = str_replace_all(text_4, \"neraUcis-SJ-dimethyl\\\\^.o-octadienal]\", \n                                  \"neral\"),\n         text_4 = str_replace_all(text_4, \"2-methyl-l-propanol -\", \n                                  \"2-methyl-l-propanol\"),\n         text_4 = str_replace_all(text_4, \"propanal 9 09 39 49 5\",\n                                  \"propanal\"),\n         text_4 = str_replace_all(text_4, \"\\\\(methylthioH-propanol\",\n                                  \"\\\\(methylthio)-propanol\"),\n         text_4 = str_replace_all(text_4, \"\\\\(2,2,6-trimethyl-7-oxabicyclo\",\n                                  \"\"),\n         text_4 = str_replace_all(text_4, \"._.\", \"\"),\n         \n         # remove white space\n         text_4 = str_replace_all(text_4, \" \\\\s\", \"\"),\n         \n         # remove quotation marks\n         text_4 = str_remove_all(text_4, \"\\\"\")) \n\n\n\nOne final clean:\n\n\ntomato_cleaned <- cleaned_text_b$text_4 %>% \n  as.data.frame() %>% \n  unique()\n\nnames(tomato_cleaned) <- c(\"compounds\")\n\ntomato_cleaned <- print(tomato_cleaned, quote = FALSE) %>% \n  filter(!compounds == \" \",\n         !compounds == \"\") # remove quotation marks \n\n\n                                                 compounds\n1                                             HYDROCARBONS\n2                                                 heptane \n3                                                  octane \n4                                                  nonane \n5                                                  decane \n6                                                 undecane\n7                                             pentadecane \n8                                                ethylene \n9                                                camphene \n10                                                3-carene\n11                                               limonene \n12                                                myrcene \n13                                          a-phellandrene\n14                                          ß-phellandrene\n15                                               o-pinene \n16                                                3-pinene\n17                                               sabinene \n18                                            terpinolene \n19                                          triisobutylene\n20                                                benzene \n21                                                 toluene\n22                                            ethylbenzene\n23                                                 styrene\n24                                          propylbenzene \n25                                                  cumene\n26                                           butylbenzene \n27                                                o-xylene\n28                                               m-xylene \n29                                                p-xylene\n30                                 l-ethyl-4-methylbenzene\n31                                         diethylbenzene \n32                                                  cymene\n33                                               p-cymene \n34                                       trimethylbenzene \n35                                           hemimellitene\n36                                            pseudocumene\n37                                              mesitylene\n38                                                biphenyl\n39                                             naphtalene \n40                                                ALCOHOLS\n41                                               methanol \n42                                                 ethanol\n43                                                        \n44                                             1-propanol \n46                                              2-propanol\n47                                     2-methyl-l-propanol\n48                                                        \n49                                    2-methyl-2-propanol \n50                                           2-propen-l-ol\n51                                               1-butanol\n53                                              2-butanol \n54                                              buten-1-ol\n55                                     2-methyl-l-butanol \n56                                      3-methyl-l-butanol\n58                                   3-methyl-2-buten-l-ol\n59                                  2-methyl-3-buten-2-ol \n60                                         2,3-butanediol \n61                                             1-pentanol \n63                                             2-pentanol \n64                                             3-pentanol \n65                                      cis-3-penten-l-ol \n66                                          l-penten-3-ol \n67                                    2-methyl-l-pentanol \n68                                    3-methyl-l-pentanol \n69                                     2-methyl-2-pentanol\n70                                               1-hexanol\n72                                              2-hexanol \n73                                                 hexenol\n74                                            2-hexen-l-ol\n75                                        cis-2-hexen-l-ol\n76                                     trans-2-hexen-l-ol \n77                                           3-hexen-l-ol \n78                                       cis-3-hexen-l-ol \n80                                     trans-3-hexen-1 -ol\n81                                       cis-4-hexen-l-ol \n82                                           methylhexanol\n83                                     2-methyl-3-hexanol \n84                                    5-methyl-1 -hexanol \n85                                             1-heptanol \n86                                              2-heptanol\n87                                              4-heptanol\n88                                 6-methyl-5-hepten-2-ol \n89                                               1-octanol\n91                                           l-octen-3-ol \n92                                     7-methyl-l-octanol \n93                                              1-decanol \n94                                            8-p-cymenol \n95                                             citronellol\n96                                                farnesol\n97                                               geraniol \n98                                                linalool\n100                                                 nerol \n101                                              nerolidol\n102                                          terpinen-4-ol\n103                                            o-terpineol\n104                                        benzyl alcohol \n105                                        2-phenylethanol\n107                              4-isopropylbenzyl alcohol\n108                                               menthol \n109                                                PHENOLS\n110                                                phenol \n111                                              o-cresol \n112                                               p-cresol\n113                                          4-ethylphenol\n114                                         4-vinylphenol \n115                                               guaiacol\n116                                4-ethyl-2-methoxyphenol\n117                                2-methoxy-4-vinylphenol\n118                                                eugenol\n119                                           3,4-xylenol \n120                                                 ETHERS\n121                                          diethyl ether\n122                                   1,1-dipropoxyethane \n123                    1-ethoxy-l (3-methylbutoxy)-ethane \n124                              1-ethoxy-l-pentoxyethane \n125                             l-methoxy-4-methylbenzene \n126                              isopropyl-methoxybenzene \n127                                    2-methoxy-biphenyl \n128                                              ALDEHYDES\n129                                           formaldehyde\n130                                           acetaldehyde\n175                                              propanal \n176                                               acrolein\n177                                       2-methylpropanal\n178                                                butanal\n179                                              2-butenal\n180                                       2-methylbutanal \n181                                       3-methylbutanal \n183                                    2-methyl-2-butenal \n184                                          tiglaldehyde \n185                                               pentanal\n186                                            2-pentenal \n187                                       trans-2-pentenal\n188                                             3-pentenal\n189                                         methylpentenal\n190                                                hexanal\n192                                               hexenal \n193                                              2-hexenal\n194                                          cis-2-hexenal\n195                                        trans-2-hexenal\n197                                         cis-3-hexenal \n198                                      2E,4Z-hexadienal \n199                                      2E,4E-hexadienal \n200                                               heptanal\n201                                              heptenal \n202                                             2-heptenal\n203                                       trans-2-heptenal\n204                                      2E,4Z-heptadienal\n205                                     2E,4E-heptadienal \n206                                               octanal \n207                                             2-octenal \n208                                       trans-2-octenal \n209                                               nonanal \n210                                              2-nonenal\n211                                        trans-2-nonenal\n212                                      2E,4E-nonadienal \n213                                               decanal \n214                                             2-decenal \n215                                        2,4-decadienal \n216                                       2E,4Z-decadienal\n217                                      2E,4E-decadienal \n218                                             undecanal \n219                                              dodecanal\n221                                                citral \n222                                                 neral \n223                                              geranial \n224                                           citronellal \n225                                               farnesal\n226                                          benzaldehyde \n228                                  3-methylbenzaldehyde \n229                                  4-methylbenzaldehyde \n230                                        salicylaldehyde\n231                                  4-hydroxybenzaldehyde\n232                                 3-methoxybenzaldehyde \n233                                          anisaldehyde \n234                                  2-phenylacetaldehyde \n235                                      3-phenylpropanal \n236                                         cinnamaldehyde\n237                                                KETONES\n238                                                acetone\n239                                            2-butanone \n240                                  3-hydroxy-2-butanone \n241                                          3-buten-2-one\n242                                            2-pentanone\n243                                           3-pentanone \n244                                         l-penten-3-one\n245                                         3-penten-2-one\n246                                         cyclopentanone\n247                                 2-ethylcyclopentanone \n248                                  2-methyl-3-pentanone \n249                                          mesityl oxide\n250                       4-hydroxy- 4-methyl-2-pentanone \n251                              2,4-dimethylpentan-3-one \n252                                            2-hexanone \n253                2-hydroxy-2,6,6-trimethylcyclohexanone \n254                                           2-heptanone \n255                                  4-methyl-3-heptanone \n256                                        methylheptenone\n257                               6-methyl-5-hepten-2-one \n259                           6-methyl-35-heptadien-2-one \n260                                             2-octanone\n261                                   3E,5E-octadien-2-one\n262                                            2-nonanone \n263                                   trans-2-nonen-4-one \n265                                             undecanone\n266                                          2-dodecanone \n267                                         pseudo-ionone \n268                                        geranylacetone \n270                                       farnesylacetone \n272                                              tt-ionone\n273                                               ß-ionone\n275                                              •y-ionone\n276                                         epoxy-0-ionone\n278                                                carvone\n279                                          acetophenone \n280                                  4-methylacetophenone \n281                                 2-hydroxyacetophenone \n282                                  4-methoxyacetophenone\n283                         4-methyl-4-phenyl-2-pentanone \n284                                   l-phenyl-2-propanone\n285                                    l-phenyl-2-butanone\n286                                   DICARBONYL COMPOUNDS\n287                                               glyoxal \n288                                          methylglyoxal\n289                                              biacetyl \n291                                       2-oxo-3-butenal \n292                                       2,3-pentanedione\n293                                      2,3-heptanedione \n294                                                  ACIDS\n295                                                formic \n296                                                 acetic\n297                                             propanoic \n298                                     2-methylpropanoic \n299                                              butanoic \n300                                      2-methylbutanoic \n301                                      3-methylbutanoic \n302                                              pentanoic\n303                                     4-methylpentanoic \n304                                              hexanoic \n305                                             4-hexenoic\n306                                             heptanoic \n308                                              octanoic \n309                                                geranic\n310                                               nonanoic\n311                                               myristic\n312                                         pentadecanoic \n313                                               palmitic\n314                                               stearic \n315                                                 oleic \n316                                               linoleic\n317                                             linolenic \n318                                               benzoic \n319                                              salicylic\n320                                        2-phenylacetic \n321                                              cinnamic \n322                                     4-hydroxycinnamic \n323                                                 ESTERS\n324                                        methyl fonnate \n325                                         ethyl fonnate \n326                                        pentyl fonnate \n327                                      phenetyl fonnate \n328                                        methyl acetate \n329                                         ethyl acetate \n330                                        propyl acetate \n331                                          butyl acetate\n332                                 2-methylbutyl acetate \n333                                     isopentyl acetate \n334                                         pentyl acetate\n335                                         hexyl acetate \n336                               trans-2-hexenyl acetate \n337                                     3-hexenyl acetate \n338                                  cis-3-hexenyl acetate\n339                              trans-3-hexeny 1 acetate2\n340                                        heptyl acetate \n341                               6 -methylheptyl acetate \n342                                         nonyl acetate \n343                                      phenethyl acetate\n344                                    citronellyl acetate\n345                                       geranyl acetate \n346                                        linalyl acetate\n347                                       ethyl propanoate\n348                                  isopentyl propanoate \n349                                 citronellyl propanoate\n350                                      methyl butanoate \n352                                     2-butyl butanoate \n353                                   isopentyl butanoate \n354                                 citronellyl butanoate \n355                                     geranyl butanoate \n356                            isobutyl 3-methylbutanoate \n357                       2-methylbutyl 3-methylbutanoate \n358                           isopentyl 3-methylbutanoate \n359                                   isobutyl pentanoate \n360                                   isopentyl pentanoate\n361                                      methyl hexanoate \n362                                        ethyl hexanoate\n363                                        butyl hexanoate\n364                                   isopentyl hexanoate \n365                                        hexyl hexanoate\n366                                  isopentyl heptanoate \n367                                       methyl octanoate\n368                                      propyl nonanoate \n369                                   isopentyl nonanoate \n370                                      propyl decanoate \n371                                   isopentyl decanoate \n372                                       methyl myristate\n373                                        ethyl myristate\n374                                  methyl pentadecanoate\n375                                      methyl palmitate \n376                                        ethyl palmitate\n377                                          methyl oléate\n378                                      methyl linoleate \n379                                        ethyl linoleate\n380                                      methyl linolenate\n381                                       ethyl linolenate\n382                                       methylsalicylate\n383                                       ethyl salicylate\n384                                               LACTONES\n385                                        7-butyrolactone\n386                                 2-methyl-4-butanolide \n387                              3-methyl-2-buten-4-olide \n388                                          4-pentanolide\n389                                3-methyl-4-pentanolide \n390                                          4-hexanolide \n391                                6-hydroxy-5-hexanolide \n392                                          4-octanolide \n393                                          5-octanolide \n394                                           4-nonanolide\n396                          2,4-dimethyl-2-nonen-4-olide \n397                                  dihydroactinidiolide \n399                                              phtalide \n400                                       SULFUR COMPOUNDS\n401                                       hydrogen sulfide\n402                                       dimethyl sulfide\n403                                   ethylmethyl sulfide \n404                                    dimethyl disulfide \n405                                methylpropyl disulfide \n406                                          methanethiol \n407                                 2-(methylthio)ethanol \n408                                 3(methylthio)-propanol\n409                              5(methylthio)-l-pentanol \n410                            2(methylthio)-acetaldehyde \n411                                3(methylthio)-propanal \n412                           methyl-methanethiosulfonate \n413                                     NITROGEN COMPOUNDS\n414                                            methylamine\n415                                             ethylamine\n416                                          dimethylamine\n417                                        trimethylamine \n418                                            propylamine\n419                                            butylamine \n420                                          isobutylamine\n421                                    dimethylethylamine \n422                                           diethylamine\n423                                    2-methylbutylamine \n424                                           pentylamine \n425                                         isopentylamine\n426                                         diphenylamine \n427                                 3-methylbutanal-oxime \n428                                         butanenitrile \n429                                  3-methylbutanenitrile\n430                                        pentanenitrile \n431                                         benzyl cyanide\n432                                    3-methylnitrobutane\n433                          3-hydroxy-3-methylnitrobutane\n434                                      HALOGEN COMPOUNDS\n435                                       trichloromethane\n436                                     trichloroethylene \n437                                    1,2-dichlorobenzene\n438               OXYGEN-CONTAINING HETEROCYCLIC COMPOUNDS\n439                                                 furan \n440                                          2-methylfuran\n441                                          2-ethylfuran \n442                                         2-propylfuran \n443                                      2-isobutenylfuran\n444                             2-isopropyl-5-methylfuran \n445                            2-isopropenyl-5-methylfuran\n446                              2-methyl-5-propenylfuran \n447                                         2-pentylfuran \n448                                          2-hexylfuran \n449                                         2-heptylfuran \n450                                            acetylfuran\n451                                         2-acetylfuran \n452                                              furfural \n454                                       5-methylfurfural\n455                                 2-acetyl-5-methylfuran\n456                              2-acetonyl-5-methylfuran \n457                             methyl-2-furancarboxylate \n458                                          dibenzofuran \n459                                      furfuryl alcohol \n460                                2-furancarboxylic acid \n461                          2-methyltetrahydro-3-furanone\n462                               linalool oxide I. or II.\n463                                     linalool oxide I. \n465                                    linalool oxide II. \n467                                   linalool III. or IV.\n468                                            structure) \n469                                           1,4-dioxane \n470                          2,2,4-trimethyl-l3-dioxolane \n471               2,7-dioxa-l,3,3-trimethylbicycloheptane \n472                   ó.S-dioxa-l.S-dimethylbicyclooctane \n473               SULFUR-CONTAINING HETEROCYCLIC COMPOUNDS\n474                                     2-forraylthiophene\n475                                     3-formylthiophene \n476                            2-formyl-5-methylthiophene \n477                                     2-acetylthiophene \n478                            2-thiophenecarboxyIic acid \n479             NITROGEN-CONTAINING HETEROCYCLIC COMPOUNDS\n480                                               pyrrole \n481                                   2,5-dimethylpyrrole \n483                                        2-formylpyrrole\n484                                       2-acetylpyrrole \n485                                              pyridine \n486                                      2-formylpyridine \n487                                         methylpyrazine\n488                                      2-methylpyrazine \n489                                  2,6-dimethylpyrazine \n490                               2-ethyl-6-vinylpyrazine \n491                          2-isopropyl-3-methoxypyrazine\n492                                                indene \n493 SULFUR- AND NITROGEN-CONTAINING HETEROCYCLIC COMPOUNDS\n494                                      2-propylthiazole \n495                                    2-isobutylthiazole \n497                                   2-sec-butylthiazole \n498                          2-isopropyl-4-methylthiazole \n499                                          benzothiazole\n500               NITROGEN-AND OXYGEN-CONTAINING COMPOUNDS\n501                                        4-butyloxazole \n502                               5-pentyl-4-ethyloxazole \n503                                 4,5-dimethylisoxazole \n\ntomato_cleaned$compounds <- str_remove_all(tomato_cleaned$compounds, \n                                           \"\\\\s\")\n\n\n\nThe file could be exported as a .csv file as a back up, in case it is needed again in the future.\nTRANSFORM\nNext, I had to split the compounds into various chemical categories.\n\n\nhydrocarbons <- tomato_cleaned %>% \n  as_tibble() %>% \n  slice(2:39) %>% \n  mutate(category = \"hydrocarbons\")\n\n\nalcohols <- tomato_cleaned %>% \n  as_tibble() %>% \n  slice(41:98) %>% \n  mutate(category = \"alcohols\")\n\nphenols <- tomato_cleaned %>% \n  as_tibble() %>% \n  slice(99:108) %>% \n  mutate(category = \"phenols\")\n\nethers<- tomato_cleaned %>% \n  as_tibble() %>% \n  slice(111:116) %>% \n  mutate(category = \"ethers\")\n\naldehydes<- tomato_cleaned %>% \n  as_tibble() %>% \n  slice(118:176) %>% \n  mutate(category = \"aldehydes\")\n\nketones<- tomato_cleaned %>% \n  as_tibble() %>% \n  slice(178:219) %>% \n  mutate(category = \"ketones\")\n\ndicarbonyl<- tomato_cleaned %>% \n  as_tibble() %>% \n  slice(221:226) %>% \n  mutate(category = \"dicarbonyl\")\n\nacids<- tomato_cleaned %>% \n  as_tibble() %>% \n  slice(228:254) %>% \n  mutate(category = \"acids\")\n\nesters<- tomato_cleaned %>% \n  as_tibble() %>% \n  slice(256:314) %>% \n  mutate(category = \"esters\")\n\nlactones<- tomato_cleaned %>% \n  as_tibble() %>% \n  slice(316:328) %>% \n  mutate(category = \"lactones\")\n\nsulfur<- tomato_cleaned %>% \n  as_tibble() %>% \n  slice(330:341) %>% \n  mutate(category = \"sulfur\")\n\nnitrogen<- tomato_cleaned %>% \n  as_tibble() %>% \n  slice(343:362) %>% \n  mutate(category = \"nitrogen\")\n\nhalogen<- tomato_cleaned %>% \n  as_tibble() %>% \n  slice(364:366) %>% \n  mutate(category = \"halogen\")\n\noxygen<- tomato_cleaned %>% \n  as_tibble() %>% \n  slice(368:398) %>% \n  mutate(category = \"oxygen\")\n\nsulfur_heterocyclic<- tomato_cleaned %>% \n  as_tibble() %>% \n  slice(400:404) %>% \n  mutate(category = \"sulfur_heterocyclic\")\n\nnitrogen_heterocyclic<- tomato_cleaned %>% \n  as_tibble() %>% \n  slice(406:417) %>% \n  mutate(category = \"nitrogen_heterocyclic\")\n\nnitrogen_sulfur_heterocyclic<- tomato_cleaned %>% \n  as_tibble() %>% \n  slice(419:423) %>% \n  mutate(category = \"nitrogen_sulfur_heterocyclic\")\n\nnitrogen_oxygen_heterocyclic<- tomato_cleaned %>% \n  as_tibble() %>% \n  slice(425:427) %>% \n  mutate(category = \"nitrogen_oxygen_heterocyclic\")\n\n\n\nVisualize\n\n\ntomatoes_compounds <- bind_rows(hydrocarbons,\n                                alcohols,\n                                phenols,\n                                ethers,\n                                aldehydes,\n                                ketones,\n                                dicarbonyl,\n                                acids,\n                                esters,\n                                lactones,\n                                sulfur,\n                                halogen,\n                                oxygen,\n                                sulfur_heterocyclic,\n                                nitrogen_heterocyclic,\n                                nitrogen_sulfur_heterocyclic,\n                                nitrogen_oxygen_heterocyclic\n                                )\n\nplot <- tomatoes_compounds %>% \n  group_by(category) %>% \n  summarise(count = n()) %>% \n  ggplot(aes(x = reorder(category, count), y = count, label = count)) +\n  geom_col(fill = \"tomato2\") +\n  geom_text(aes(label = count), hjust = -0.5, size = 5) +\n  scale_y_continuous(expand = c(0,0), limits = c(0, 80)) +\n  labs(y = \"No. of compounds\",\n       x = \"Category\",\n       title = \"Number of volatile compounds identified in tomatoes, sorted by chemical category\",\n       subtitle = \"Esters, aldehydes and alcohols dominate the types of compounds identified\",\n       caption = \"Petro-Turza(1989): Flavor of tomato and tomato products \") +\n  coord_flip() +\n  theme_classic() +\n   theme(title = element_text(size = 28),\n        axis.title = element_text(size = 24, face = \"bold\"),\n        axis.text = element_text(size = 20))\n\nplot\n\n\n\n\nReflections\nIt may have been easier to type out the list of 400 compounds, which would only take an hour or less, with the formatting done properly on the onset. However, if the table was much longer, text cleaning would be more effectively carried out by stringr. Some improvements could be made to the script so that I do not have to carry out multiple str_replace_all, and to automatically filter out by categories instead of manually defining them. However, it was a good beginner’s practice on text cleaning using the stringr package as I do not often have the chance to use regular expressions, and I found the str_detect, str_which and str_view_all functions extremely useful in locating regex matches.\nThe plot above only lists the number of compounds identified so far by chemical classes, but does not show which are the character impact compounds that contribute significantly to tomatoes.\nHistorically, researchers focused on identifying volatiles, quantifying them and classifying them based on their odor thresholds to determine which compounds played a contributory role to tomato flavor. However, the new trend is in assessing the importance of compounds based on how much they contribute to the liking of tomato flavor, and this could be by means of targeted metabolomics, or by generating prediction models for different descriptors of tomato flavor using regression analysis of both volatile and non-volatile compounds, or by carrying out multivariate modelling on physicochemical, volatile and sensory parameters(Rambla et al. 2013).\nIt would be interesting to try to apply prediction models and multivariate analysis in R.\nReferences\nhttps://www.r-bloggers.com/2019/09/pdf-scraping-in-r-with-tabulizer/\n\n\n\nBaldwin, E. A., J. W. Scott, M. A. Einstein, T. M. M. Malundo, B. T. Carr, R. L. Shewfelt, and K. S. Tandon. 1998. “Relationship Between Sensory and Instrumental Analysis for Tomato Flavor.” Journal of the American Society for Horticultural Science 123 (5): 906–15.\n\n\nButtery, Ron G., Roy Teranishi, and Louisa C. Ling. 1987. “Fresh Tomato Aroma Volatiles: A Quantitative Study.” Journal of Agricultural and Food Chemistry 35 (4): 540–44.\n\n\nPetro‐Turza, Martha. 1986. “Flavor of Tomato and Tomato Products.” Food Reviews International 2 (3): 309–51. https://doi.org/10.1080/87559128609540802.\n\n\nRambla, José L., Yury M. Tikunov, Antonio J. Monforte, Arnaud G. Bovy, and Antonio Granell. 2013. “The Expanded Tomato Fruit Volatile Landscape.” Journal of Experimental Botany 65 (16): 4613–23.\n\n\nYilmaz, Emin. 2001. “The Chemistry of Fresh Tomato Flavor.” Turkish Journal of Agriculture and Forestry 25 (3): 149–55.\n\n\n\n\n",
    "preview": "posts/20210130_Volatiles_tomato/Volatiles_tomatoes_files/figure-html5/unnamed-chunk-6-1.png",
    "last_modified": "2021-02-01T23:36:52+08:00",
    "input_file": {},
    "preview_width": 3840,
    "preview_height": 2304
  },
  {
    "path": "posts/20210123_PCA wine/",
    "title": "PCA Wine",
    "description": "PCA (using tidymodels) with wine dataset",
    "author": [
      {
        "name": "lruolin",
        "url": {}
      }
    ],
    "date": "2021-01-23",
    "categories": [],
    "contents": "\nSummary\nPCA is a data reduction technique, to uncover latent variables that are uncorrelated. It is an unsupervised way of classification. Not all of the variables in high-dimensional data are required. Some are highly correlated with others and these variables may be omitted, while retaining a similar level of information in the dataset in terms of explaining the variance.\nIt is used as an exploratory data analysis tool, and may be used for feature engineering and/or clustering.\nWorkflow\nImport data\nExploratory data analysis\nskim\nggcorr\nggpairs\nCheck assumptions on whether PCA can be carried out\nKMO\nBartlett\nCarry out PCA using tidymodels workflow\nAlways use only continuous variables, ensure that there are no missing data. Determine the number of components using eigenvalues, scree plots and parallel analysis.\nrecipe : preprocess the data (missing values, center and scale, ensuring that variables are continuous)\nprep : evaluate the data\nbake : get the PCA Scores results\nvisualize\ncommunicate results: show the scree plot, PCA loadings, variance explained by each component, loadings and score plot.\nThe scores plot show the positions of the individual wine samples in the coordinate system of the PCs.\nThe loadings plot shows the contribution of the X variables to the PCs.\nLoading packages\n\n\nlibrary(pacman)\np_load(corrr, palmerpenguins, GGally, tidymodels, tidytext, tidyverse, psych,\n       skimr, gridExtra, kohonen, janitor, learntidymodels, kohonen)\n\n\n\nImport\nThis dataset is from the kohonen package. It contains 177 rows and 13 columns.\nThese data are the results of chemical analyses of wines grown in the same region in Italy (Piedmont) but derived from three different cultivars: Nebbiolo, Barberas and Grignolino grapes. The wine from the Nebbiolo grape is called Barolo. The data contain the quantities of several constituents found in each of the three types of wines, as well as some spectroscopic variables.\nThe dataset requires some cleaning, and the type of wine was added to the datset.\n\n\ndata(wines)\n\nwines <- as.data.frame(wines) %>% \n  janitor::clean_names() %>%  # require data.frame\n  as_tibble() %>% \n  cbind(vintages)  # vintages = Y outcome = category\n \nglimpse(wines)\n\n\nRows: 177\nColumns: 14\n$ alcohol          <dbl> 13.20, 13.16, 14.37, 13.24, 14.20, 14.39, …\n$ malic_acid       <dbl> 1.78, 2.36, 1.95, 2.59, 1.76, 1.87, 2.15, …\n$ ash              <dbl> 2.14, 2.67, 2.50, 2.87, 2.45, 2.45, 2.61, …\n$ ash_alkalinity   <dbl> 11.2, 18.6, 16.8, 21.0, 15.2, 14.6, 17.6, …\n$ magnesium        <dbl> 100, 101, 113, 118, 112, 96, 121, 97, 98, …\n$ tot_phenols      <dbl> 2.65, 2.80, 3.85, 2.80, 3.27, 2.50, 2.60, …\n$ flavonoids       <dbl> 2.76, 3.24, 3.49, 2.69, 3.39, 2.52, 2.51, …\n$ non_flav_phenols <dbl> 0.26, 0.30, 0.24, 0.39, 0.34, 0.30, 0.31, …\n$ proanth          <dbl> 1.28, 2.81, 2.18, 1.82, 1.97, 1.98, 1.25, …\n$ col_int          <dbl> 4.38, 5.68, 7.80, 4.32, 6.75, 5.25, 5.05, …\n$ col_hue          <dbl> 1.05, 1.03, 0.86, 1.04, 1.05, 1.02, 1.06, …\n$ od_ratio         <dbl> 3.40, 3.17, 3.45, 2.93, 2.85, 3.58, 3.58, …\n$ proline          <dbl> 1050, 1185, 1480, 735, 1450, 1290, 1295, 1…\n$ vintages         <fct> Barolo, Barolo, Barolo, Barolo, Barolo, Ba…\n\nEDA\nSome exploratory data analysis was carried out:\nWhat are the types of variables? Categorical or numerical?\nWhat is the distribution like? Skewed?\nAre there any missing values?\nAre there any outliers?\nCheck the types of wine\nAre the variables quite correlated with each other?\nskimr\n\n\nskim(wines) # 177 x 13, all numeric + Y outcome\n\n\nTable 1: Data summary\nName\nwines\nNumber of rows\n177\nNumber of columns\n14\n_______________________\n\nColumn type frequency:\n\nfactor\n1\nnumeric\n13\n________________________\n\nGroup variables\nNone\nVariable type: factor\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\nvintages\n0\n1\nFALSE\n3\nGri: 71, Bar: 58, Bar: 48\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nalcohol\n0\n1\n12.99\n0.81\n11.03\n12.36\n13.05\n13.67\n14.83\n▂▇▇▇▃\nmalic_acid\n0\n1\n2.34\n1.12\n0.74\n1.60\n1.87\n3.10\n5.80\n▇▅▂▂▁\nash\n0\n1\n2.37\n0.28\n1.36\n2.21\n2.36\n2.56\n3.23\n▁▂▇▅▁\nash_alkalinity\n0\n1\n19.52\n3.34\n10.60\n17.20\n19.50\n21.50\n30.00\n▁▆▇▃▁\nmagnesium\n0\n1\n99.59\n14.17\n70.00\n88.00\n98.00\n107.00\n162.00\n▅▇▃▁▁\ntot_phenols\n0\n1\n2.29\n0.63\n0.98\n1.74\n2.35\n2.80\n3.88\n▅▇▇▇▁\nflavonoids\n0\n1\n2.02\n1.00\n0.34\n1.20\n2.13\n2.86\n5.08\n▆▆▇▂▁\nnon_flav_phenols\n0\n1\n0.36\n0.12\n0.13\n0.27\n0.34\n0.44\n0.66\n▃▇▅▃▂\nproanth\n0\n1\n1.59\n0.57\n0.41\n1.25\n1.55\n1.95\n3.58\n▃▇▆▂▁\ncol_int\n0\n1\n5.05\n2.32\n1.28\n3.21\n4.68\n6.20\n13.00\n▇▇▃▂▁\ncol_hue\n0\n1\n0.96\n0.23\n0.48\n0.78\n0.96\n1.12\n1.71\n▅▇▇▃▁\nod_ratio\n0\n1\n2.60\n0.71\n1.27\n1.93\n2.78\n3.17\n4.00\n▆▃▆▇▂\nproline\n0\n1\n745.10\n314.88\n278.00\n500.00\n672.00\n985.00\n1680.00\n▇▇▅▃▁\n\nGGally\n\n\nwines %>% \n  select(-vintages) %>% \n  ggcorr(label = T, label_alpha = T, label_round = 2)\n\n\n\nwines %>% \n  ggpairs(aes(col = vintages))\n\n\n\n\nChecking assumptions\nIs the dataset suitable for PCA analysis?\n\n\n# Continuous Y\n# No missing data\n# Check assumptions for PCA #####\nwines_no_y <- wines %>% \n  select(-vintages)\n\nglimpse(wines_no_y)\n\n\nRows: 177\nColumns: 13\n$ alcohol          <dbl> 13.20, 13.16, 14.37, 13.24, 14.20, 14.39, …\n$ malic_acid       <dbl> 1.78, 2.36, 1.95, 2.59, 1.76, 1.87, 2.15, …\n$ ash              <dbl> 2.14, 2.67, 2.50, 2.87, 2.45, 2.45, 2.61, …\n$ ash_alkalinity   <dbl> 11.2, 18.6, 16.8, 21.0, 15.2, 14.6, 17.6, …\n$ magnesium        <dbl> 100, 101, 113, 118, 112, 96, 121, 97, 98, …\n$ tot_phenols      <dbl> 2.65, 2.80, 3.85, 2.80, 3.27, 2.50, 2.60, …\n$ flavonoids       <dbl> 2.76, 3.24, 3.49, 2.69, 3.39, 2.52, 2.51, …\n$ non_flav_phenols <dbl> 0.26, 0.30, 0.24, 0.39, 0.34, 0.30, 0.31, …\n$ proanth          <dbl> 1.28, 2.81, 2.18, 1.82, 1.97, 1.98, 1.25, …\n$ col_int          <dbl> 4.38, 5.68, 7.80, 4.32, 6.75, 5.25, 5.05, …\n$ col_hue          <dbl> 1.05, 1.03, 0.86, 1.04, 1.05, 1.02, 1.06, …\n$ od_ratio         <dbl> 3.40, 3.17, 3.45, 2.93, 2.85, 3.58, 3.58, …\n$ proline          <dbl> 1050, 1185, 1480, 735, 1450, 1290, 1295, 1…\n\n# KMO: Indicates the proportion of variance in the variables that may be caused by underlying factors. High values (close to 1) indicate that factor analysis may be useful.\nwines_no_y %>% \n  cor() %>% \n  KMO() # .70 above : YES\n\n\nKaiser-Meyer-Olkin factor adequacy\nCall: KMO(r = .)\nOverall MSA =  0.78\nMSA for each item = \n         alcohol       malic_acid              ash   ash_alkalinity \n            0.73             0.80             0.44             0.68 \n       magnesium      tot_phenols       flavonoids non_flav_phenols \n            0.67             0.87             0.81             0.82 \n         proanth          col_int          col_hue         od_ratio \n            0.85             0.62             0.79             0.86 \n         proline \n            0.81 \n\n# Bartlett's test of sphericity: tests the hypothesis that the correlation matrix is an identity matrix (ie variables are unrelated and not suitable for structure detection.) For factor analysis, the p. value should be <0.05.\n\nwines_no_y %>% \n  cor() %>% \n  cortest.bartlett(., n = 177) # p<0.05\n\n\n$chisq\n[1] 1306.787\n\n$p.value\n[1] 3.302319e-222\n\n$df\n[1] 78\n\nTidymodels (PCA)\nRecipe\nWith the use of update_role(), the types of wine information is retained in the dataset.\nstep_normalize() combines step_center() and step_scale()\nNote that step_pca is the second step –> will need to retrieve the PCA results from the second list later.\n\n\nwines_recipe <- recipe(~ ., data = wines) %>% \n  update_role(vintages, new_role = \"id\") %>%  \n  # step_naomit(all_predictors()) %>% \n  step_normalize(all_predictors()) %>% \n  step_pca(all_predictors(), id = \"pca\")\n\nwines_recipe # 13 predictors\n\n\nData Recipe\n\nInputs:\n\n      role #variables\n        id          1\n predictor         13\n\nOperations:\n\nCentering and scaling for all_predictors()\nNo PCA components were extracted.\n\nPreparation\n\n\nwines_prep <- prep(wines_recipe)\n\nwines_prep # trained\n\n\nData Recipe\n\nInputs:\n\n      role #variables\n        id          1\n predictor         13\n\nTraining data contained 177 data points and no missing data.\n\nOperations:\n\nCentering and scaling for alcohol, malic_acid, ... [trained]\nPCA extraction with alcohol, malic_acid, ... [trained]\n\ntidy_pca_loadings <- wines_prep %>% \n  tidy(id = \"pca\")\n\ntidy_pca_loadings # values here are the loading\n\n\n# A tibble: 169 x 4\n   terms               value component id   \n   <chr>               <dbl> <chr>     <chr>\n 1 alcohol          -0.138   PC1       pca  \n 2 malic_acid        0.246   PC1       pca  \n 3 ash               0.00432 PC1       pca  \n 4 ash_alkalinity    0.237   PC1       pca  \n 5 magnesium        -0.135   PC1       pca  \n 6 tot_phenols      -0.396   PC1       pca  \n 7 flavonoids       -0.424   PC1       pca  \n 8 non_flav_phenols  0.299   PC1       pca  \n 9 proanth          -0.313   PC1       pca  \n10 col_int           0.0933  PC1       pca  \n# … with 159 more rows\n\nBake\n\n\nwines_bake <- bake(wines_prep, wines)\nwines_bake  # has the PCA SCORES that we are familiar with\n\n\n# A tibble: 177 x 6\n   vintages   PC1    PC2    PC3      PC4     PC5\n   <fct>    <dbl>  <dbl>  <dbl>    <dbl>   <dbl>\n 1 Barolo   -2.22 -0.301 -2.03   0.281   -0.259 \n 2 Barolo   -2.52  1.06   0.974 -0.734   -0.198 \n 3 Barolo   -3.74  2.80  -0.180 -0.575   -0.257 \n 4 Barolo   -1.02  0.886  2.02   0.432    0.274 \n 5 Barolo   -3.04  2.16  -0.637  0.486   -0.630 \n 6 Barolo   -2.45  1.20  -0.985  0.00466 -1.03  \n 7 Barolo   -2.06  1.64   0.143  1.20     0.0105\n 8 Barolo   -2.51  0.958 -1.78  -0.104   -0.871 \n 9 Barolo   -2.76  0.822 -0.986 -0.374   -0.437 \n10 Barolo   -3.48  1.35  -0.428 -0.0399  -0.316 \n# … with 167 more rows\n\nCheck number of PC\n\n\n# a. Eigenvalues: Keep components greater than 1\n# data is stored in penguins_prep, step 3\n\nwines_prep$steps[[2]]$res$sdev # 3\n\n\n [1] 2.1628220 1.5815708 1.2055413 0.9614802 0.9282978 0.8030241\n [7] 0.7429548 0.5922321 0.5377546 0.4967984 0.4748054 0.4103374\n[13] 0.3224124\n\n# b. Scree plot/Variance plot\n\nwines_prep %>% \n  tidy(id = \"pca\", type = \"variance\") %>% \n  filter(terms ==  \"percent variance\") %>% \n  ggplot(aes(x = component, y = value)) +\n  geom_point(size = 2) +\n  geom_line(size = 1) +\n  scale_x_continuous(breaks = 1:4) +\n  labs(title = \"% Variance explained\",\n       y = \"% total variance\",\n       x = \"PC\",\n       caption = \"Source: ChemometricswithR book\") +\n  theme_minimal() +\n  theme(axis.title = element_text(face = \"bold\", size = 12),\n        axis.text = element_text(size = 10),\n        plot.title = element_text(size = 14, face = \"bold\"))  # 2 or 3\n\n\n\n# bii: Cumulative variance plot\n\nwines_prep %>% \n  tidy(id = \"pca\", type = \"variance\") %>% \n  filter(terms == \"cumulative percent variance\") %>%\n  ggplot(aes(component, value)) +\n  geom_col(fill= \"forestgreen\") +\n  labs(x = \"Principal Components\", \n       y = \"Cumulative variance explained (%)\",\n       title = \"Cumulative Variance explained\") +\n  geom_text(aes(label = round(value, 2)), vjust = -0.2, size = 4) +\n  theme_minimal() +\n  theme(axis.title = element_text(face = \"bold\", size = 12),\n        axis.text = element_text(size = 10),\n        plot.title = element_text(size = 14, face = \"bold\")) \n\n\n\n# c. Parallel analysis\n\nfa.parallel(cor(wines_no_y),\n            n.obs = 333,\n            cor = \"cor\",\n            plot = T)  # 3\n\n\n\nParallel analysis suggests that the number of factors =  4  and the number of components =  3 \n\nVisualize\nLoadings plot\n\n\nplot_loadings <- tidy_pca_loadings %>% \n  filter(component %in% c(\"PC1\", \"PC2\", \"PC3\", \"PC4\")) %>% \n  mutate(terms = tidytext::reorder_within(terms, \n                                          abs(value), \n                                          component)) %>% \n  ggplot(aes(abs(value), terms, fill = value>0)) +\n  geom_col() +\n  facet_wrap( ~component, scales = \"free_y\") +\n  scale_y_reordered() + # appends ___ and then the facet at the end of each string\n  scale_fill_manual(values = c(\"deepskyblue4\", \"darkorange\")) +\n  labs( x = \"absolute value of contribution\",\n        y = NULL,\n        fill = \"Positive?\",\n        title = \"PCA Loadings Plot\",\n        subtitle = \"Number of PC should be 3, compare the pos and the neg\",\n        caption = \"Source: ChemometricswithR\") +\n  theme_minimal()\n\n\nplot_loadings\n\n\n\n# PC1: flavonoids, tot_phenols, od_ratio, proanthocyanidins, col_hue, 36%\n# PC2: col_int, alcohol, proline, ash, magnesium; 19.2%\n# PC3: ash, ash_alkalinity, non_flav phenols; 11.2%\n# PC4: malic acid?\n\n\n\nAn alternative way to plot:\n\n\n# alternate plot loadings\n\nlearntidymodels::plot_top_loadings(wines_prep,\n                  component_number <= 4, n = 5) +\n  scale_fill_manual(values = c(\"deepskyblue4\", \"darkorange\")) +\n  theme_minimal()\n\n\n\n\nLoadings only\n\n\n# define arrow style\narrow_style <- arrow(angle = 30,\n                     length = unit(0.2, \"inches\"),\n                     type = \"closed\")\n\n# get pca loadings into wider format\npca_loadings_wider <- tidy_pca_loadings%>% \n  pivot_wider(names_from = component, id_cols = terms)\n\n\npca_loadings_only <- pca_loadings_wider %>% \n  ggplot(aes(x = PC1, y = PC2)) +\n  geom_segment(aes(xend = PC1, yend = PC2),\n               x = 0, \n               y = 0,\n               arrow = arrow_style) +\n  ggrepel::geom_text_repel(aes(x = PC1, y = PC2, label = terms),\n            hjust = 0, \n            vjust = 1,\n            size = 5,\n            color = \"red\") +\n  labs(title = \"Loadings on PCs 1 and 2 for normalized data\") +\n  theme_classic()\n\n\n\nScores plot\n\n\n# Scores plot #####\n# PCA SCORES are in bake\npc1pc2_scores_plot <- wines_bake %>% \n  ggplot(aes(PC1, PC2)) +\n  geom_point(aes(color = vintages, shape = vintages), \n             alpha = 0.8, size = 2) +\n  scale_color_manual(values = c(\"deepskyblue4\", \"darkorange\", \"purple\")) +\n  labs(title = \"Scores on PCs 1 and 2 for normalized data\",\n       x = \"PC1 (36%)\",\n       y = \"PC2 (19.2%)\") +\n  theme_classic() +\n  theme(legend.position = \"none\") \n\n\n\nFinalised plots\n\n\ngrid.arrange(pc1pc2_scores_plot, pca_loadings_only, ncol = 2)\n\n\n\n\nCheck against Data\n\n\nwines %>% \n  group_by(vintages) %>% \n  summarise(across(c(flavonoids, col_int, ash, malic_acid),\n                   mean,\n                   na.rm = T))\n\n\n# A tibble: 3 x 5\n  vintages   flavonoids col_int   ash malic_acid\n* <fct>           <dbl>   <dbl> <dbl>      <dbl>\n1 Barbera         0.781    7.40  2.44       3.33\n2 Barolo          2.98     5.53  2.46       2.02\n3 Grignolino      2.08     3.09  2.24       1.93\n\nInterpretation of results\nPCA allows for exploratory characterizing of x variables that are associated with each other.\nPC1: flavanoids, total phenols, OD_ratio. PC2: color intensity, alcohol, proline PC3: ash, ash_alkalinity PC4: malic acid (by right 3 components are sufficient)\nBarbera, indicated in blue, has the largest score on PC 1 and PC2. Barolo, indicated in orange, has the smallest score on PC 1. Grignolo, indicated in purple, has the lowest score on PC 2.\nBarbera has low flavonoids, high col_int and high malic acid Barolo has high flavonoids, medium col_int and intermediate malic acid Grignolino has intermediate flavonoids, high col_int and low malic acid.\nReferences\nhttps://rdrr.io/github/tidymodels/learntidymodels/f/inst/tutorials/pca_recipes/pca_recipes.Rmd\nhttps://allisonhorst.github.io/palmerpenguins/articles/articles/pca.html\nhttps://www.ibm.com/support/knowledgecenter/en/SSLVMB_subs/statistics_casestudies_project_ddita/spss/tutorials/fac_telco_kmo_01.html\n\n\n\n",
    "preview": "posts/20210123_PCA wine/PCA-wine_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2021-01-23T15:55:43+08:00",
    "input_file": {},
    "preview_width": 3072,
    "preview_height": 2304
  },
  {
    "path": "posts/20210120_statistical concepts/",
    "title": "Statistical Concepts",
    "description": "Definition of terms",
    "author": [
      {
        "name": "lruolin",
        "url": {}
      }
    ],
    "date": "2021-01-20",
    "categories": [],
    "contents": "\nThis is a glossary of terms, in alphabetical order.\nCorrelation, r : whether there is any relationship between two variables. If so, whether the relationship is weak or strong, and what the direction of relationship is.\nPrincipal Component Analysis (PCA): a multivariate technique used to reduce the number of dimensions to explain the total variation in the data with a few linear combinations of original variables, which are uncorrelated.\nVariance, Sˆ2: the average of squared deviations of the values from mean. Square root of variance = standard deviation.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-21T00:34:33+08:00",
    "input_file": {}
  },
  {
    "path": "posts/20210115_kovats/",
    "title": "Kovats Index",
    "description": "R script for calculating Kovats Index",
    "author": [
      {
        "name": "lruolin",
        "url": {}
      }
    ],
    "date": "2021-01-15",
    "categories": [],
    "contents": "\n\nContents\nBackground\nR workflow\nExampleLoad packages\nImport\nTransform\n\nReferences:\n\nBackground\nAbout 70% of my time at work is spent on interpreting GCMS and GC data. It is more of a qualitative type of identifying what each peak is, and this requires a seach based on mass spectra found in the GCMS library, as well as using the retention index. When working on GC data, I am even more reliant on the retention index for cross checking of peaks on GCMS, since there is no spectra information available.\nRetention time is influenced by GC conditions and column types. Using retention time alone is not useful when you are trying to compare with retention times stated in the literature, since the elution conditions are different.\nThe Kovats index (KI) may be used to convert retention times into standardised retention indices (RI), based on retention times of alkane standards. The equation for Non-Isothermal Kovats RI is shown below.\n\\[\nI_x = 100n + 100(t_x-t_n) / (t_(n+1) − t_n)\n\\]\nPrior to learning R, I used to do the calculation on an excel spreadsheet. This was cumbersome, first I had to key in the retention times of each alkane standard, and then update my formula for the range of retention times between each alkane standard, and then copy and paste all the compiled retention times into 2 columns. That involved a lot of clicking with the mouse.\nR workflow\nRun alkane standards on instrument (for example, GCMS) and compile the retention times in either .csv or .xlsx.\nCreate a function to calculate KI.\nCalculate the KI for retention times between each pair of alkane standard\nMerge the compiled retention times and corresponding KI together\nExport the data to excel and use the vlookup function to find out the KI when retention time is keyed in; alternatively, use inner_join function to tabulate calculated KI before identifying the peaks. I am using the former as there may be some small peaks that were not integrated, or coeluted with other peaks, so there is still a degree of manual input that is required.\nExample\nSample retention time data was retrieved from: https://massfinder.com/wiki/Retention_index_guide\nLoad packages\n\n\nlibrary(tidyverse)\n\n\n\nImport\n\n\n# Key in values\ncarbon_number <- c(\"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\")\nMS_RT <- c(1.85, 2.71, 3.69, 4.59, 5.37, 6.19, 7.17, 8.40, 9.99)\n\n# Create a tibble\nms_rt <- cbind(carbon_number, MS_RT) %>% as_tibble()\nms_rt$carbon_number <- as.numeric(ms_rt$carbon_number)\nms_rt$MS_RT <- as.numeric(ms_rt$MS_RT)\n\n# The data may also be imported from excel\n\n\n\nTransform\n\n\n# create function to calculate KI ####\nto_Calc_KI = function(n,Tn,m,Tm,Ti){\n  RI = 100*n + (100*(m-n)*((Ti-Tn)/(Tm-Tn)))\n  round(RI, 0)\n  \n}\n\n\n\n\n\n# create function to filter by carbon number ####\n# dat refers to data\n# col refers to column\n# val refers to values\n\nfilter_by_carbon_number <- function(dat, col, val){\n  filter(dat, col %in%  val)\n}\n\n\n\nThe following step could be improved on by creating another function to repeat the codes rather than manually changing the values.\n\n\nfil_c8c9 <- filter_by_carbon_number(ms_rt, ms_rt$carbon_number, c(8,9)) \n\nfil_c9c10 <- filter_by_carbon_number(ms_rt, ms_rt$carbon_number, c(9,10)) \n\nfil_c10c11 <- filter_by_carbon_number(ms_rt, ms_rt$carbon_number, c(10,11)) \nfil_c11c12 <- filter_by_carbon_number(ms_rt, ms_rt$carbon_number, c(11,12)) \nfil_c12c13 <- filter_by_carbon_number(ms_rt, ms_rt$carbon_number, c(12,13)) \nfil_c13c14 <- filter_by_carbon_number(ms_rt, ms_rt$carbon_number, c(13,14)) \nfil_c14c15 <- filter_by_carbon_number(ms_rt, ms_rt$carbon_number, c(14,15)) \nfil_c15c16 <- filter_by_carbon_number(ms_rt, ms_rt$carbon_number, c(15,16)) \n\n\n\n\n\n# create function to generate tibble for KI calculation\ncreate_KI_tibble <- function(msrt_col, n , m){\n  seq(from = min(msrt_col), to = max(msrt_col), by = 0.01) %>% \n    as_tibble() %>% \n    rename(\"Ti\" = value) %>% \n    mutate(n = n,\n           m = m,\n           Tn = min(msrt_col), \n           Tm = max(msrt_col)) %>% \n    dplyr::select(n, Tn, m, Tm, Ti) %>% \n    mutate(KI = pmap_dbl(., to_Calc_KI))\n}\n\n\n\n\n\nc8c9 <- create_KI_tibble(fil_c8c9$MS_RT, 8, 9)\nc9c10 <- create_KI_tibble(fil_c9c10$MS_RT, 9, 10)\nc10c11 <- create_KI_tibble(fil_c10c11$MS_RT, 10, 11)\nc11c12 <- create_KI_tibble(fil_c11c12$MS_RT, 11, 12)\nc12c13 <- create_KI_tibble(fil_c12c13$MS_RT, 12, 13)\nc13c14 <- create_KI_tibble(fil_c13c14$MS_RT, 13, 14)\nc14c15 <- create_KI_tibble(fil_c14c15$MS_RT, 14, 15)\nc15c16 <- create_KI_tibble(fil_c15c16$MS_RT, 15, 16)\n\ncalculated_MS_KI <- rbind(c8c9, c9c10, c10c11, c11c12, c12c13, \n                          c13c14, c14c15, c15c16) %>% \n  select(Ti, KI)\n\n# Export created file if needed\n# write_xlsx(calculated_MS_KI, \"Kovats_Indices.xlsx\")\n\n\n\nLooking at the first 6 lines of tabulated KI:\n\n\nhead(calculated_MS_KI)\n\n\n# A tibble: 6 x 2\n     Ti    KI\n  <dbl> <dbl>\n1  1.85   800\n2  1.86   801\n3  1.87   802\n4  1.88   803\n5  1.89   805\n6  1.9    806\n\nReferences:\nhttps://webbook.nist.gov/chemistry/gc-ri/\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-15T11:19:30+08:00",
    "input_file": {}
  },
  {
    "path": "posts/20210118_calibration curves/",
    "title": "Calibration Curves Data",
    "description": "R script for calculating Limit of Detection and Limit of Quantification",
    "author": [
      {
        "name": "lruolin",
        "url": {}
      }
    ],
    "date": "2021-01-15",
    "categories": [],
    "contents": "\n\nContents\nLoading required packages\nBackground\nImport Example Dataset\nVisualize\nModel\nErrors in slope and intercept of regression line\nPredict the value of x from y:\n\nNote: the data and theory on calibration curve were with reference from: Statistics and Chemometrics for Analytical Chemistry, James N. Miller and Jane Charlotte Miller, 6th edition, Chapter 5\nLoading required packages\n\n\nlibrary(pacman)\np_load(tidyverse, broom, chemCal)\n\n\n\nBackground\nChemists often work with calibration data using standards of known concentrations and putting them through instrumental analysis. When plotting a calibration curve, it is of interest to calculate the limit of detection (LOD) and limit of quantification (LOQ) of the method.\nImport Example Dataset\nThe fluorescence intensities of standard aqueous fluorescein solutions were analysed with a spectrophotometer, and the fluorescence results are shown below:\n\n# A tibble: 7 x 2\n  conc_pgml  fluo\n      <dbl> <dbl>\n1         0   2.1\n2         2   5  \n3         4   9  \n4         6  12.6\n5         8  17.3\n6        10  21  \n7        12  24.7\n\nVisualize\n\n\n\nModel\nLet’s fit a linear model to get the slope (b) and intercept(a).\n\\[\ny = a + bx\n\\]\n\n\nCall:\nlm(formula = fluo ~ conc_pgml, data = data)\n\nResiduals:\n       1        2        3        4        5        6        7 \n 0.58214 -0.37857 -0.23929 -0.50000  0.33929  0.17857  0.01786 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   1.5179     0.2949   5.146  0.00363 ** \nconc_pgml     1.9304     0.0409  47.197 8.07e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4328 on 5 degrees of freedom\nMultiple R-squared:  0.9978,    Adjusted R-squared:  0.9973 \nF-statistic:  2228 on 1 and 5 DF,  p-value: 8.066e-08\n\nFrom above, we can see that slope = 1.9304, and intercept = 1.5179.\nErrors in slope and intercept of regression line\nThe limit of detection is defined as:\n\\[\nLOD = \\gamma_B + 3_{SB}\n\\] where LOD is the analyte concentration wich gives a signal equal to the blank signal plus three standard deviations of the blank.\nA function was created to calculate LOD and LOQ:\n\n\ncalcLOD_y <- function(model) {\n  SSE <- sum(model$residuals**2)\n  n <- length(model$residuals) -2\n  Syx <- sqrt(SSE/n)\n  intercept <- as.numeric(model$coefficients[1])\n  calculated_y <- intercept + 3*Syx\n  names(calculated_y) <- \"calculated_y\"\n  print(calculated_y)\n  \n  chemCal::inverse.predict(model,\n                  newdata = calculated_y,\n                  alpha = 0.05) \n}\n\n\n\n\n\ncalcLOQ_y <- function(model) {\n  SSE <- sum(model$residuals**2)\n  n <- length(model$residuals) -2\n  Syx <- sqrt(SSE/n)\n  intercept <- as.numeric(model$coefficients[1])\n  calculated_y <- intercept + 10*Syx\n  names(calculated_y) <- \"calculated_y\"\n  print(calculated_y)\n  \n  chemCal::inverse.predict(model,\n                  newdata = calculated_y,\n                  alpha = 0.05) \n}\n\n\n\nInserting the linear model from the fluorescence data:\n\n\nLOD_x <- calcLOD_y(fl_mod)\n\n\ncalculated_y \n      2.8164 \n\nLOD_x$Prediction \n\n\n[1] 0.6726958\n\n\n\nLOQ_x <- calcLOQ_y(fl_mod)\n\n\ncalculated_y \n    5.846334 \n\nLOQ_x$Prediction \n\n\n[1] 2.242319\n\nPredict the value of x from y:\nTo predict the concentration of fluorescein that has fluorescence units of 2.9, we use the function inverse.predict():\n\n\nchemCal::inverse.predict(fl_mod, \n                newdata = 2.9,\n                alpha = 0.05)\n\n\n$Prediction\n[1] 0.7160037\n\n$`Standard Error`\n[1] 0.2645698\n\n$Confidence\n[1] 0.6800982\n\n$`Confidence Limits`\n[1] 0.03590545 1.39610195\n\n\n\n\n",
    "preview": "posts/20210118_calibration curves/calibration-curves_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2021-01-18T23:23:27+08:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/20210114_motivations/",
    "title": "Motivations",
    "description": "why R?",
    "author": [
      {
        "name": "lruolin",
        "url": {}
      }
    ],
    "date": "2021-01-14",
    "categories": [],
    "contents": "\nWhy R?\nI attended a short modular course on R, and was introduced to more effective and efficient ways of structuring data for customised plots that look way better than on Excel and SPSS. At the end of the course, I really wanted to retain what I have learnt, and build on what I have learnt, so that I can be better at R.\nR, to me, is a new form of literacy (like how Microsoft Office was taught in school last time). It is also an effective approach to learn problem solving, as well as a job skill.\nAristotle — ‘The more you know, the more you know you don’t know.’\nand that makes me want to learn even more.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-14T20:47:28+08:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "My first post: Learning goals for 2021",
    "description": "pRactice corner for coding in R",
    "author": [
      {
        "name": "lruolin",
        "url": {}
      }
    ],
    "date": "2021-01-14",
    "categories": [],
    "contents": "\nHi, this is my practice corner for coding in R. I would want to:\nlearn tidyverse\npractice on data visualization, exploration.\nlearn tidymodels/machine learning\nwork on chemistry related datasets using R\nlearn Design of Experiment\nlearn Chemometrics\nlearn how to analyse sensory data\nbe able to communicate insights from data analysis using the Rmarkdown/distill packages\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-18T21:54:53+08:00",
    "input_file": {}
  }
]
